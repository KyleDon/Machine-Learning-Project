{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team Member: Zhengxuan Dong, Xiaoyan Zhou\n",
    "# This project is used to recognize an image is a flower or not\n",
    "# We build a CNN to do this job\n",
    "# First we generate the training dataset\n",
    "# Second training the CNN with training dataset\n",
    "# Then test the CNN with test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "from optparse import OptionParser\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "from torch.autograd import Function, Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import dataset\n",
    "from skimage import transform,data\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import pickle\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define convolutional neural network\n",
    "class single_conv(nn.Module):\n",
    "    #'''(conv => BN => ReLU) '''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(single_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch,out_ch,3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "class down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "        self.down = nn.MaxPool2d(2,stride=2)      # use nn.MaxPool2d( )\n",
    "        self.conv =single_conv(in_ch,out_ch)                     # use previously defined single_cov\n",
    "    def forward(self, x):\n",
    "        x = self.down(x)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "class outconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv =nn.Conv2d(in_ch,out_ch,3,padding=1)    # Use nn.Conv2D( ) since we do not need to do batch norm and relu at this layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define fully-connected layer\n",
    "class fullyconnect(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(fullyconnect, self).__init__()\n",
    "        self.fullyconnect =nn.Linear(in_ch, out_ch)\n",
    "    def forward(self, x):\n",
    "        x = self.fullyconnect(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a network with 3 convolutional layers and 2 fully connected layers\n",
    "class CNN_Net(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = single_conv(n_channels, 16) # conv2d +  batchnorm + relu\n",
    "        self.down1 = down(16, 32)                 # maxpool2d + conv2d + batchnorm + relu\n",
    "        self.down2 = down(32, 32)                 # maxpool2d + conv2d + batchnorm + relu\n",
    "        #self.outc = outconv(32,n_classes)\n",
    "        self.ful1 = fullyconnect(32*225,1000)\n",
    "        self.ful2 = fullyconnect(1000,1)\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = x3#self.outc(x3)\n",
    "        x5 = x4.reshape((32*225))\n",
    "        x6 = self.ful1(x5)\n",
    "        x7 = self.ful2(x6)\n",
    "        return F.sigmoid(x7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train data\n",
    "def get_train_val(image_paths):\n",
    "    img_paths_dic = {}\n",
    "    len_data = len(image_paths)\n",
    "    for i in range(len(image_paths)):\n",
    "        img_paths_dic[os.path.basename(image_paths[i])[:-4]] = image_paths[i]\n",
    "    \n",
    "    img_mask_list = []\n",
    "    for key in img_paths_dic:\n",
    "        img_mask_list.append((img_paths_dic[key]))\n",
    "        \n",
    "    train_img_paths = img_mask_list \n",
    "    return train_img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_img_paths):\n",
    "    img_prob_list = []\n",
    "    \n",
    "    for i in tqdm(range(len(image_img_paths))):\n",
    "        img = np.array(Image.open(image_img_paths[i]), np.float32) / 255.0 \n",
    "        k=os.path.basename(image_paths[i])[1]\n",
    "        \n",
    "        if k=='0':\n",
    "            prob = np.array([1]).astype(float)\n",
    "        elif k=='1':\n",
    "            prob = np.array([0]).astype(float)\n",
    "        \n",
    "        \n",
    "        img_prob_list.append((img,prob))\n",
    "    print(len(image_img_paths))\n",
    "    print(len(img_prob_list))\n",
    "    return img_prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_store(file_name,save_data):\n",
    "    fileObj = open(file_name,'wb')\n",
    "    pickle.dump(save_data,fileObj)\n",
    "    fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image shape: (60, 60, 3)\n",
      "total len: 3956\n",
      "l0b0\n",
      "3956\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loading data\n",
    "image_paths = glob.glob(\"cir01_train2/*.jpg\")\n",
    "print('original image shape: {}'.format(np.array(Image.open(image_paths[0])).shape))\n",
    "plt.imshow(Image.open(image_paths[0]))\n",
    "train_img_paths = get_train_val(image_paths)\n",
    "print('total len:', len(train_img_paths))\n",
    "print(os.path.basename(image_paths[0])[:-4])\n",
    "print(len(train_img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 3956\n"
     ]
    }
   ],
   "source": [
    "train_img_prob_save_path = './train_img_prob8.pickle'\n",
    "if os.path.exists(train_img_prob_save_path):\n",
    "    with open(train_img_prob_save_path,'rb') as f:\n",
    "        train_img_prob = pickle.load(f)\n",
    "    f.close()\n",
    "else:\n",
    "    train_img_prob = preprocess_image(train_img_paths)\n",
    "    pickle_store(train_img_prob_save_path,train_img_prob)\n",
    "print('train len: {}'.format(len(train_img_prob)))\n",
    "#print(train_img_prob[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flip(object):\n",
    "    \"\"\"\n",
    "    Flip the image left or right for data augmentation, but prefer original image.\n",
    "    \"\"\"\n",
    "    def __init__(self,ori_probability=0.60):\n",
    "        self.ori_probability = ori_probability\n",
    " \n",
    "    def __call__(self, sample):\n",
    "        if random.uniform(0,1) < self.ori_probability:\n",
    "            return sample\n",
    "        else:\n",
    "            img, label = sample['img'], sample['label']\n",
    "            img_flip = img[:,:,::-1]\n",
    "            label_flip = label\n",
    "            \n",
    "            return {'img': img_flip, 'label': label_flip}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"\n",
    "    Convert ndarrays in sample to Tensors.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['img'], sample['label']\n",
    "\n",
    "        return {'img': torch.from_numpy(image.copy()).type(torch.DoubleTensor),\n",
    "                'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n",
      "3956\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self, image_probs, transforms=None):   # initial logic happens like transform\n",
    "\n",
    "        self.image_probs = image_probs\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):  # return count of sample we have\n",
    "\n",
    "        return len(self.image_probs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image = self.image_probs[index][0] # H, W, C\n",
    "        prob = self.image_probs[index][1]\n",
    "        \n",
    "        image = np.transpose(image, axes=[2, 0, 1]) # C, H, W\n",
    "        \n",
    "        sample = {'img': image, 'label': prob}\n",
    "        \n",
    "        if transforms:\n",
    "            sample = self.transforms(sample)\n",
    "            \n",
    "        return sample\n",
    "\n",
    "train_dataset = CustomDataset(train_img_prob, transforms=transforms.Compose([Flip(),ToTensor()]))\n",
    "\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ThinkPadT480s\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5675], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ThinkPadT480s\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2016: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0000 --- loss: 0.566506\n",
      "tensor([0.4755], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0003 --- loss: 0.645342\n",
      "tensor([0.5229], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0005 --- loss: 0.740098\n",
      "tensor([0.4244], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0008 --- loss: 0.552400\n",
      "tensor([0.3160], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0010 --- loss: 0.379869\n",
      "tensor([0.4882], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0013 --- loss: 0.716936\n",
      "tensor([0.2145], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0015 --- loss: 0.241372\n",
      "tensor([0.4576], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0018 --- loss: 0.781804\n",
      "tensor([0.7049], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0020 --- loss: 0.349750\n",
      "tensor([0.0291], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0023 --- loss: 0.029501\n",
      "tensor([0.7282], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0025 --- loss: 0.317153\n",
      "tensor([0.1160], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0028 --- loss: 0.123286\n",
      "tensor([0.9454], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0030 --- loss: 0.056142\n",
      "tensor([0.8343], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0033 --- loss: 0.181154\n",
      "tensor([0.9337], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0035 --- loss: 0.068558\n",
      "tensor([0.0152], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0038 --- loss: 0.015355\n",
      "tensor([0.9757], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0040 --- loss: 0.024562\n",
      "tensor([0.0062], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0043 --- loss: 0.006189\n",
      "tensor([0.0150], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0046 --- loss: 0.015115\n",
      "tensor([0.0196], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0048 --- loss: 0.019770\n",
      "tensor([0.1618], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0051 --- loss: 0.176536\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0053 --- loss: 0.001165\n",
      "tensor([0.0108], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0056 --- loss: 0.010852\n",
      "tensor([0.0053], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0058 --- loss: 0.005267\n",
      "tensor([0.0094], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0061 --- loss: 0.009426\n",
      "tensor([0.9891], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0063 --- loss: 4.521974\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0066 --- loss: 0.000857\n",
      "tensor([0.0024], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0068 --- loss: 0.002387\n",
      "tensor([0.0165], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0071 --- loss: 0.016668\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0073 --- loss: 0.001571\n",
      "tensor([0.9986], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0076 --- loss: 0.001451\n",
      "tensor([0.1734], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0078 --- loss: 0.190402\n",
      "tensor([0.0519], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0081 --- loss: 0.053316\n",
      "tensor([0.9980], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0083 --- loss: 0.001963\n",
      "tensor([0.0048], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0086 --- loss: 0.004767\n",
      "tensor([0.9840], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0088 --- loss: 0.016093\n",
      "tensor([0.9838], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0091 --- loss: 0.016296\n",
      "tensor([0.0014], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0094 --- loss: 0.001444\n",
      "tensor([0.0206], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0096 --- loss: 0.020784\n",
      "tensor([0.9724], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0099 --- loss: 0.027964\n",
      "tensor([0.9906], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0101 --- loss: 0.009464\n",
      "tensor([0.0084], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0104 --- loss: 0.008395\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0106 --- loss: 0.001117\n",
      "tensor([0.9854], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0109 --- loss: 0.014660\n",
      "tensor([0.9936], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0111 --- loss: 0.006385\n",
      "tensor([0.9738], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0114 --- loss: 0.026562\n",
      "tensor([0.9913], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0116 --- loss: 0.008737\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0119 --- loss: 0.000433\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0121 --- loss: 0.000806\n",
      "tensor([0.0083], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0124 --- loss: 0.008377\n",
      "tensor([0.9911], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0126 --- loss: 0.008891\n",
      "tensor([0.0081], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0129 --- loss: 0.008173\n",
      "tensor([0.0054], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0131 --- loss: 0.005442\n",
      "tensor([0.9962], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0134 --- loss: 0.003818\n",
      "tensor([0.9875], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0137 --- loss: 0.012595\n",
      "tensor([0.0095], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0139 --- loss: 0.009564\n",
      "tensor([0.9821], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0142 --- loss: 0.018018\n",
      "tensor([0.9360], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0144 --- loss: 0.066148\n",
      "tensor([0.9790], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0147 --- loss: 3.864598\n",
      "tensor([0.0030], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0149 --- loss: 0.002971\n",
      "tensor([0.9552], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0152 --- loss: 0.045829\n",
      "tensor([0.2140], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0154 --- loss: 0.240772\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0157 --- loss: 0.000639\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0159 --- loss: 0.000491\n",
      "tensor([0.1858], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0162 --- loss: 1.682912\n",
      "tensor([0.8821], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0164 --- loss: 0.125506\n",
      "tensor([0.9490], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0167 --- loss: 0.052348\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0169 --- loss: 0.000493\n",
      "tensor([0.3366], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0172 --- loss: 1.088991\n",
      "tensor([0.0193], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0174 --- loss: 0.019474\n",
      "tensor([0.0322], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0177 --- loss: 0.032769\n",
      "tensor([0.0028], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0179 --- loss: 0.002783\n",
      "tensor([0.0011], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0182 --- loss: 0.001095\n",
      "tensor([0.9555], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0185 --- loss: 0.045564\n",
      "tensor([0.3028], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0187 --- loss: 0.360697\n",
      "tensor([0.0256], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0190 --- loss: 0.025909\n",
      "tensor([0.6592], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0192 --- loss: 1.076401\n",
      "tensor([0.0019], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0195 --- loss: 0.001922\n",
      "tensor([0.0106], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0197 --- loss: 0.010683\n",
      "tensor([0.5630], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0200 --- loss: 0.827850\n",
      "tensor([0.9963], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0202 --- loss: 0.003725\n",
      "tensor([0.9892], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0205 --- loss: 0.010888\n",
      "tensor([0.9918], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0207 --- loss: 0.008224\n",
      "tensor([0.0144], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0210 --- loss: 0.014468\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0212 --- loss: 0.000253\n",
      "tensor([0.0053], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0215 --- loss: 0.005297\n",
      "tensor([0.2674], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0217 --- loss: 0.311222\n",
      "tensor([0.0040], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0220 --- loss: 0.004044\n",
      "tensor([0.0028], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0222 --- loss: 0.002815\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0225 --- loss: 0.000294\n",
      "tensor([0.9138], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0228 --- loss: 0.090147\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0230 --- loss: 0.000217\n",
      "tensor([4.7084e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0233 --- loss: 0.000047\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0235 --- loss: 0.000162\n",
      "tensor([0.7956], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0238 --- loss: 0.228708\n",
      "tensor([0.3573], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0240 --- loss: 1.029075\n",
      "tensor([0.0020], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0243 --- loss: 0.001958\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0245 --- loss: 0.000294\n",
      "tensor([0.0009], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0248 --- loss: 0.000895\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0250 --- loss: 0.000375\n",
      "tensor([0.9945], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0253 --- loss: 0.005514\n",
      "tensor([0.9964], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0255 --- loss: 0.003642\n",
      "tensor([0.0009], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0258 --- loss: 0.000873\n",
      "tensor([0.0057], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0260 --- loss: 0.005678\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0263 --- loss: 0.000779\n",
      "tensor([0.9958], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0265 --- loss: 0.004174\n",
      "tensor([0.0017], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0268 --- loss: 0.001673\n",
      "tensor([0.9983], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0270 --- loss: 0.001715\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0273 --- loss: 0.000285\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0276 --- loss: 0.000487\n",
      "tensor([0.9983], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0278 --- loss: 0.001698\n",
      "tensor([0.1606], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0281 --- loss: 0.175103\n",
      "tensor([0.0009], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0283 --- loss: 0.000912\n",
      "tensor([0.0021], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0286 --- loss: 0.002133\n",
      "tensor([0.0489], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0288 --- loss: 0.050095\n",
      "tensor([0.0129], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0291 --- loss: 0.013019\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0293 --- loss: 0.000382\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0296 --- loss: 0.000263\n",
      "tensor([0.0348], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0298 --- loss: 0.035453\n",
      "tensor([0.0023], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0301 --- loss: 0.002280\n",
      "tensor([0.9971], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0303 --- loss: 0.002906\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0306 --- loss: 0.000858\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0308 --- loss: 0.000025\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0311 --- loss: 0.001206\n",
      "tensor([0.0012], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0313 --- loss: 0.001236\n",
      "tensor([0.0869], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0316 --- loss: 0.090862\n",
      "tensor([0.9969], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0319 --- loss: 0.003078\n",
      "tensor([0.9981], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0321 --- loss: 0.001896\n",
      "tensor([0.0070], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0324 --- loss: 0.006990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4925], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0326 --- loss: 0.678327\n",
      "tensor([0.0016], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0329 --- loss: 0.001574\n",
      "tensor([0.0039], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0331 --- loss: 0.003917\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0334 --- loss: 0.000710\n",
      "tensor([0.0011], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0336 --- loss: 0.001113\n",
      "tensor([0.9976], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0339 --- loss: 0.002368\n",
      "tensor([0.9978], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0341 --- loss: 0.002184\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0344 --- loss: 0.000266\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0346 --- loss: 0.000155\n",
      "tensor([0.0054], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0349 --- loss: 0.005424\n",
      "tensor([0.9981], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0351 --- loss: 0.001909\n",
      "tensor([0.0023], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0354 --- loss: 0.002266\n",
      "tensor([3.5424e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0356 --- loss: 0.000035\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0359 --- loss: 0.000062\n",
      "tensor([0.9971], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0361 --- loss: 0.002892\n",
      "tensor([0.0016], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0364 --- loss: 0.001592\n",
      "tensor([0.0041], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0367 --- loss: 0.004155\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0369 --- loss: 0.000295\n",
      "tensor([0.9948], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0372 --- loss: 0.005183\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0374 --- loss: 0.000734\n",
      "tensor([2.6685e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0377 --- loss: 0.000027\n",
      "tensor([7.6434e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0379 --- loss: 0.000076\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0382 --- loss: 0.000157\n",
      "tensor([0.0044], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0384 --- loss: 0.004398\n",
      "tensor([0.9977], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0387 --- loss: 0.002294\n",
      "tensor([0.9891], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0389 --- loss: 0.010912\n",
      "tensor([0.8683], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0392 --- loss: 0.141181\n",
      "tensor([0.0109], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0394 --- loss: 0.010952\n",
      "tensor([0.9990], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0397 --- loss: 0.001004\n",
      "tensor([0.0225], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0399 --- loss: 0.022732\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0402 --- loss: 0.000105\n",
      "tensor([2.9377e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0404 --- loss: 0.000029\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0407 --- loss: 0.000160\n",
      "tensor([5.2522e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0410 --- loss: 0.000053\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0412 --- loss: 0.000225\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0415 --- loss: 0.000911\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0417 --- loss: 0.000279\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0420 --- loss: 0.000408\n",
      "tensor([3.5184e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0422 --- loss: 0.000035\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0425 --- loss: 0.000514\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0427 --- loss: 0.000881\n",
      "tensor([2.8997e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0430 --- loss: 0.000029\n",
      "tensor([0.0138], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0432 --- loss: 0.013884\n",
      "tensor([0.0012], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0435 --- loss: 0.001169\n",
      "tensor([0.0024], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0437 --- loss: 0.002384\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0440 --- loss: 0.000841\n",
      "tensor([5.0040e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0442 --- loss: 0.000050\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0445 --- loss: 0.000163\n",
      "tensor([2.6086e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0447 --- loss: 0.000026\n",
      "tensor([5.7239e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0450 --- loss: 0.000057\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0452 --- loss: 0.001650\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0455 --- loss: 0.000225\n",
      "tensor([0.0018], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0458 --- loss: 0.001791\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0460 --- loss: 0.000243\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0463 --- loss: 0.000794\n",
      "tensor([0.9951], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0465 --- loss: 0.004941\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0468 --- loss: 0.000780\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0470 --- loss: 0.000516\n",
      "tensor([0.0122], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0473 --- loss: 0.012304\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0475 --- loss: 0.000087\n",
      "tensor([0.0012], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0478 --- loss: 0.001181\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0480 --- loss: 0.000820\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0483 --- loss: 0.000177\n",
      "tensor([0.9982], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0485 --- loss: 0.001812\n",
      "tensor([0.9773], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0488 --- loss: 3.785242\n",
      "tensor([7.3753e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0490 --- loss: 0.000074\n",
      "tensor([7.3795e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0493 --- loss: 0.000074\n",
      "tensor([0.0016], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0495 --- loss: 0.001590\n",
      "tensor([0.2318], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0498 --- loss: 0.263700\n",
      "tensor([2.0848e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0501 --- loss: 0.000021\n",
      "tensor([0.9417], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0503 --- loss: 0.060073\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0506 --- loss: 0.000211\n",
      "tensor([0.9987], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0508 --- loss: 0.001329\n",
      "tensor([0.0309], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0511 --- loss: 0.031408\n",
      "tensor([0.9974], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0513 --- loss: 0.002585\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0516 --- loss: 0.000399\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0518 --- loss: 0.000278\n",
      "tensor([0.0021], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0521 --- loss: 0.002133\n",
      "tensor([8.5242e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0523 --- loss: 0.000085\n",
      "tensor([0.9977], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0526 --- loss: 0.002322\n",
      "tensor([8.2359e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0528 --- loss: 0.000082\n",
      "tensor([0.0473], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0531 --- loss: 0.048447\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0533 --- loss: 0.000474\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0536 --- loss: 0.000246\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0538 --- loss: 0.000081\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0541 --- loss: 0.000750\n",
      "tensor([0.0118], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0543 --- loss: 0.011862\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0546 --- loss: 0.000062\n",
      "tensor([0.2834], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0549 --- loss: 0.333237\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0551 --- loss: 0.000270\n",
      "tensor([0.9974], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0554 --- loss: 0.002649\n",
      "tensor([0.0059], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0556 --- loss: 0.005893\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0559 --- loss: 0.001137\n",
      "tensor([0.9045], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0561 --- loss: 2.348927\n",
      "tensor([0.9943], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0564 --- loss: 0.005673\n",
      "tensor([0.9064], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0566 --- loss: 0.098302\n",
      "tensor([9.2691e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0569 --- loss: 0.000093\n",
      "tensor([0.0802], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0571 --- loss: 0.083558\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0574 --- loss: 0.000318\n",
      "tensor([0.6046], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0576 --- loss: 0.503164\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0579 --- loss: 0.000112\n",
      "tensor([5.0116e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0581 --- loss: 0.000050\n",
      "tensor([1.5193e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0584 --- loss: 0.000015\n",
      "tensor([1.2118e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0586 --- loss: 0.000012\n",
      "tensor([5.4374e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0589 --- loss: 0.000005\n",
      "tensor([6.5558e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0592 --- loss: 0.000066\n",
      "tensor([3.8208e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0594 --- loss: 0.000038\n",
      "tensor([0.6824], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0597 --- loss: 0.382086\n",
      "tensor([1.7828e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0599 --- loss: 0.000018\n",
      "tensor([1.9610e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0602 --- loss: 0.000020\n",
      "tensor([0.9618], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0604 --- loss: 0.038979\n",
      "tensor([0.0428], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0607 --- loss: 0.043714\n",
      "tensor([6.0934e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0609 --- loss: 0.000006\n",
      "tensor([7.1567e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0612 --- loss: 0.000072\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0614 --- loss: 0.000157\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0617 --- loss: 0.000484\n",
      "tensor([0.0019], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0619 --- loss: 0.001902\n",
      "tensor([9.6389e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0622 --- loss: 0.000096\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0624 --- loss: 0.000253\n",
      "tensor([0.9963], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0627 --- loss: 0.003677\n",
      "tensor([0.0009], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0629 --- loss: 0.000906\n",
      "tensor([0.9857], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0632 --- loss: 0.014452\n",
      "tensor([6.5191e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0634 --- loss: 0.000007\n",
      "tensor([0.9625], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0637 --- loss: 0.038180\n",
      "tensor([7.2156e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0640 --- loss: 0.000007\n",
      "tensor([0.6453], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0642 --- loss: 0.437995\n",
      "tensor([0.0107], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0645 --- loss: 0.010797\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0647 --- loss: 0.000242\n",
      "tensor([1.4830e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0650 --- loss: 0.000015\n",
      "tensor([1.4794e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0652 --- loss: 0.000015\n",
      "tensor([0.9783], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0655 --- loss: 0.021945\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0657 --- loss: 0.000253\n",
      "tensor([2.5880e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0660 --- loss: 0.000026\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0662 --- loss: 0.000158\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0665 --- loss: 0.000082\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0667 --- loss: 0.000068\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0670 --- loss: 0.001624\n",
      "tensor([0.0012], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0672 --- loss: 0.001216\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0675 --- loss: 0.000674\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0677 --- loss: 0.000542\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0680 --- loss: 0.000022\n",
      "tensor([0.0409], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0683 --- loss: 0.041810\n",
      "tensor([0.9982], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0685 --- loss: 0.001792\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0688 --- loss: 0.000160\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0690 --- loss: 0.000027\n",
      "tensor([0.0088], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0693 --- loss: 0.008793\n",
      "tensor([0.9990], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0695 --- loss: 0.001022\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0698 --- loss: 0.000152\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0700 --- loss: 0.000156\n",
      "tensor([0.0017], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0703 --- loss: 0.001705\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0705 --- loss: 0.000236\n",
      "tensor([0.0013], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0708 --- loss: 0.001256\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0710 --- loss: 0.000133\n",
      "tensor([0.0022], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0713 --- loss: 0.002159\n",
      "tensor([7.3161e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0715 --- loss: 0.000073\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0718 --- loss: 0.000641\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0720 --- loss: 0.000145\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0723 --- loss: 0.000033\n",
      "tensor([0.0156], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0725 --- loss: 0.015738\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0728 --- loss: 0.000031\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0731 --- loss: 0.000035\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0733 --- loss: 0.000924\n",
      "tensor([0.5872], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0736 --- loss: 0.532336\n",
      "tensor([3.7989e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0738 --- loss: 0.000038\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0741 --- loss: 0.000015\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0743 --- loss: 0.000111\n",
      "tensor([0.0021], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0746 --- loss: 0.002099\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0748 --- loss: 0.000039\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0751 --- loss: 0.000212\n",
      "tensor([3.7054e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0753 --- loss: 0.000037\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0756 --- loss: 0.000419\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0758 --- loss: 0.001160\n",
      "tensor([0.5719], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0761 --- loss: 0.558810\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0763 --- loss: 0.000021\n",
      "tensor([5.8328e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0766 --- loss: 0.000058\n",
      "tensor([0.1978], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0768 --- loss: 0.220427\n",
      "tensor([0.0045], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0771 --- loss: 0.004490\n",
      "tensor([0.9939], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0774 --- loss: 0.006133\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0776 --- loss: 0.000158\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0779 --- loss: 0.000028\n",
      "tensor([0.0011], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0781 --- loss: 0.001084\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0784 --- loss: 0.000001\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0786 --- loss: 0.000404\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0789 --- loss: 0.000464\n",
      "tensor([0.0014], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0791 --- loss: 0.001425\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0794 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0796 --- loss: 0.000033\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0799 --- loss: 0.000655\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0801 --- loss: 0.000171\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0804 --- loss: 0.000836\n",
      "tensor([0.0350], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0806 --- loss: 0.035591\n",
      "tensor([0.0040], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0809 --- loss: 0.004032\n",
      "tensor([0.0052], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0811 --- loss: 0.005192\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0814 --- loss: 0.000003\n",
      "tensor([0.0033], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0816 --- loss: 0.003335\n",
      "tensor([8.2451e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0819 --- loss: 0.000008\n",
      "tensor([5.4630e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0822 --- loss: 0.000055\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0824 --- loss: 0.000003\n",
      "tensor([0.0853], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0827 --- loss: 0.089208\n",
      "tensor([0.0012], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0829 --- loss: 0.001236\n",
      "tensor([2.0095e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0832 --- loss: 0.000020\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0834 --- loss: 0.000779\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0837 --- loss: 0.000985\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0839 --- loss: 0.000459\n",
      "tensor([5.9627e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0842 --- loss: 0.000060\n",
      "tensor([0.0060], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0844 --- loss: 0.006010\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0847 --- loss: 0.000041\n",
      "tensor([3.5974e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0849 --- loss: 0.000036\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0852 --- loss: 0.001008\n",
      "tensor([5.9869e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0854 --- loss: 0.000060\n",
      "tensor([0.0051], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0857 --- loss: 0.005136\n",
      "tensor([0.0058], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0859 --- loss: 0.005793\n",
      "tensor([0.0341], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0862 --- loss: 0.034722\n",
      "tensor([2.5535e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0865 --- loss: 0.000026\n",
      "tensor([5.8829e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0867 --- loss: 0.000059\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0870 --- loss: 0.000006\n",
      "tensor([0.0031], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0872 --- loss: 0.003098\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0875 --- loss: 0.000007\n",
      "tensor([2.5026e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0877 --- loss: 0.000025\n",
      "tensor([2.0564e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0880 --- loss: 0.000021\n",
      "tensor([3.6233e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0882 --- loss: 0.000036\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0885 --- loss: 0.000007\n",
      "tensor([0.1346], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0887 --- loss: 0.144558\n",
      "tensor([0.0136], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0890 --- loss: 0.013656\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0892 --- loss: 0.000003\n",
      "tensor([0.1080], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0895 --- loss: 0.114266\n",
      "tensor([0.0035], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0897 --- loss: 0.003534\n",
      "tensor([0.0037], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0900 --- loss: 0.003750\n",
      "tensor([2.6306e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0902 --- loss: 0.000026\n",
      "tensor([3.5844e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0905 --- loss: 0.000036\n",
      "tensor([0.0073], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0907 --- loss: 0.007366\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0910 --- loss: 0.000055\n",
      "tensor([3.1534e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0913 --- loss: 0.000032\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0915 --- loss: 0.001155\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0918 --- loss: 0.000463\n",
      "tensor([0.0013], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0920 --- loss: 0.001253\n",
      "tensor([0.0030], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0923 --- loss: 0.003032\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0925 --- loss: 0.000034\n",
      "tensor([1.0106e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0928 --- loss: 0.000010\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0930 --- loss: 0.000611\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0933 --- loss: 0.000420\n",
      "tensor([0.0535], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0935 --- loss: 0.055029\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0938 --- loss: 0.000408\n",
      "tensor([1.5966e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0940 --- loss: 0.000016\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0943 --- loss: 0.000141\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0945 --- loss: 0.000002\n",
      "tensor([5.1386e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0948 --- loss: 0.000005\n",
      "tensor([0.0087], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0950 --- loss: 0.008694\n",
      "tensor([0.9982], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0953 --- loss: 0.001762\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0956 --- loss: 0.000014\n",
      "tensor([0.0012], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0958 --- loss: 0.001201\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0961 --- loss: 0.000251\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0963 --- loss: 0.000124\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0966 --- loss: 0.000140\n",
      "tensor([0.9986], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0968 --- loss: 0.001446\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0971 --- loss: 0.000376\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0973 --- loss: 0.000765\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0976 --- loss: 0.000002\n",
      "tensor([0.9986], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0978 --- loss: 0.001374\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0981 --- loss: 0.000039\n",
      "tensor([5.4377e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0983 --- loss: 0.000054\n",
      "tensor([0.9961], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0986 --- loss: 0.003939\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0988 --- loss: 0.000215\n",
      "tensor([0.0069], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0991 --- loss: 0.006970\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0993 --- loss: 0.000214\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0996 --- loss: 0.000728\n",
      "tensor([0.0018], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0998 --- loss: 0.001830\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1001 --- loss: 0.000153\n",
      "tensor([8.7894e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1004 --- loss: 0.000088\n",
      "tensor([0.8769], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1006 --- loss: 0.131368\n",
      "tensor([0.0014], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1009 --- loss: 0.001450\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1011 --- loss: 0.000573\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1014 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1016 --- loss: 0.000025\n",
      "tensor([0.9985], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1019 --- loss: 0.001478\n",
      "tensor([0.0903], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1021 --- loss: 0.094662\n",
      "tensor([0.0145], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1024 --- loss: 0.014650\n",
      "tensor([1.8325e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1026 --- loss: 0.000002\n",
      "tensor([1.2602e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1029 --- loss: 0.000013\n",
      "tensor([8.3280e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1031 --- loss: 0.000008\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1034 --- loss: 0.000031\n",
      "tensor([0.0162], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1036 --- loss: 0.016359\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1039 --- loss: 0.000218\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1041 --- loss: 0.000143\n",
      "tensor([3.9785e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1044 --- loss: 0.000004\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1047 --- loss: 0.000298\n",
      "tensor([0.0100], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1049 --- loss: 0.010082\n",
      "tensor([3.8615e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1052 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1054 --- loss: 0.000014\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1057 --- loss: 0.000151\n",
      "tensor([0.0407], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1059 --- loss: 0.041589\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1062 --- loss: 0.000006\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1064 --- loss: 0.000194\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1067 --- loss: 0.000001\n",
      "tensor([0.0013], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1069 --- loss: 0.001289\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1072 --- loss: 0.000614\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1074 --- loss: 0.000101\n",
      "tensor([0.0021], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1077 --- loss: 0.002117\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1079 --- loss: 0.000306\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1082 --- loss: 0.000148\n",
      "tensor([2.7493e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1084 --- loss: 0.000027\n",
      "tensor([0.0157], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1087 --- loss: 0.015868\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1089 --- loss: 0.000541\n",
      "tensor([0.0109], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1092 --- loss: 0.010985\n",
      "tensor([0.0011], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1095 --- loss: 0.001094\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1097 --- loss: 0.000002\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1100 --- loss: 0.000072\n",
      "tensor([9.4880e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1102 --- loss: 0.000095\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1105 --- loss: 0.000028\n",
      "tensor([3.2239e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1107 --- loss: 0.000003\n",
      "tensor([1.3271e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1110 --- loss: 0.000013\n",
      "tensor([8.2352e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1112 --- loss: 0.000001\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1115 --- loss: 0.000499\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1117 --- loss: 0.000008\n",
      "tensor([7.8665e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1120 --- loss: 0.000079\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1122 --- loss: 0.000264\n",
      "tensor([5.9385e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1125 --- loss: 0.000059\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1127 --- loss: 0.000505\n",
      "tensor([0.9953], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1130 --- loss: 0.004709\n",
      "tensor([0.0040], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1132 --- loss: 0.003960\n",
      "tensor([0.9913], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1135 --- loss: 0.008779\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1138 --- loss: 0.000346\n",
      "tensor([0.0499], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1140 --- loss: 0.051147\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1143 --- loss: 0.000017\n",
      "tensor([5.7433e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1145 --- loss: 0.000006\n",
      "tensor([3.9309e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1148 --- loss: 0.000004\n",
      "tensor([5.7191e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1150 --- loss: 0.000057\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1153 --- loss: 0.000142\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1155 --- loss: 0.000050\n",
      "tensor([0.0014], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1158 --- loss: 0.001402\n",
      "tensor([1.9716e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1160 --- loss: 0.000020\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1163 --- loss: 0.000659\n",
      "tensor([6.7042e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1165 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1168 --- loss: 0.000036\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1170 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1173 --- loss: 0.000043\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1175 --- loss: 0.000078\n",
      "tensor([0.0011], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1178 --- loss: 0.001129\n",
      "tensor([0.2805], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1180 --- loss: 0.329239\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1183 --- loss: 0.000136\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1186 --- loss: 0.000003\n",
      "tensor([4.1688e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1188 --- loss: 0.000042\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1191 --- loss: 0.000106\n",
      "tensor([1.4687e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1193 --- loss: 0.000001\n",
      "tensor([1.9544e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1196 --- loss: 0.000002\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1198 --- loss: 0.000270\n",
      "tensor([0.9758], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1201 --- loss: 0.024509\n",
      "tensor([1.5074e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1203 --- loss: 0.000015\n",
      "tensor([0.9850], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1206 --- loss: 0.015131\n",
      "tensor([0.9944], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1208 --- loss: 0.005662\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1211 --- loss: 0.000069\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1213 --- loss: 0.000515\n",
      "tensor([1.6337e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1216 --- loss: 0.000000\n",
      "tensor([2.0068e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1218 --- loss: 0.000000\n",
      "tensor([0.0013], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1221 --- loss: 0.001316\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1223 --- loss: 0.000099\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1226 --- loss: 0.000088\n",
      "tensor([1.5956e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1229 --- loss: 0.000016\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1231 --- loss: 0.000885\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1234 --- loss: 0.000058\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1236 --- loss: 0.000008\n",
      "tensor([1.8875e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1239 --- loss: 0.000002\n",
      "tensor([1.0576e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1241 --- loss: 0.000001\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1244 --- loss: 0.000305\n",
      "tensor([0.9982], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1246 --- loss: 0.001757\n",
      "tensor([1.5246e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1249 --- loss: 0.000002\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1251 --- loss: 0.000435\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1254 --- loss: 0.001609\n",
      "tensor([1.1419e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1256 --- loss: 0.000011\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1259 --- loss: 0.000123\n",
      "tensor([0.0135], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1261 --- loss: 0.013569\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1264 --- loss: 0.000311\n",
      "tensor([1.0704e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1266 --- loss: 0.000011\n",
      "tensor([5.8389e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1269 --- loss: 0.000001\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1271 --- loss: 0.000197\n",
      "tensor([2.0888e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1274 --- loss: 0.000021\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1277 --- loss: 0.000021\n",
      "tensor([2.8419e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1279 --- loss: 0.000003\n",
      "tensor([2.2350e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1282 --- loss: 0.000000\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1284 --- loss: 0.001215\n",
      "tensor([3.8127e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1287 --- loss: 0.000038\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1289 --- loss: 0.000524\n",
      "tensor([7.2717e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1292 --- loss: 0.000007\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1294 --- loss: 0.000189\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1297 --- loss: 0.000783\n",
      "tensor([5.4153e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1299 --- loss: 0.000005\n",
      "tensor([0.9946], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1302 --- loss: 0.005456\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1304 --- loss: 0.000695\n",
      "tensor([7.6329e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1307 --- loss: 0.000001\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1309 --- loss: 0.001209\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1312 --- loss: 0.000122\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1314 --- loss: 0.001250\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1317 --- loss: 0.000017\n",
      "tensor([0.4683], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1320 --- loss: 0.758643\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1322 --- loss: 0.000108\n",
      "tensor([0.9874], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1325 --- loss: 0.012716\n",
      "tensor([1.7680e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1327 --- loss: 0.000000\n",
      "tensor([0.9974], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1330 --- loss: 0.002564\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1332 --- loss: 0.001637\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1335 --- loss: 0.000229\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1337 --- loss: 0.001033\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1340 --- loss: 0.000214\n",
      "tensor([6.1512e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1342 --- loss: 0.000006\n",
      "tensor([2.6432e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1345 --- loss: 0.000026\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1347 --- loss: 0.000001\n",
      "tensor([0.2357], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1350 --- loss: 1.445176\n",
      "tensor([3.2332e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1352 --- loss: 0.000003\n",
      "tensor([4.3416e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1355 --- loss: 0.000043\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1357 --- loss: 0.000042\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1360 --- loss: 0.000005\n",
      "tensor([0.1537], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1362 --- loss: 0.166853\n",
      "tensor([2.7571e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1365 --- loss: 0.000003\n",
      "tensor([1.4332e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1368 --- loss: 0.000014\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1370 --- loss: 0.000318\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1373 --- loss: 0.000018\n",
      "tensor([0.0167], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1375 --- loss: 0.016823\n",
      "tensor([0.0271], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1378 --- loss: 0.027489\n",
      "tensor([0.0012], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1380 --- loss: 0.001163\n",
      "tensor([0.0157], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1383 --- loss: 0.015835\n",
      "tensor([0.0270], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1385 --- loss: 0.027331\n",
      "tensor([1.2549e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1388 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1390 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1393 --- loss: 0.000002\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1395 --- loss: 0.000313\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1398 --- loss: 0.000002\n",
      "tensor([0.0201], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1400 --- loss: 0.020322\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1403 --- loss: 0.000001\n",
      "tensor([0.9978], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1405 --- loss: 0.002224\n",
      "tensor([1.2115e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1408 --- loss: 0.000001\n",
      "tensor([0.0016], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1411 --- loss: 0.001583\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1413 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1416 --- loss: 0.000006\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1418 --- loss: 0.000179\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1421 --- loss: 0.000210\n",
      "tensor([1.1644e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1423 --- loss: 0.000012\n",
      "tensor([0.9859], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1426 --- loss: 4.261114\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1428 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1431 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1433 --- loss: 0.000004\n",
      "tensor([1.7613e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1436 --- loss: 0.000018\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1438 --- loss: 0.000159\n",
      "tensor([1.1282e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1441 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1443 --- loss: 0.000011\n",
      "tensor([1.2669e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1446 --- loss: 0.000000\n",
      "tensor([5.8800e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1448 --- loss: 0.000059\n",
      "tensor([4.6506e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1451 --- loss: 0.000000\n",
      "tensor([2.4600e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1453 --- loss: 0.000025\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1456 --- loss: 0.000237\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1459 --- loss: 0.000000\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1461 --- loss: 0.000318\n",
      "tensor([3.4087e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1464 --- loss: 0.000003\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1466 --- loss: 0.001250\n",
      "tensor([6.6713e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1469 --- loss: 0.000007\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1471 --- loss: 0.000008\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1474 --- loss: 0.000578\n",
      "tensor([0.0021], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1476 --- loss: 0.002087\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1479 --- loss: 0.000195\n",
      "tensor([0.0049], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1481 --- loss: 0.004925\n",
      "tensor([2.4020e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1484 --- loss: 0.000002\n",
      "tensor([1.6866e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1486 --- loss: 0.000017\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1489 --- loss: 0.000651\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1491 --- loss: 0.000156\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1494 --- loss: 0.000179\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1496 --- loss: 0.000159\n",
      "tensor([2.0548e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1499 --- loss: 0.000021\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1502 --- loss: 0.000303\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1504 --- loss: 0.000298\n",
      "tensor([8.3517e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1507 --- loss: 0.000008\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1509 --- loss: 0.000050\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1512 --- loss: 0.000697\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1514 --- loss: 0.000207\n",
      "tensor([0.0021], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1517 --- loss: 0.002073\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1519 --- loss: 0.000152\n",
      "tensor([0.9985], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1522 --- loss: 0.001459\n",
      "tensor([0.8845], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1524 --- loss: 0.122701\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1527 --- loss: 0.000807\n",
      "tensor([0.0172], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1529 --- loss: 0.017360\n",
      "tensor([0.9981], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1532 --- loss: 0.001853\n",
      "tensor([0.0872], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1534 --- loss: 0.091200\n",
      "tensor([9.8280e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1537 --- loss: 0.000010\n",
      "tensor([5.3811e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1539 --- loss: 0.000054\n",
      "tensor([0.9915], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1542 --- loss: 0.008584\n",
      "tensor([0.0049], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1544 --- loss: 0.004898\n",
      "tensor([0.9987], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1547 --- loss: 0.001256\n",
      "tensor([0.9971], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1550 --- loss: 0.002874\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1552 --- loss: 0.000047\n",
      "tensor([0.0076], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1555 --- loss: 0.007581\n",
      "tensor([0.0042], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1557 --- loss: 0.004255\n",
      "tensor([0.9759], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1560 --- loss: 3.727432\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1562 --- loss: 0.000058\n",
      "tensor([0.1097], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1565 --- loss: 0.116153\n",
      "tensor([0.6822], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1567 --- loss: 1.146354\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1570 --- loss: 0.000104\n",
      "tensor([0.0024], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1572 --- loss: 0.002416\n",
      "tensor([0.9928], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1575 --- loss: 0.007223\n",
      "tensor([5.7348e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1577 --- loss: 0.000001\n",
      "tensor([9.6399e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1580 --- loss: 0.000010\n",
      "tensor([2.9122e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1582 --- loss: 0.000003\n",
      "tensor([1.7276e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1585 --- loss: 0.000000\n",
      "tensor([0.0459], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1587 --- loss: 3.082295\n",
      "tensor([0.3023], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1590 --- loss: 1.196234\n",
      "tensor([0.9880], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1593 --- loss: 0.012032\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1595 --- loss: 0.000388\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1598 --- loss: 0.000184\n",
      "tensor([3.7894e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1600 --- loss: 0.000038\n",
      "tensor([0.9760], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1603 --- loss: 0.024258\n",
      "tensor([0.0012], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1605 --- loss: 0.001232\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1608 --- loss: 0.000021\n",
      "tensor([0.0021], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1610 --- loss: 0.002064\n",
      "tensor([0.8840], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1613 --- loss: 2.153885\n",
      "tensor([9.2602e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1615 --- loss: 0.000093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0620], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1618 --- loss: 0.064005\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1620 --- loss: 0.000472\n",
      "tensor([0.1923], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1623 --- loss: 0.213568\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1625 --- loss: 0.000256\n",
      "tensor([0.9397], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1628 --- loss: 0.062208\n",
      "tensor([1.7733e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1630 --- loss: 0.000002\n",
      "tensor([0.0612], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1633 --- loss: 0.063194\n",
      "tensor([1.9935e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1635 --- loss: 0.000020\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1638 --- loss: 0.000024\n",
      "tensor([0.0346], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1641 --- loss: 0.035229\n",
      "tensor([0.9388], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1643 --- loss: 0.063178\n",
      "tensor([0.9940], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1646 --- loss: 0.006014\n",
      "tensor([0.0045], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1648 --- loss: 0.004464\n",
      "tensor([0.9622], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1651 --- loss: 0.038508\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1653 --- loss: 0.000737\n",
      "tensor([0.0018], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1656 --- loss: 0.001788\n",
      "tensor([1.3594e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1658 --- loss: 0.000014\n",
      "tensor([0.0018], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1661 --- loss: 0.001807\n",
      "tensor([0.9920], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1663 --- loss: 0.007999\n",
      "tensor([1.3825e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1666 --- loss: 0.000014\n",
      "tensor([0.0283], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1668 --- loss: 0.028743\n",
      "tensor([0.9851], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1671 --- loss: 0.015061\n",
      "tensor([3.1103e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1673 --- loss: 0.000000\n",
      "tensor([0.0018], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1676 --- loss: 0.001844\n",
      "tensor([0.9943], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1678 --- loss: 0.005670\n",
      "tensor([0.3630], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1681 --- loss: 1.013454\n",
      "tensor([0.8823], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1684 --- loss: 0.125181\n",
      "tensor([9.3110e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1686 --- loss: 0.000009\n",
      "tensor([0.9558], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1689 --- loss: 0.045186\n",
      "tensor([2.4825e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1691 --- loss: 0.000000\n",
      "tensor([0.9940], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1694 --- loss: 0.006046\n",
      "tensor([0.9861], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1696 --- loss: 0.013985\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1699 --- loss: 0.000661\n",
      "tensor([0.0397], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1701 --- loss: 0.040524\n",
      "tensor([1.1094e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1704 --- loss: 0.000011\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1706 --- loss: 0.000036\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1709 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1711 --- loss: 0.000076\n",
      "tensor([0.5313], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1714 --- loss: 0.757712\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1716 --- loss: 0.000787\n",
      "tensor([0.0172], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1719 --- loss: 0.017302\n",
      "tensor([0.0148], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1721 --- loss: 0.014864\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1724 --- loss: 0.000456\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1726 --- loss: 0.000984\n",
      "tensor([4.2010e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1729 --- loss: 0.000042\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1732 --- loss: 0.000001\n",
      "tensor([0.0038], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1734 --- loss: 0.003793\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1737 --- loss: 0.000002\n",
      "tensor([9.9315e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1739 --- loss: 0.000099\n",
      "tensor([1.2417e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1742 --- loss: 0.000012\n",
      "tensor([0.1342], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1744 --- loss: 0.144055\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1747 --- loss: 0.000087\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1749 --- loss: 0.000047\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1752 --- loss: 0.000372\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1754 --- loss: 0.000040\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1757 --- loss: 0.000303\n",
      "tensor([0.0834], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1759 --- loss: 0.087070\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1762 --- loss: 0.000232\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1764 --- loss: 0.000581\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1767 --- loss: 0.001132\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1769 --- loss: 0.000243\n",
      "tensor([0.2408], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1772 --- loss: 0.275476\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1775 --- loss: 0.000002\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1777 --- loss: 0.000144\n",
      "tensor([5.6863e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1780 --- loss: 0.000057\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1782 --- loss: 0.000217\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1785 --- loss: 0.000021\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1787 --- loss: 0.000146\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1790 --- loss: 0.000206\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1792 --- loss: 0.000227\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1795 --- loss: 0.000058\n",
      "tensor([4.8176e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1797 --- loss: 0.000000\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1800 --- loss: 0.001603\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1802 --- loss: 0.000022\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1805 --- loss: 0.000113\n",
      "tensor([2.4411e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1807 --- loss: 0.000024\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1810 --- loss: 0.000353\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1812 --- loss: 0.000038\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1815 --- loss: 0.000597\n",
      "tensor([2.6730e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1817 --- loss: 0.000027\n",
      "tensor([0.0242], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1820 --- loss: 0.024543\n",
      "tensor([8.3403e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1823 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1825 --- loss: 0.000014\n",
      "tensor([4.3235e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1828 --- loss: 0.000000\n",
      "tensor([1.4473e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1830 --- loss: 0.000000\n",
      "tensor([5.7535e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1833 --- loss: 0.000058\n",
      "tensor([0.0498], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1835 --- loss: 0.051095\n",
      "tensor([0.0022], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1838 --- loss: 0.002215\n",
      "tensor([9.9291e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1840 --- loss: 0.000099\n",
      "tensor([1.5193e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1843 --- loss: 0.000002\n",
      "tensor([4.2295e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1845 --- loss: 0.000042\n",
      "tensor([6.5511e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1848 --- loss: 0.000066\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1850 --- loss: 0.000155\n",
      "tensor([0.9973], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1853 --- loss: 0.002658\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1855 --- loss: 0.000172\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1858 --- loss: 0.000489\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1860 --- loss: 0.000191\n",
      "tensor([0.0171], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1863 --- loss: 0.017283\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1866 --- loss: 0.000224\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1868 --- loss: 0.000019\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1871 --- loss: 0.000048\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1873 --- loss: 0.000023\n",
      "tensor([0.0026], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1876 --- loss: 0.002645\n",
      "tensor([2.1250e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1878 --- loss: 0.000002\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1881 --- loss: 0.000261\n",
      "tensor([0.9958], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1883 --- loss: 0.004180\n",
      "tensor([0.9985], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1886 --- loss: 0.001526\n",
      "tensor([0.0023], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1888 --- loss: 0.002295\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1891 --- loss: 0.000710\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1893 --- loss: 0.000100\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1896 --- loss: 0.000075\n",
      "tensor([8.9322e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1898 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1901 --- loss: 0.000063\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1903 --- loss: 0.000085\n",
      "tensor([1.4916e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1906 --- loss: 0.000015\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1908 --- loss: 0.000118\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1911 --- loss: 0.000122\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1914 --- loss: 0.000469\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1916 --- loss: 0.000002\n",
      "tensor([0.0023], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1919 --- loss: 0.002257\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1921 --- loss: 0.000003\n",
      "tensor([0.9952], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1924 --- loss: 0.004814\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1926 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1929 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1931 --- loss: 0.000006\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1934 --- loss: 0.000646\n",
      "tensor([0.0049], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1936 --- loss: 0.004952\n",
      "tensor([1.3287e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1939 --- loss: 0.000013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0039], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1941 --- loss: 0.003872\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1944 --- loss: 0.000406\n",
      "tensor([8.8694e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1946 --- loss: 0.000000\n",
      "tensor([0.0213], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1949 --- loss: 0.021521\n",
      "tensor([0.0028], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1951 --- loss: 0.002813\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1954 --- loss: 0.000025\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1957 --- loss: 0.000023\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1959 --- loss: 0.000178\n",
      "tensor([0.0143], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1962 --- loss: 0.014425\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1964 --- loss: 0.000175\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1967 --- loss: 0.000247\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1969 --- loss: 0.000021\n",
      "tensor([0.0880], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1972 --- loss: 0.092110\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1974 --- loss: 0.000995\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1977 --- loss: 0.000379\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1979 --- loss: 0.000108\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1982 --- loss: 0.000027\n",
      "tensor([0.0153], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1984 --- loss: 0.015383\n",
      "tensor([1.3653e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1987 --- loss: 0.000014\n",
      "tensor([0.0057], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1989 --- loss: 0.005710\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1992 --- loss: 0.000273\n",
      "tensor([2.0587e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1994 --- loss: 0.000021\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1997 --- loss: 0.000186\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1999 --- loss: 0.000020\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2002 --- loss: 0.000408\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2005 --- loss: 0.000397\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2007 --- loss: 0.000738\n",
      "tensor([1.7356e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2010 --- loss: 0.000017\n",
      "tensor([1.8183e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2012 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2015 --- loss: 0.000007\n",
      "tensor([6.8620e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2017 --- loss: 0.000007\n",
      "tensor([0.0046], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2020 --- loss: 0.004659\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2022 --- loss: 0.000133\n",
      "tensor([2.1116e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2025 --- loss: 0.000021\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2027 --- loss: 0.000143\n",
      "tensor([3.8097e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2030 --- loss: 0.000000\n",
      "tensor([1.4565e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2032 --- loss: 0.000015\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2035 --- loss: 0.000180\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2037 --- loss: 0.000235\n",
      "tensor([0.9966], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2040 --- loss: 0.003422\n",
      "tensor([9.6836e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2042 --- loss: 0.000010\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2045 --- loss: 0.000157\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2048 --- loss: 0.000095\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2050 --- loss: 0.000229\n",
      "tensor([0.0769], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2053 --- loss: 0.079995\n",
      "tensor([1.4816e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2055 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2058 --- loss: 0.000094\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2060 --- loss: 0.000120\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2063 --- loss: 0.000020\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2065 --- loss: 0.000151\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2068 --- loss: 0.000205\n",
      "tensor([2.4835e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2070 --- loss: 0.000025\n",
      "tensor([1.0544e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2073 --- loss: 0.000011\n",
      "tensor([9.8674e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2075 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2078 --- loss: 0.000016\n",
      "tensor([0.0060], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2080 --- loss: 0.006059\n",
      "tensor([4.6950e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2083 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2085 --- loss: 0.000151\n",
      "tensor([0.9832], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2088 --- loss: 0.016938\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2090 --- loss: 0.000029\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2093 --- loss: 0.000001\n",
      "tensor([8.5726e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2096 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2098 --- loss: 0.000093\n",
      "tensor([4.1269e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2101 --- loss: 0.000041\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2103 --- loss: 0.000016\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2106 --- loss: 0.000106\n",
      "tensor([3.6377e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2108 --- loss: 0.000004\n",
      "tensor([0.0025], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2111 --- loss: 0.002512\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2113 --- loss: 0.000696\n",
      "tensor([8.7156e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2116 --- loss: 0.000009\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2118 --- loss: 0.000151\n",
      "tensor([4.8142e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2121 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2123 --- loss: 0.000003\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2126 --- loss: 0.000156\n",
      "tensor([8.1252e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2128 --- loss: 0.000000\n",
      "tensor([0.8593], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2131 --- loss: 0.151589\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2133 --- loss: 0.000051\n",
      "tensor([1.8670e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2136 --- loss: 0.000019\n",
      "tensor([0.8282], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2139 --- loss: 0.188441\n",
      "tensor([2.0849e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2141 --- loss: 0.000000\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2144 --- loss: 0.000524\n",
      "tensor([0.7458], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2146 --- loss: 0.293284\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2149 --- loss: 0.000239\n",
      "tensor([1.1881e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2151 --- loss: 0.000001\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2154 --- loss: 0.000151\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2156 --- loss: 0.000210\n",
      "tensor([0.9506], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2159 --- loss: 3.006856\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2161 --- loss: 0.000000\n",
      "tensor([0.0032], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2164 --- loss: 0.003218\n",
      "tensor([5.8463e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2166 --- loss: 0.000006\n",
      "tensor([7.9892e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2169 --- loss: 0.000000\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2171 --- loss: 0.000632\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2174 --- loss: 0.000289\n",
      "tensor([0.0177], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2176 --- loss: 0.017860\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2179 --- loss: 0.000056\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2181 --- loss: 0.000356\n",
      "tensor([0.9553], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2184 --- loss: 0.045764\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2187 --- loss: 0.000149\n",
      "tensor([0.9979], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2189 --- loss: 0.002088\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2192 --- loss: 0.000133\n",
      "tensor([0.0052], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2194 --- loss: 5.252350\n",
      "tensor([0.9950], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2197 --- loss: 0.004964\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2199 --- loss: 0.000024\n",
      "tensor([0.9956], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2202 --- loss: 0.004370\n",
      "tensor([1.1982e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2204 --- loss: 0.000012\n",
      "tensor([0.9951], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2207 --- loss: 0.004948\n",
      "tensor([0.1445], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2209 --- loss: 0.156044\n",
      "tensor([1.4059e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2212 --- loss: 0.000001\n",
      "tensor([0.0075], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2214 --- loss: 0.007478\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2217 --- loss: 0.000892\n",
      "tensor([2.5230e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2219 --- loss: 0.000000\n",
      "tensor([0.2224], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2222 --- loss: 0.251604\n",
      "tensor([9.2782e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2224 --- loss: 0.000001\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2227 --- loss: 0.000100\n",
      "tensor([1.1862e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2230 --- loss: 0.000001\n",
      "tensor([0.0019], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2232 --- loss: 0.001925\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2235 --- loss: 0.000809\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2237 --- loss: 0.000653\n",
      "tensor([0.9961], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2240 --- loss: 0.003870\n",
      "tensor([3.0546e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2242 --- loss: 0.000003\n",
      "tensor([2.4655e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2245 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2247 --- loss: 0.000010\n",
      "tensor([7.1568e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2250 --- loss: 0.000007\n",
      "tensor([0.0088], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2252 --- loss: 0.008802\n",
      "tensor([8.6316e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2255 --- loss: 0.000001\n",
      "tensor([0.9987], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2257 --- loss: 0.001300\n",
      "tensor([1.8557e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2260 --- loss: 0.000002\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2262 --- loss: 0.000753\n",
      "tensor([0.9931], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2265 --- loss: 0.006955\n",
      "tensor([0.9945], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2267 --- loss: 0.005530\n",
      "tensor([0.0021], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2270 --- loss: 0.002076\n",
      "tensor([0.0039], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2272 --- loss: 0.003885\n",
      "tensor([0.9975], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2275 --- loss: 0.002524\n",
      "tensor([0.0023], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2278 --- loss: 0.002282\n",
      "tensor([0.9888], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2280 --- loss: 0.011286\n",
      "tensor([2.9746e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2283 --- loss: 0.000030\n",
      "tensor([0.0012], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2285 --- loss: 0.001170\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2288 --- loss: 0.000192\n",
      "tensor([2.4950e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2290 --- loss: 0.000002\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2293 --- loss: 0.001094\n",
      "tensor([0.0058], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2295 --- loss: 0.005793\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2298 --- loss: 0.000242\n",
      "tensor([0.3763], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2300 --- loss: 0.977285\n",
      "tensor([0.0186], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2303 --- loss: 0.018791\n",
      "tensor([0.0067], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2305 --- loss: 0.006718\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2308 --- loss: 0.000580\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2310 --- loss: 0.000217\n",
      "tensor([0.0009], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2313 --- loss: 0.000853\n",
      "tensor([0.0535], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2315 --- loss: 0.055003\n",
      "tensor([1.7214e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2318 --- loss: 0.000017\n",
      "tensor([0.4158], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2321 --- loss: 0.537432\n",
      "tensor([0.9980], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2323 --- loss: 0.001962\n",
      "tensor([1.5773e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2326 --- loss: 0.000016\n",
      "tensor([0.0169], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2328 --- loss: 0.017001\n",
      "tensor([0.0028], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2331 --- loss: 0.002797\n",
      "tensor([0.0011], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2333 --- loss: 0.001074\n",
      "tensor([0.9964], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2336 --- loss: 0.003564\n",
      "tensor([0.3989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2338 --- loss: 0.508957\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2341 --- loss: 0.000629\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2343 --- loss: 0.000201\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2346 --- loss: 0.000006\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2348 --- loss: 0.001590\n",
      "tensor([0.9547], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2351 --- loss: 0.046394\n",
      "tensor([0.0057], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2353 --- loss: 0.005672\n",
      "tensor([0.8639], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2356 --- loss: 0.146353\n",
      "tensor([0.0336], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2358 --- loss: 0.034200\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2361 --- loss: 0.000691\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2363 --- loss: 0.000175\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2366 --- loss: 0.000138\n",
      "tensor([1.4368e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2369 --- loss: 0.000000\n",
      "tensor([0.0347], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2371 --- loss: 0.035351\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2374 --- loss: 0.000735\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2376 --- loss: 0.000165\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2379 --- loss: 0.000246\n",
      "tensor([5.1847e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2381 --- loss: 0.000005\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2384 --- loss: 0.000371\n",
      "tensor([0.0009], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2386 --- loss: 0.000855\n",
      "tensor([9.2405e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2389 --- loss: 0.000000\n",
      "tensor([0.0210], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2391 --- loss: 0.021197\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2394 --- loss: 0.000977\n",
      "tensor([0.0023], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2396 --- loss: 0.002262\n",
      "tensor([0.0160], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2399 --- loss: 0.016157\n",
      "tensor([0.0024], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2401 --- loss: 0.002440\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2404 --- loss: 0.000509\n",
      "tensor([1.3665e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2406 --- loss: 0.000001\n",
      "tensor([1.5647e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2409 --- loss: 0.000016\n",
      "tensor([1.8129e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2412 --- loss: 0.000002\n",
      "tensor([6.5046e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2414 --- loss: 0.000007\n",
      "tensor([8.0929e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2417 --- loss: 0.000081\n",
      "tensor([0.9983], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2419 --- loss: 0.001702\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2422 --- loss: 0.000308\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2424 --- loss: 0.000223\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2427 --- loss: 0.001071\n",
      "tensor([0.9987], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2429 --- loss: 0.001260\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2432 --- loss: 0.000501\n",
      "tensor([3.0858e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2434 --- loss: 0.000031\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2437 --- loss: 0.000133\n",
      "tensor([0.0018], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2439 --- loss: 0.001842\n",
      "tensor([0.8934], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2442 --- loss: 0.112757\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2444 --- loss: 0.000076\n",
      "tensor([5.2263e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2447 --- loss: 0.000052\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2449 --- loss: 0.000292\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2452 --- loss: 0.000033\n",
      "tensor([0.9979], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2454 --- loss: 0.002053\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2457 --- loss: 0.000150\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2460 --- loss: 0.000006\n",
      "tensor([7.4475e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2462 --- loss: 0.000007\n",
      "tensor([0.0066], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2465 --- loss: 0.006591\n",
      "tensor([1.8822e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2467 --- loss: 0.000000\n",
      "tensor([6.7925e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2470 --- loss: 0.000007\n",
      "tensor([4.7381e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2472 --- loss: 0.000000\n",
      "tensor([0.0039], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2475 --- loss: 0.003863\n",
      "tensor([7.4590e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2477 --- loss: 0.000075\n",
      "tensor([0.0032], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2480 --- loss: 0.003232\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2482 --- loss: 0.000027\n",
      "tensor([5.6908e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2485 --- loss: 0.000006\n",
      "tensor([0.0016], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2487 --- loss: 0.001601\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2490 --- loss: 0.000158\n",
      "tensor([6.6511e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2492 --- loss: 0.000000\n",
      "tensor([9.9610e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2495 --- loss: 0.000000\n",
      "tensor([3.4074e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2497 --- loss: 0.000000\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2500 --- loss: 0.001216\n",
      "tensor([0.9703], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2503 --- loss: 0.030132\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2505 --- loss: 0.000101\n",
      "tensor([0.0028], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2508 --- loss: 0.002755\n",
      "tensor([0.0738], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2510 --- loss: 0.076632\n",
      "tensor([0.6120], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2513 --- loss: 0.946842\n",
      "tensor([0.9830], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2515 --- loss: 0.017174\n",
      "tensor([0.0103], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2518 --- loss: 0.010314\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2520 --- loss: 0.000096\n",
      "tensor([4.2114e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2523 --- loss: 0.000004\n",
      "tensor([3.4799e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2525 --- loss: 0.000035\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2528 --- loss: 0.000141\n",
      "tensor([0.0101], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2530 --- loss: 0.010186\n",
      "tensor([0.9952], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2533 --- loss: 0.004836\n",
      "tensor([6.2366e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2535 --- loss: 0.000000\n",
      "tensor([0.9985], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2538 --- loss: 0.001513\n",
      "tensor([4.9079e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2540 --- loss: 0.000005\n",
      "tensor([0.9902], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2543 --- loss: 0.009892\n",
      "tensor([0.9953], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2546 --- loss: 0.004738\n",
      "tensor([0.9814], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2548 --- loss: 0.018763\n",
      "tensor([1.9536e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2551 --- loss: 0.000000\n",
      "tensor([6.5631e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2553 --- loss: 0.000001\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2556 --- loss: 0.000224\n",
      "tensor([2.3083e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2558 --- loss: 0.000000\n",
      "tensor([0.9985], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2561 --- loss: 0.001514\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2563 --- loss: 0.000191\n",
      "tensor([1.6907e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2566 --- loss: 0.000017\n",
      "tensor([9.2811e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2568 --- loss: 0.000093\n",
      "tensor([5.0420e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2571 --- loss: 0.000001\n",
      "tensor([3.2219e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2573 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2576 --- loss: 0.000083\n",
      "tensor([1.5010e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2578 --- loss: 0.000015\n",
      "tensor([0.0022], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2581 --- loss: 0.002250\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2583 --- loss: 0.001098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2586 --- loss: 0.001217\n",
      "tensor([1.0045e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2588 --- loss: 0.000010\n",
      "tensor([0.9967], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2591 --- loss: 0.003313\n",
      "tensor([2.2965e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2594 --- loss: 0.000000\n",
      "tensor([1.1090e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2596 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2599 --- loss: 0.000291\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2601 --- loss: 0.001077\n",
      "tensor([5.9873e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2604 --- loss: 0.000060\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2606 --- loss: 0.000013\n",
      "tensor([6.5097e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2609 --- loss: 0.000001\n",
      "tensor([9.6578e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2611 --- loss: 0.000097\n",
      "tensor([0.9776], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2614 --- loss: 0.022638\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2616 --- loss: 0.000387\n",
      "tensor([3.1315e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2619 --- loss: 0.000000\n",
      "tensor([0.9476], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2621 --- loss: 0.053854\n",
      "tensor([0.9963], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2624 --- loss: 0.003711\n",
      "tensor([0.0009], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2626 --- loss: 0.000946\n",
      "tensor([0.9703], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2629 --- loss: 0.030168\n",
      "tensor([0.9927], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2631 --- loss: 0.007281\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2634 --- loss: 0.000089\n",
      "tensor([8.5462e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2637 --- loss: 0.000085\n",
      "tensor([3.5996e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2639 --- loss: 0.000000\n",
      "tensor([0.0009], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2642 --- loss: 0.000852\n",
      "tensor([0.9955], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2644 --- loss: 0.004483\n",
      "tensor([6.3835e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2647 --- loss: 0.000000\n",
      "tensor([1.3929e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2649 --- loss: 0.000000\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2652 --- loss: 0.000581\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2654 --- loss: 0.000354\n",
      "tensor([7.8623e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2657 --- loss: 0.000079\n",
      "tensor([5.5474e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2659 --- loss: 0.000055\n",
      "tensor([0.9847], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2662 --- loss: 0.015467\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2664 --- loss: 0.001580\n",
      "tensor([3.2265e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2667 --- loss: 0.000032\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2669 --- loss: 0.000608\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2672 --- loss: 0.001073\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2674 --- loss: 0.000260\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2677 --- loss: 0.000011\n",
      "tensor([0.9676], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2679 --- loss: 0.032904\n",
      "tensor([6.1879e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2682 --- loss: 0.000001\n",
      "tensor([0.9861], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2685 --- loss: 0.014031\n",
      "tensor([0.9987], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2687 --- loss: 0.001284\n",
      "tensor([9.3730e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2690 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2692 --- loss: 0.000317\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2695 --- loss: 0.000007\n",
      "tensor([4.9967e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2697 --- loss: 0.000000\n",
      "tensor([2.0607e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2700 --- loss: 0.000021\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2702 --- loss: 0.000291\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2705 --- loss: 0.000815\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2707 --- loss: 0.000125\n",
      "tensor([0.0016], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2710 --- loss: 0.001630\n",
      "tensor([5.6579e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2712 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2715 --- loss: 0.000014\n",
      "tensor([3.5367e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2717 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2720 --- loss: 0.000118\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2722 --- loss: 0.000013\n",
      "tensor([4.4479e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2725 --- loss: 0.000044\n",
      "tensor([0.0020], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2728 --- loss: 0.001999\n",
      "tensor([0.0030], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2730 --- loss: 0.003020\n",
      "tensor([0.9986], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2733 --- loss: 0.001432\n",
      "tensor([0.0207], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2735 --- loss: 0.020923\n",
      "tensor([8.2810e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2738 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2740 --- loss: 0.000019\n",
      "tensor([0.0134], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2743 --- loss: 0.013493\n",
      "tensor([1.1977e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2745 --- loss: 0.000001\n",
      "tensor([6.2157e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2748 --- loss: 0.000000\n",
      "tensor([6.2528e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2750 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2753 --- loss: 0.000013\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2755 --- loss: 0.000012\n",
      "tensor([1.3863e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2758 --- loss: 0.000014\n",
      "tensor([1.3023e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2760 --- loss: 0.000000\n",
      "tensor([0.0340], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2763 --- loss: 0.034616\n",
      "tensor([8.3129e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2765 --- loss: 0.000008\n",
      "tensor([0.9038], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2768 --- loss: 0.101171\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2770 --- loss: 0.000047\n",
      "tensor([0.0201], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2773 --- loss: 0.020306\n",
      "tensor([1.8200e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2776 --- loss: 0.000018\n",
      "tensor([2.9935e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2778 --- loss: 0.000030\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2781 --- loss: 0.000409\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2783 --- loss: 0.000438\n",
      "tensor([4.0198e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2786 --- loss: 0.000000\n",
      "tensor([3.5126e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2788 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2791 --- loss: 0.000007\n",
      "tensor([4.5109e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2793 --- loss: 0.000000\n",
      "tensor([4.3690e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2796 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2798 --- loss: 0.000099\n",
      "tensor([8.3267e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2801 --- loss: 0.000083\n",
      "tensor([0.9954], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2803 --- loss: 0.004601\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2806 --- loss: 0.000586\n",
      "tensor([3.7863e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2808 --- loss: 0.000000\n",
      "tensor([5.3944e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2811 --- loss: 0.000054\n",
      "tensor([7.5517e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2813 --- loss: 0.000000\n",
      "tensor([4.7931e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2816 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2819 --- loss: 0.000139\n",
      "tensor([0.9720], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2821 --- loss: 0.028421\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2824 --- loss: 0.000470\n",
      "tensor([2.3469e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2826 --- loss: 0.000002\n",
      "tensor([3.5568e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2829 --- loss: 0.000000\n",
      "tensor([0.9947], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2831 --- loss: 0.005356\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2834 --- loss: 0.000230\n",
      "tensor([0.9983], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2836 --- loss: 0.001726\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2839 --- loss: 0.000415\n",
      "tensor([0.0041], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2841 --- loss: 0.004132\n",
      "tensor([2.8597e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2844 --- loss: 0.000029\n",
      "tensor([0.0018], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2846 --- loss: 0.001788\n",
      "tensor([2.2035e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2849 --- loss: 0.000022\n",
      "tensor([9.1708e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2851 --- loss: 0.000092\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2854 --- loss: 0.000029\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2856 --- loss: 0.000093\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2859 --- loss: 0.000845\n",
      "tensor([5.2869e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2861 --- loss: 0.000000\n",
      "tensor([2.0179e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2864 --- loss: 0.000020\n",
      "tensor([3.7933e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2867 --- loss: 0.000000\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2869 --- loss: 0.000414\n",
      "tensor([1.4970e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2872 --- loss: 0.000000\n",
      "tensor([2.6988e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2874 --- loss: 0.000000\n",
      "tensor([0.9990], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2877 --- loss: 0.001015\n",
      "tensor([0.0011], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2879 --- loss: 0.001124\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2882 --- loss: 0.000102\n",
      "tensor([1.0911e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2884 --- loss: 0.000011\n",
      "tensor([1.1811e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2887 --- loss: 0.000001\n",
      "tensor([3.5143e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2889 --- loss: 0.000004\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2892 --- loss: 0.001014\n",
      "tensor([9.3076e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2894 --- loss: 0.000093\n",
      "tensor([3.9451e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2897 --- loss: 0.000039\n",
      "tensor([0.9978], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2899 --- loss: 0.002250\n",
      "tensor([0.0051], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2902 --- loss: 0.005091\n",
      "tensor([0.0016], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2904 --- loss: 0.001634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0025], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2907 --- loss: 0.002507\n",
      "tensor([3.1622e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2910 --- loss: 0.000000\n",
      "tensor([5.9970e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2912 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2915 --- loss: 0.000250\n",
      "tensor([3.4067e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2917 --- loss: 0.000000\n",
      "tensor([2.4221e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2920 --- loss: 0.000024\n",
      "tensor([0.9979], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2922 --- loss: 0.002081\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2925 --- loss: 0.000623\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2927 --- loss: 0.000138\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2930 --- loss: 0.001209\n",
      "tensor([3.6876e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2932 --- loss: 0.000000\n",
      "tensor([0.9964], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2935 --- loss: 0.003608\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2937 --- loss: 0.000004\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2940 --- loss: 0.000102\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2942 --- loss: 0.001078\n",
      "tensor([1.8943e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2945 --- loss: 0.000019\n",
      "tensor([2.6831e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2947 --- loss: 0.000003\n",
      "tensor([3.7892e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2950 --- loss: 0.000038\n",
      "tensor([1.2281e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2952 --- loss: 0.000012\n",
      "tensor([0.9980], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2955 --- loss: 0.002025\n",
      "tensor([7.1226e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2958 --- loss: 0.000000\n",
      "tensor([0.9560], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2960 --- loss: 0.045026\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2963 --- loss: 0.000241\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2965 --- loss: 0.000003\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2968 --- loss: 0.000263\n",
      "tensor([0.0072], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2970 --- loss: 0.007186\n",
      "tensor([6.0443e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2973 --- loss: 0.000060\n",
      "tensor([4.2538e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2975 --- loss: 0.000043\n",
      "tensor([8.3599e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2978 --- loss: 0.000001\n",
      "tensor([2.5948e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2980 --- loss: 0.000026\n",
      "tensor([3.5543e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2983 --- loss: 0.000000\n",
      "tensor([5.0780e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2985 --- loss: 0.000005\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2988 --- loss: 0.000764\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2990 --- loss: 0.000213\n",
      "tensor([2.7565e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2993 --- loss: 0.000028\n",
      "tensor([2.3462e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2995 --- loss: 0.000023\n",
      "tensor([5.9784e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2998 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3001 --- loss: 0.000017\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3003 --- loss: 0.000028\n",
      "tensor([0.0072], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3006 --- loss: 0.007242\n",
      "tensor([1.3802e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3008 --- loss: 0.000001\n",
      "tensor([7.7879e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3011 --- loss: 0.000000\n",
      "tensor([1.8822e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3013 --- loss: 0.000019\n",
      "tensor([0.9981], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3016 --- loss: 0.001895\n",
      "tensor([6.7935e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3018 --- loss: 0.000001\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3021 --- loss: 0.000494\n",
      "tensor([4.3053e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3023 --- loss: 0.000000\n",
      "tensor([0.0134], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3026 --- loss: 0.013467\n",
      "tensor([2.7615e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3028 --- loss: 0.000000\n",
      "tensor([1.8757e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3031 --- loss: 0.000019\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3033 --- loss: 0.000089\n",
      "tensor([1.0099e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3036 --- loss: 0.000000\n",
      "tensor([1.3133e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3038 --- loss: 0.000013\n",
      "tensor([1.5162e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3041 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3043 --- loss: 0.000088\n",
      "tensor([0.9986], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3046 --- loss: 0.001366\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3049 --- loss: 0.000351\n",
      "tensor([3.5717e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3051 --- loss: 0.000000\n",
      "tensor([4.5029e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3054 --- loss: 0.000005\n",
      "tensor([1.1712e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3056 --- loss: 0.000000\n",
      "tensor([8.9749e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3059 --- loss: 0.000000\n",
      "tensor([2.7664e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3061 --- loss: 0.000003\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3064 --- loss: 0.000069\n",
      "tensor([7.2625e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3066 --- loss: 0.000000\n",
      "tensor([1.7211e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3069 --- loss: 0.000000\n",
      "tensor([1.9662e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3071 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3074 --- loss: 0.000026\n",
      "tensor([0.0038], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3076 --- loss: 0.003796\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3079 --- loss: 0.000051\n",
      "tensor([0.0043], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3081 --- loss: 0.004306\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3084 --- loss: 0.000059\n",
      "tensor([4.6409e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3086 --- loss: 0.000046\n",
      "tensor([5.9828e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3089 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3092 --- loss: 0.000084\n",
      "tensor([5.0987e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3094 --- loss: 0.000001\n",
      "tensor([5.9184e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3097 --- loss: 0.000001\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3099 --- loss: 0.000126\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3102 --- loss: 0.000386\n",
      "tensor([1.4593e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3104 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3107 --- loss: 0.000003\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3109 --- loss: 0.000484\n",
      "tensor([0.9976], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3112 --- loss: 0.002365\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3114 --- loss: 0.000021\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3117 --- loss: 0.000153\n",
      "tensor([4.9434e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3119 --- loss: 0.000049\n",
      "tensor([7.0592e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3122 --- loss: 0.000001\n",
      "tensor([0.9981], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3124 --- loss: 0.001943\n",
      "tensor([6.8012e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3127 --- loss: 0.000007\n",
      "tensor([0.9983], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3129 --- loss: 0.001677\n",
      "tensor([0.0016], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3132 --- loss: 0.001648\n",
      "tensor([0.0011], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3134 --- loss: 0.001081\n",
      "tensor([1.0750e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3137 --- loss: 0.000011\n",
      "tensor([8.7381e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3140 --- loss: 0.000000\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3142 --- loss: 0.000348\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3145 --- loss: 0.000204\n",
      "tensor([9.2276e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3147 --- loss: 0.000001\n",
      "tensor([3.4889e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3150 --- loss: 0.000035\n",
      "tensor([5.2790e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3152 --- loss: 0.000001\n",
      "tensor([1.9360e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3155 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3157 --- loss: 0.000008\n",
      "tensor([0.0014], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3160 --- loss: 0.001388\n",
      "tensor([0.1834], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3162 --- loss: 0.202664\n",
      "tensor([0.9915], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3165 --- loss: 0.008581\n",
      "tensor([6.3866e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3167 --- loss: 0.000000\n",
      "tensor([0.9939], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3170 --- loss: 0.006103\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3172 --- loss: 0.000179\n",
      "tensor([5.0039e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3175 --- loss: 0.000050\n",
      "tensor([0.9941], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3177 --- loss: 5.132064\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3180 --- loss: 0.000241\n",
      "tensor([1.9918e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3183 --- loss: 0.000000\n",
      "tensor([6.2634e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3185 --- loss: 0.000006\n",
      "tensor([0.0009], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3188 --- loss: 0.000877\n",
      "tensor([0.9237], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3190 --- loss: 0.079419\n",
      "tensor([0.8259], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3193 --- loss: 0.191314\n",
      "tensor([2.1874e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3195 --- loss: 0.000002\n",
      "tensor([3.4937e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3198 --- loss: 0.000000\n",
      "tensor([1.8239e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3200 --- loss: 0.000000\n",
      "tensor([0.8912], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3203 --- loss: 0.115217\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3205 --- loss: 0.000828\n",
      "tensor([2.0004e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3208 --- loss: 0.000020\n",
      "tensor([0.0026], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3210 --- loss: 0.002579\n",
      "tensor([0.9980], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3213 --- loss: 0.002007\n",
      "tensor([9.6211e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3215 --- loss: 0.000096\n",
      "tensor([5.4111e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3218 --- loss: 0.000001\n",
      "tensor([0.9437], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3220 --- loss: 0.057960\n",
      "tensor([2.3550e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3223 --- loss: 0.000024\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3225 --- loss: 0.000120\n",
      "tensor([1.5825e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3228 --- loss: 0.000000\n",
      "tensor([0.9855], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3231 --- loss: 0.014617\n",
      "tensor([1.4853e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3233 --- loss: 0.000015\n",
      "tensor([3.5353e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3236 --- loss: 0.000004\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3238 --- loss: 0.000281\n",
      "tensor([4.6609e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3241 --- loss: 0.000005\n",
      "tensor([2.5299e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3243 --- loss: 0.000025\n",
      "tensor([0.9195], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3246 --- loss: 0.083975\n",
      "tensor([6.4086e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3248 --- loss: 0.000006\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3251 --- loss: 0.000713\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3253 --- loss: 0.000824\n",
      "tensor([6.7059e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3256 --- loss: 0.000067\n",
      "tensor([1.9167e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3258 --- loss: 0.000000\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3261 --- loss: 0.000862\n",
      "tensor([2.3508e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3263 --- loss: 0.000000\n",
      "tensor([2.7771e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3266 --- loss: 0.000000\n",
      "tensor([3.0792e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3268 --- loss: 0.000003\n",
      "tensor([8.8502e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3271 --- loss: 0.000089\n",
      "tensor([1.2170e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3274 --- loss: 0.000012\n",
      "tensor([2.2488e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3276 --- loss: 0.000022\n",
      "tensor([0.9183], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3279 --- loss: 0.085266\n",
      "tensor([4.9542e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3281 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3284 --- loss: 0.000142\n",
      "tensor([5.7051e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3286 --- loss: 0.000000\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3289 --- loss: 0.000554\n",
      "tensor([0.0012], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3291 --- loss: 0.001234\n",
      "tensor([2.2479e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3294 --- loss: 0.000022\n",
      "tensor([2.6567e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3296 --- loss: 0.000003\n",
      "tensor([2.3425e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3299 --- loss: 0.000023\n",
      "tensor([0.8394], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3301 --- loss: 0.175014\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3304 --- loss: 0.001009\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3306 --- loss: 0.000076\n",
      "tensor([1.6720e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3309 --- loss: 0.000002\n",
      "tensor([0.0046], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3311 --- loss: 0.004608\n",
      "tensor([5.0883e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3314 --- loss: 0.000000\n",
      "tensor([0.0060], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3316 --- loss: 0.006066\n",
      "tensor([4.6237e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3319 --- loss: 0.000005\n",
      "tensor([5.3030e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3322 --- loss: 0.000001\n",
      "tensor([6.7833e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3324 --- loss: 0.000001\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3327 --- loss: 0.000216\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3329 --- loss: 0.000189\n",
      "tensor([0.0050], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3332 --- loss: 0.005011\n",
      "tensor([0.5860], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3334 --- loss: 0.881818\n",
      "tensor([3.8386e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3337 --- loss: 0.000038\n",
      "tensor([0.0075], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3339 --- loss: 0.007481\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3342 --- loss: 0.000292\n",
      "tensor([2.8481e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3344 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3347 --- loss: 0.000036\n",
      "tensor([3.9993e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3349 --- loss: 0.000004\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3352 --- loss: 0.000094\n",
      "tensor([0.9975], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3354 --- loss: 0.002474\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3357 --- loss: 0.000300\n",
      "tensor([4.9442e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3359 --- loss: 0.000049\n",
      "tensor([2.0624e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3362 --- loss: 0.000000\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3365 --- loss: 0.000822\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3367 --- loss: 0.000115\n",
      "tensor([1.0741e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3370 --- loss: 0.000001\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3372 --- loss: 0.000185\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3375 --- loss: 0.000120\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3377 --- loss: 0.000180\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3380 --- loss: 0.000915\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3382 --- loss: 0.000308\n",
      "tensor([3.3635e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3385 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3387 --- loss: 0.000175\n",
      "tensor([0.9088], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3390 --- loss: 0.095624\n",
      "tensor([3.8145e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3392 --- loss: 0.000000\n",
      "tensor([0.9706], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3395 --- loss: 0.029866\n",
      "tensor([0.9752], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3397 --- loss: 0.025073\n",
      "tensor([0.9120], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3400 --- loss: 0.092074\n",
      "tensor([0.3618], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3402 --- loss: 1.016620\n",
      "tensor([1.0339e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3405 --- loss: 0.000010\n",
      "tensor([1.3121e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3407 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3410 --- loss: 0.000058\n",
      "tensor([4.7869e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3413 --- loss: 0.000048\n",
      "tensor([5.8160e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3415 --- loss: 0.000058\n",
      "tensor([0.9966], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3418 --- loss: 0.003375\n",
      "tensor([7.1981e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3420 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3423 --- loss: 0.000027\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3425 --- loss: 0.000654\n",
      "tensor([7.1469e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3428 --- loss: 0.000000\n",
      "tensor([0.9946], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3430 --- loss: 0.005437\n",
      "tensor([0.0077], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3433 --- loss: 0.007763\n",
      "tensor([0.0013], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3435 --- loss: 0.001290\n",
      "tensor([7.7951e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3438 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3440 --- loss: 0.000205\n",
      "tensor([5.1259e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3443 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3445 --- loss: 0.000007\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3448 --- loss: 0.000345\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3450 --- loss: 0.000000\n",
      "tensor([1.6205e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3453 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3456 --- loss: 0.000008\n",
      "tensor([1.7043e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3458 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3461 --- loss: 0.000104\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3463 --- loss: 0.000011\n",
      "tensor([0.0030], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3466 --- loss: 0.002974\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3468 --- loss: 0.000448\n",
      "tensor([1.1304e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3471 --- loss: 0.000001\n",
      "tensor([2.7351e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3473 --- loss: 0.000027\n",
      "tensor([0.0077], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3476 --- loss: 0.007737\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3478 --- loss: 0.000113\n",
      "tensor([3.2361e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3481 --- loss: 0.000003\n",
      "tensor([4.6146e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3483 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3486 --- loss: 0.000153\n",
      "tensor([8.3244e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3488 --- loss: 0.000008\n",
      "tensor([7.5107e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3491 --- loss: 0.000008\n",
      "tensor([5.3644e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3493 --- loss: 0.000001\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3496 --- loss: 0.000615\n",
      "tensor([0.0071], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3498 --- loss: 0.007166\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3501 --- loss: 0.000488\n",
      "tensor([3.3007e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3504 --- loss: 0.000003\n",
      "tensor([4.8387e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3506 --- loss: 0.000005\n",
      "tensor([4.9716e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3509 --- loss: 0.000000\n",
      "tensor([2.0320e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3511 --- loss: 0.000000\n",
      "tensor([0.0101], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3514 --- loss: 0.010168\n",
      "tensor([0.0053], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3516 --- loss: 0.005342\n",
      "tensor([0.0039], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3519 --- loss: 0.003916\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3521 --- loss: 0.000034\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3524 --- loss: 0.000058\n",
      "tensor([0.0129], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3526 --- loss: 0.013012\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3529 --- loss: 0.000087\n",
      "tensor([0.0009], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3531 --- loss: 0.000875\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3534 --- loss: 0.000162\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3536 --- loss: 0.000030\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3539 --- loss: 0.000279\n",
      "tensor([0.9987], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3541 --- loss: 6.647254\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3544 --- loss: 0.000117\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3547 --- loss: 0.000401\n",
      "tensor([0.0638], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3549 --- loss: 0.065947\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3552 --- loss: 0.000805\n",
      "tensor([3.6602e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3554 --- loss: 0.000037\n",
      "tensor([0.9938], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3557 --- loss: 0.006244\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3559 --- loss: 0.000490\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3562 --- loss: 0.000613\n",
      "tensor([0.0013], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3564 --- loss: 0.001274\n",
      "tensor([0.0031], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3567 --- loss: 0.003118\n",
      "tensor([0.0011], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3569 --- loss: 0.001119\n",
      "tensor([3.6332e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3572 --- loss: 0.000000\n",
      "tensor([2.4801e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3574 --- loss: 0.000000\n",
      "tensor([0.0025], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3577 --- loss: 0.002494\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3579 --- loss: 0.000098\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3582 --- loss: 0.000480\n",
      "tensor([0.9985], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3584 --- loss: 0.001526\n",
      "tensor([0.9977], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3587 --- loss: 0.002259\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3589 --- loss: 0.000332\n",
      "tensor([0.9930], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3592 --- loss: 0.007060\n",
      "tensor([0.9126], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3595 --- loss: 0.091474\n",
      "tensor([0.9623], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3597 --- loss: 0.038417\n",
      "tensor([0.8802], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3600 --- loss: 0.127599\n",
      "tensor([0.8689], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3602 --- loss: 0.140495\n",
      "tensor([0.9967], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3605 --- loss: 0.003280\n",
      "tensor([0.9714], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3607 --- loss: 0.028996\n",
      "tensor([6.9238e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3610 --- loss: 0.000001\n",
      "tensor([6.3070e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3612 --- loss: 0.000006\n",
      "tensor([0.9929], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3615 --- loss: 0.007146\n",
      "tensor([0.9982], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3617 --- loss: 0.001795\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3620 --- loss: 0.000637\n",
      "tensor([0.0021], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3622 --- loss: 0.002129\n",
      "tensor([8.7883e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3625 --- loss: 0.000009\n",
      "tensor([8.5695e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3627 --- loss: 0.000086\n",
      "tensor([0.9927], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3630 --- loss: 0.007365\n",
      "tensor([7.5352e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3632 --- loss: 0.000075\n",
      "tensor([9.0363e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3635 --- loss: 0.000009\n",
      "tensor([3.1723e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3638 --- loss: 0.000003\n",
      "tensor([0.9967], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3640 --- loss: 0.003265\n",
      "tensor([1.0131e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3643 --- loss: 0.000001\n",
      "tensor([0.9969], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3645 --- loss: 0.003082\n",
      "tensor([0.9981], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3648 --- loss: 0.001874\n",
      "tensor([7.8299e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3650 --- loss: 0.000001\n",
      "tensor([0.2381], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3653 --- loss: 0.271896\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3655 --- loss: 0.001605\n",
      "tensor([0.0027], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3658 --- loss: 0.002705\n",
      "tensor([0.0060], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3660 --- loss: 0.005975\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3663 --- loss: 0.000202\n",
      "tensor([1.1597e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3665 --- loss: 0.000012\n",
      "tensor([8.2049e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3668 --- loss: 0.000082\n",
      "tensor([0.0033], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3670 --- loss: 0.003258\n",
      "tensor([6.2910e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3673 --- loss: 0.000063\n",
      "tensor([1.7310e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3675 --- loss: 0.000002\n",
      "tensor([9.6401e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3678 --- loss: 0.000010\n",
      "tensor([0.9887], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3680 --- loss: 0.011411\n",
      "tensor([1.3693e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3683 --- loss: 0.000001\n",
      "tensor([0.9978], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3686 --- loss: 0.002184\n",
      "tensor([0.4160], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3688 --- loss: 0.877100\n",
      "tensor([5.7522e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3691 --- loss: 0.000001\n",
      "tensor([0.0013], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3693 --- loss: 0.001345\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3696 --- loss: 0.001626\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3698 --- loss: 0.000276\n",
      "tensor([0.9981], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3701 --- loss: 0.001905\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3703 --- loss: 0.001621\n",
      "tensor([3.0881e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3706 --- loss: 0.000000\n",
      "tensor([0.0016], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3708 --- loss: 0.001563\n",
      "tensor([0.9930], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3711 --- loss: 0.007032\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3713 --- loss: 0.000129\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3716 --- loss: 0.000233\n",
      "tensor([0.9942], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3718 --- loss: 0.005778\n",
      "tensor([8.5535e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3721 --- loss: 0.000009\n",
      "tensor([0.0016], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3723 --- loss: 0.001559\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3726 --- loss: 0.000271\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3729 --- loss: 0.000549\n",
      "tensor([3.7532e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3731 --- loss: 0.000038\n",
      "tensor([2.5173e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3734 --- loss: 0.000000\n",
      "tensor([3.5463e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3736 --- loss: 0.000035\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3739 --- loss: 0.000144\n",
      "tensor([0.0062], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3741 --- loss: 0.006242\n",
      "tensor([2.4506e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3744 --- loss: 0.000025\n",
      "tensor([5.8359e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3746 --- loss: 0.000006\n",
      "tensor([0.9975], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3749 --- loss: 0.002497\n",
      "tensor([9.4143e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3751 --- loss: 0.000094\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3754 --- loss: 0.000420\n",
      "tensor([0.9970], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3756 --- loss: 0.002971\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3759 --- loss: 0.000912\n",
      "tensor([0.0023], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3761 --- loss: 0.002268\n",
      "tensor([3.3727e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3764 --- loss: 0.000034\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3766 --- loss: 0.000441\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3769 --- loss: 0.000321\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3771 --- loss: 0.000097\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3774 --- loss: 0.000009\n",
      "tensor([4.6082e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3777 --- loss: 0.000000\n",
      "tensor([3.0479e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3779 --- loss: 0.000030\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3782 --- loss: 0.000096\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3784 --- loss: 0.000253\n",
      "tensor([1.6760e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3787 --- loss: 0.000017\n",
      "tensor([0.9975], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3789 --- loss: 0.002527\n",
      "tensor([0.0051], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3792 --- loss: 0.005081\n",
      "tensor([3.0228e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3794 --- loss: 0.000000\n",
      "tensor([0.0552], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3797 --- loss: 0.056807\n",
      "tensor([4.8321e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3799 --- loss: 0.000005\n",
      "tensor([0.0203], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3802 --- loss: 0.020463\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3804 --- loss: 0.000544\n",
      "tensor([0.0135], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3807 --- loss: 0.013605\n",
      "tensor([0.0288], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3809 --- loss: 0.029219\n",
      "tensor([0.0013], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3812 --- loss: 0.001282\n",
      "tensor([0.9987], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3814 --- loss: 0.001256\n",
      "tensor([0.9886], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3817 --- loss: 0.011431\n",
      "tensor([0.0233], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3820 --- loss: 0.023591\n",
      "tensor([0.0038], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3822 --- loss: 0.003824\n",
      "tensor([2.8437e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3825 --- loss: 0.000003\n",
      "tensor([8.8372e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3827 --- loss: 0.000088\n",
      "tensor([1.6636e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3830 --- loss: 0.000002\n",
      "tensor([5.6615e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3832 --- loss: 0.000006\n",
      "tensor([0.9948], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3835 --- loss: 0.005166\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3837 --- loss: 0.000088\n",
      "tensor([3.7229e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3840 --- loss: 0.000000\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3842 --- loss: 0.000840\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3845 --- loss: 0.000213\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3847 --- loss: 0.000744\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3850 --- loss: 0.000228\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3852 --- loss: 0.000317\n",
      "tensor([0.9986], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3855 --- loss: 0.001394\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3857 --- loss: 0.000344\n",
      "tensor([2.0963e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3860 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3862 --- loss: 0.000009\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3865 --- loss: 0.000442\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3868 --- loss: 0.000252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9.9986e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3870 --- loss: 0.000010\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3873 --- loss: 0.000332\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3875 --- loss: 0.001085\n",
      "tensor([3.8576e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3878 --- loss: 0.000004\n",
      "tensor([0.9986], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3880 --- loss: 0.001362\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3883 --- loss: 0.000507\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3885 --- loss: 0.000278\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3888 --- loss: 0.000062\n",
      "tensor([0.0617], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3890 --- loss: 0.063693\n",
      "tensor([3.4724e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3893 --- loss: 0.000000\n",
      "tensor([1.3100e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3895 --- loss: 0.000000\n",
      "tensor([2.5186e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3898 --- loss: 0.000025\n",
      "tensor([0.0408], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3900 --- loss: 0.041631\n",
      "tensor([2.6427e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3903 --- loss: 0.000000\n",
      "tensor([4.1618e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3905 --- loss: 0.000042\n",
      "tensor([8.0103e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3908 --- loss: 0.000080\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3911 --- loss: 0.001102\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3913 --- loss: 0.000177\n",
      "tensor([2.0971e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3916 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3918 --- loss: 0.000233\n",
      "tensor([0.0192], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3921 --- loss: 0.019436\n",
      "tensor([7.0005e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3923 --- loss: 0.000001\n",
      "tensor([0.0213], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3926 --- loss: 0.021485\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3928 --- loss: 0.000453\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3931 --- loss: 0.001041\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3933 --- loss: 0.000455\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3936 --- loss: 0.001219\n",
      "tensor([1.3477e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3938 --- loss: 0.000001\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3941 --- loss: 0.000331\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3943 --- loss: 0.000183\n",
      "tensor([0.9977], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3946 --- loss: 0.002314\n",
      "tensor([4.6976e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3948 --- loss: 0.000005\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3951 --- loss: 0.000893\n",
      "tensor([0.0020], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3953 --- loss: 0.002005\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3956 --- loss: 0.001191\n",
      "tensor([1.8686e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3959 --- loss: 0.000000\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3961 --- loss: 0.000810\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3964 --- loss: 0.000398\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3966 --- loss: 0.000382\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3969 --- loss: 0.000125\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3971 --- loss: 0.000203\n",
      "tensor([9.2370e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3974 --- loss: 0.000009\n",
      "tensor([2.3332e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3976 --- loss: 0.000002\n",
      "tensor([0.0018], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3979 --- loss: 0.001753\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3981 --- loss: 0.000192\n",
      "tensor([9.9540e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3984 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3986 --- loss: 0.000169\n",
      "tensor([6.9419e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3989 --- loss: 0.000001\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3991 --- loss: 0.000512\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3994 --- loss: 0.000590\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3996 --- loss: 0.000207\n",
      "tensor([4.5365e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3999 --- loss: 0.000005\n",
      "tensor([8.1391e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4002 --- loss: 0.000000\n",
      "tensor([4.7893e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4004 --- loss: 0.000000\n",
      "tensor([0.0921], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4007 --- loss: 0.096673\n",
      "tensor([5.7924e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4009 --- loss: 0.000000\n",
      "tensor([0.1290], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4012 --- loss: 0.138079\n",
      "tensor([0.0025], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4014 --- loss: 0.002475\n",
      "tensor([5.3420e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4017 --- loss: 0.000005\n",
      "tensor([1.5990e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4019 --- loss: 0.000002\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4022 --- loss: 0.000117\n",
      "tensor([2.1452e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4024 --- loss: 0.000021\n",
      "tensor([6.5170e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4027 --- loss: 0.000007\n",
      "tensor([6.5411e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4029 --- loss: 0.000000\n",
      "tensor([0.9826], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4032 --- loss: 0.017546\n",
      "tensor([4.6167e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4034 --- loss: 0.000000\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4037 --- loss: 0.000291\n",
      "tensor([0.9972], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4039 --- loss: 0.002770\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4042 --- loss: 0.000022\n",
      "tensor([0.9976], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4044 --- loss: 0.002428\n",
      "tensor([2.9333e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4047 --- loss: 0.000000\n",
      "tensor([0.9819], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4050 --- loss: 0.018273\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4052 --- loss: 0.000443\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4055 --- loss: 0.000527\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4057 --- loss: 0.000102\n",
      "tensor([0.9971], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4060 --- loss: 0.002947\n",
      "tensor([3.3365e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4062 --- loss: 0.000000\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4065 --- loss: 0.000430\n",
      "tensor([0.0014], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4067 --- loss: 0.001413\n",
      "tensor([0.0013], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4070 --- loss: 0.001266\n",
      "tensor([0.9949], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4072 --- loss: 0.005093\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4075 --- loss: 0.000095\n",
      "tensor([2.5629e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4077 --- loss: 0.000003\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4080 --- loss: 0.000636\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4082 --- loss: 0.000134\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4085 --- loss: 0.000670\n",
      "tensor([4.4395e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4087 --- loss: 0.000044\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4090 --- loss: 0.000009\n",
      "tensor([0.9980], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4093 --- loss: 0.002042\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4095 --- loss: 0.000865\n",
      "tensor([2.1287e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4098 --- loss: 0.000021\n",
      "tensor([0.9958], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4100 --- loss: 0.004239\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4103 --- loss: 0.000162\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4105 --- loss: 0.000601\n",
      "tensor([2.9843e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4108 --- loss: 0.000000\n",
      "tensor([1.3241e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4110 --- loss: 0.000001\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4113 --- loss: 0.001248\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4115 --- loss: 0.000010\n",
      "tensor([1.6184e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4118 --- loss: 0.000002\n",
      "tensor([5.7203e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4120 --- loss: 0.000000\n",
      "tensor([1.3805e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4123 --- loss: 0.000014\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4125 --- loss: 0.000273\n",
      "tensor([0.0026], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4128 --- loss: 0.002561\n",
      "tensor([0.9933], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4130 --- loss: 0.006759\n",
      "tensor([8.7584e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4133 --- loss: 0.000088\n",
      "tensor([0.0028], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4135 --- loss: 0.002840\n",
      "tensor([1.0464e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4138 --- loss: 0.000000\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4141 --- loss: 0.000853\n",
      "tensor([6.6038e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4143 --- loss: 0.000000\n",
      "tensor([7.9307e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4146 --- loss: 0.000079\n",
      "tensor([2.6867e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4148 --- loss: 0.000003\n",
      "tensor([1.7810e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4151 --- loss: 0.000000\n",
      "tensor([1.0206e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4153 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4156 --- loss: 0.000044\n",
      "tensor([2.7933e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4158 --- loss: 0.000028\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4161 --- loss: 0.000138\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4163 --- loss: 0.000023\n",
      "tensor([1.6901e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4166 --- loss: 0.000000\n",
      "tensor([0.9977], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4168 --- loss: 0.002340\n",
      "tensor([6.7242e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4171 --- loss: 0.000007\n",
      "tensor([3.9724e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4173 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4176 --- loss: 0.000152\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4178 --- loss: 0.000170\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4181 --- loss: 0.000273\n",
      "tensor([6.0352e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4184 --- loss: 0.000006\n",
      "tensor([1.9538e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4186 --- loss: 0.000002\n",
      "tensor([2.8795e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4189 --- loss: 0.000003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.8285e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4191 --- loss: 0.000002\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4194 --- loss: 0.000203\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4196 --- loss: 0.000162\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4199 --- loss: 0.000492\n",
      "tensor([7.1046e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4201 --- loss: 0.000071\n",
      "tensor([3.6246e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4204 --- loss: 0.000036\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4206 --- loss: 0.001116\n",
      "tensor([0.0065], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4209 --- loss: 0.006482\n",
      "tensor([3.0998e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4211 --- loss: 0.000000\n",
      "tensor([3.4672e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4214 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4216 --- loss: 0.000208\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4219 --- loss: 0.000241\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4221 --- loss: 0.000472\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4224 --- loss: 0.001588\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4226 --- loss: 0.000769\n",
      "tensor([2.4020e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4229 --- loss: 0.000024\n",
      "tensor([2.6999e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4232 --- loss: 0.000027\n",
      "tensor([4.8273e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4234 --- loss: 0.000048\n",
      "tensor([0.9979], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4237 --- loss: 0.002092\n",
      "tensor([0.0014], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4239 --- loss: 0.001352\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4242 --- loss: 0.000775\n",
      "tensor([3.0737e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4244 --- loss: 0.000000\n",
      "tensor([0.9925], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4247 --- loss: 0.007502\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4249 --- loss: 0.000955\n",
      "tensor([1.4936e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4252 --- loss: 0.000015\n",
      "tensor([3.4420e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4254 --- loss: 0.000034\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4257 --- loss: 0.000508\n",
      "tensor([1.4172e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4259 --- loss: 0.000001\n",
      "tensor([1.9713e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4262 --- loss: 0.000000\n",
      "tensor([3.3995e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4264 --- loss: 0.000034\n",
      "tensor([0.0017], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4267 --- loss: 0.001729\n",
      "tensor([0.0027], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4269 --- loss: 0.002712\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4272 --- loss: 0.000488\n",
      "tensor([1.2618e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4275 --- loss: 0.000001\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4277 --- loss: 0.000893\n",
      "tensor([2.6424e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4280 --- loss: 0.000026\n",
      "tensor([0.9986], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4282 --- loss: 0.001404\n",
      "tensor([1.0898e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4285 --- loss: 0.000001\n",
      "tensor([1.0705e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4287 --- loss: 0.000001\n",
      "tensor([3.1767e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4290 --- loss: 0.000000\n",
      "tensor([3.4777e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4292 --- loss: 0.000000\n",
      "tensor([0.0024], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4295 --- loss: 0.002374\n",
      "tensor([3.0149e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4297 --- loss: 0.000000\n",
      "tensor([0.0011], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4300 --- loss: 0.001125\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4302 --- loss: 0.000241\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4305 --- loss: 0.000007\n",
      "tensor([0.9980], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4307 --- loss: 0.002050\n",
      "tensor([2.3864e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4310 --- loss: 0.000024\n",
      "tensor([6.0994e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4312 --- loss: 0.000006\n",
      "tensor([0.9990], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4315 --- loss: 0.000999\n",
      "tensor([1.0813e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4317 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4320 --- loss: 0.000031\n",
      "tensor([0.0018], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4323 --- loss: 0.001802\n",
      "tensor([4.6977e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4325 --- loss: 0.000005\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4328 --- loss: 0.000175\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4330 --- loss: 0.000241\n",
      "tensor([1.2831e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4333 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4335 --- loss: 0.000037\n",
      "tensor([6.9874e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4338 --- loss: 0.000000\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4340 --- loss: 0.000494\n",
      "tensor([0.9708], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4343 --- loss: 0.029586\n",
      "tensor([1.1919e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4345 --- loss: 0.000012\n",
      "tensor([6.7732e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4348 --- loss: 0.000068\n",
      "tensor([1.5831e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4350 --- loss: 0.000002\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4353 --- loss: 0.000066\n",
      "tensor([6.3055e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4355 --- loss: 0.000006\n",
      "tensor([0.9954], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4358 --- loss: 0.004588\n",
      "tensor([5.0016e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4360 --- loss: 0.000050\n",
      "tensor([6.9448e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4363 --- loss: 0.000000\n",
      "tensor([2.2563e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4366 --- loss: 0.000000\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4368 --- loss: 0.000478\n",
      "tensor([0.2526], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4371 --- loss: 0.291148\n",
      "tensor([6.8981e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4373 --- loss: 0.000069\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4376 --- loss: 0.000488\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4378 --- loss: 0.000154\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4381 --- loss: 0.000333\n",
      "tensor([0.9883], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4383 --- loss: 0.011760\n",
      "tensor([0.9990], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4386 --- loss: 0.001013\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4388 --- loss: 0.000031\n",
      "tensor([4.5883e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4391 --- loss: 0.000046\n",
      "tensor([6.6618e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4393 --- loss: 0.000067\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4396 --- loss: 0.000219\n",
      "tensor([1.3610e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4398 --- loss: 0.000001\n",
      "tensor([9.1717e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4401 --- loss: 0.000092\n",
      "tensor([1.0013e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4403 --- loss: 0.000001\n",
      "tensor([5.4731e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4406 --- loss: 0.000055\n",
      "tensor([9.4003e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4408 --- loss: 0.000009\n",
      "tensor([4.1617e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4411 --- loss: 0.000004\n",
      "tensor([2.2125e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4414 --- loss: 0.000000\n",
      "tensor([0.9979], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4416 --- loss: 0.002147\n",
      "tensor([5.7233e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4419 --- loss: 0.000000\n",
      "tensor([6.0989e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4421 --- loss: 0.000000\n",
      "tensor([1.1405e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4424 --- loss: 0.000000\n",
      "tensor([9.9298e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4426 --- loss: 0.000099\n",
      "tensor([3.1969e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4429 --- loss: 0.000032\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4431 --- loss: 0.000365\n",
      "tensor([2.6538e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4434 --- loss: 0.000000\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4436 --- loss: 0.000755\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4439 --- loss: 0.000535\n",
      "tensor([3.3054e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4441 --- loss: 0.000033\n",
      "tensor([6.5859e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4444 --- loss: 0.000007\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4446 --- loss: 0.000360\n",
      "tensor([5.8122e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4449 --- loss: 0.000058\n",
      "tensor([0.0041], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4451 --- loss: 0.004130\n",
      "tensor([4.7781e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4454 --- loss: 0.000005\n",
      "tensor([0.9964], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4457 --- loss: 0.003565\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4459 --- loss: 0.001136\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4462 --- loss: 0.000120\n",
      "tensor([0.9937], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4464 --- loss: 0.006358\n",
      "tensor([0.9901], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4467 --- loss: 0.009971\n",
      "tensor([6.6026e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4469 --- loss: 0.000066\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4472 --- loss: 0.000068\n",
      "tensor([0.9969], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4474 --- loss: 0.003136\n",
      "tensor([0.9979], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4477 --- loss: 0.002112\n",
      "tensor([2.5670e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4479 --- loss: 0.000026\n",
      "tensor([0.9943], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4482 --- loss: 0.005711\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4484 --- loss: 0.000351\n",
      "tensor([2.5019e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4487 --- loss: 0.000000\n",
      "tensor([0.9909], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4489 --- loss: 0.009104\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4492 --- loss: 0.000078\n",
      "tensor([0.0033], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4494 --- loss: 0.003333\n",
      "tensor([4.0697e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4497 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4499 --- loss: 0.000230\n",
      "tensor([7.8851e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4502 --- loss: 0.000000\n",
      "tensor([7.7045e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4505 --- loss: 0.000000\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4507 --- loss: 0.001570\n",
      "tensor([0.0095], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4510 --- loss: 0.009507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4512 --- loss: 0.000204\n",
      "tensor([7.6093e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4515 --- loss: 0.000000\n",
      "tensor([3.9368e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4517 --- loss: 0.000004\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4520 --- loss: 0.000146\n",
      "tensor([1.2618e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4522 --- loss: 0.000000\n",
      "tensor([4.6427e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4525 --- loss: 0.000046\n",
      "tensor([6.3854e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4527 --- loss: 0.000064\n",
      "tensor([6.7987e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4530 --- loss: 0.000000\n",
      "tensor([0.0012], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4532 --- loss: 0.001204\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4535 --- loss: 0.001591\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4537 --- loss: 0.000185\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4540 --- loss: 0.000125\n",
      "tensor([0.9964], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4542 --- loss: 0.003574\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4545 --- loss: 0.000235\n",
      "tensor([3.2348e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4548 --- loss: 0.000000\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4550 --- loss: 0.000985\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4553 --- loss: 0.000060\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4555 --- loss: 0.000459\n",
      "tensor([0.9977], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4558 --- loss: 0.002293\n",
      "tensor([3.2990e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4560 --- loss: 0.000003\n",
      "tensor([9.6923e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4563 --- loss: 0.000001\n",
      "tensor([2.4979e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4565 --- loss: 0.000000\n",
      "tensor([1.0657e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4568 --- loss: 0.000011\n",
      "tensor([0.9987], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4570 --- loss: 0.001298\n",
      "tensor([3.9232e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4573 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4575 --- loss: 0.000190\n",
      "tensor([2.0069e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4578 --- loss: 0.000020\n",
      "tensor([4.9560e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4580 --- loss: 0.000005\n",
      "tensor([2.4831e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4583 --- loss: 0.000002\n",
      "tensor([0.9965], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4585 --- loss: 0.003503\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4588 --- loss: 0.000122\n",
      "tensor([4.3388e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4590 --- loss: 0.000004\n",
      "tensor([0.9974], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4593 --- loss: 0.002651\n",
      "tensor([3.6992e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4596 --- loss: 0.000000\n",
      "tensor([4.2487e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4598 --- loss: 0.000004\n",
      "tensor([1.0156e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4601 --- loss: 0.000001\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4603 --- loss: 0.000357\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4606 --- loss: 0.000899\n",
      "tensor([6.1687e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4608 --- loss: 0.000062\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4611 --- loss: 0.000271\n",
      "tensor([5.5599e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4613 --- loss: 0.000000\n",
      "tensor([0.9929], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4616 --- loss: 0.007103\n",
      "tensor([4.8561e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4618 --- loss: 0.000049\n",
      "tensor([4.8218e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4621 --- loss: 0.000048\n",
      "tensor([7.3836e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4623 --- loss: 0.000000\n",
      "tensor([0.9987], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4626 --- loss: 0.001267\n",
      "tensor([3.5516e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4628 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4631 --- loss: 0.000119\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4633 --- loss: 0.000351\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4636 --- loss: 0.000302\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4639 --- loss: 0.000353\n",
      "tensor([2.5354e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4641 --- loss: 0.000025\n",
      "tensor([8.8786e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4644 --- loss: 0.000000\n",
      "tensor([2.6906e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4646 --- loss: 0.000000\n",
      "tensor([0.0014], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4649 --- loss: 0.001434\n",
      "tensor([0.9981], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4651 --- loss: 0.001889\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4654 --- loss: 0.000031\n",
      "tensor([8.0944e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4656 --- loss: 0.000001\n",
      "tensor([3.1528e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4659 --- loss: 0.000032\n",
      "tensor([0.0049], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4661 --- loss: 0.004872\n",
      "tensor([8.1579e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4664 --- loss: 0.000008\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4666 --- loss: 0.000762\n",
      "tensor([0.9954], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4669 --- loss: 0.004571\n",
      "tensor([7.4742e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4671 --- loss: 0.000075\n",
      "tensor([6.3076e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4674 --- loss: 0.000006\n",
      "tensor([9.5852e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4676 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4679 --- loss: 0.000152\n",
      "tensor([2.6420e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4681 --- loss: 0.000026\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4684 --- loss: 0.000509\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4687 --- loss: 0.000561\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4689 --- loss: 0.000394\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4692 --- loss: 0.000443\n",
      "tensor([4.1998e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4694 --- loss: 0.000042\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4697 --- loss: 0.000168\n",
      "tensor([2.3060e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4699 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4702 --- loss: 0.000025\n",
      "tensor([8.7415e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4704 --- loss: 0.000087\n",
      "tensor([3.5856e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4707 --- loss: 0.000000\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4709 --- loss: 0.000639\n",
      "tensor([0.9754], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4712 --- loss: 0.024874\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4714 --- loss: 0.000030\n",
      "tensor([5.4334e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4717 --- loss: 0.000054\n",
      "tensor([8.7888e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4719 --- loss: 0.000000\n",
      "tensor([1.0059e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4722 --- loss: 0.000001\n",
      "tensor([2.4198e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4724 --- loss: 0.000000\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4727 --- loss: 0.000298\n",
      "tensor([0.0014], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4730 --- loss: 0.001362\n",
      "tensor([3.8680e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4732 --- loss: 0.000039\n",
      "tensor([5.0492e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4735 --- loss: 0.000050\n",
      "tensor([0.9982], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4737 --- loss: 0.001816\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4740 --- loss: 0.000518\n",
      "tensor([0.9815], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4742 --- loss: 0.018674\n",
      "tensor([7.1507e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4745 --- loss: 0.000007\n",
      "tensor([1.0629e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4747 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4750 --- loss: 0.000113\n",
      "tensor([1.1268e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4752 --- loss: 0.000000\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4755 --- loss: 0.000415\n",
      "tensor([7.3412e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4757 --- loss: 0.000073\n",
      "tensor([0.2471], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4760 --- loss: 0.283860\n",
      "tensor([1.9771e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4762 --- loss: 0.000002\n",
      "tensor([2.0180e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4765 --- loss: 0.000000\n",
      "tensor([0.9944], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4767 --- loss: 0.005657\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4770 --- loss: 0.000207\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4772 --- loss: 0.000007\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4775 --- loss: 0.000093\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4778 --- loss: 0.000043\n",
      "tensor([0.9967], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4780 --- loss: 0.003313\n",
      "tensor([3.5910e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4783 --- loss: 0.000004\n",
      "tensor([0.9951], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4785 --- loss: 0.004882\n",
      "tensor([1.4993e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4788 --- loss: 0.000015\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4790 --- loss: 0.000817\n",
      "tensor([5.4417e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4793 --- loss: 0.000001\n",
      "tensor([1.0810e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4795 --- loss: 0.000011\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4798 --- loss: 0.000621\n",
      "tensor([3.7199e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4800 --- loss: 0.000000\n",
      "tensor([0.9979], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4803 --- loss: 0.002073\n",
      "tensor([7.9096e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4805 --- loss: 0.000001\n",
      "tensor([4.0353e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4808 --- loss: 0.000040\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4810 --- loss: 0.001117\n",
      "tensor([2.5730e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4813 --- loss: 0.000003\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4815 --- loss: 0.000215\n",
      "tensor([0.0011], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4818 --- loss: 0.001055\n",
      "tensor([0.9473], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4821 --- loss: 0.054126\n",
      "tensor([1.0623e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4823 --- loss: 0.000011\n",
      "tensor([2.1108e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4826 --- loss: 0.000002\n",
      "tensor([3.3225e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4828 --- loss: 0.000033\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4831 --- loss: 0.000145\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4833 --- loss: 0.000060\n",
      "tensor([3.5235e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4836 --- loss: 0.000000\n",
      "tensor([0.9983], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4838 --- loss: 0.001734\n",
      "tensor([9.1517e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4841 --- loss: 0.000009\n",
      "tensor([7.1012e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4843 --- loss: 0.000071\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4846 --- loss: 0.000684\n",
      "tensor([0.8699], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4848 --- loss: 0.139420\n",
      "tensor([7.7883e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4851 --- loss: 0.000001\n",
      "tensor([0.9962], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4853 --- loss: 0.003845\n",
      "tensor([1.2499e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4856 --- loss: 0.000000\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4858 --- loss: 0.000818\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4861 --- loss: 0.001155\n",
      "tensor([1.2538e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4863 --- loss: 0.000000\n",
      "tensor([4.0899e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4866 --- loss: 0.000000\n",
      "tensor([0.9980], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4869 --- loss: 0.001983\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4871 --- loss: 0.000569\n",
      "tensor([2.1236e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4874 --- loss: 0.000000\n",
      "tensor([3.6517e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4876 --- loss: 0.000000\n",
      "tensor([2.8548e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4879 --- loss: 0.000003\n",
      "tensor([3.9408e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4881 --- loss: 0.000004\n",
      "tensor([2.8203e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4884 --- loss: 0.000028\n",
      "tensor([1.8166e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4886 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4889 --- loss: 0.000054\n",
      "tensor([1.8793e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4891 --- loss: 0.000002\n",
      "tensor([7.3597e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4894 --- loss: 0.000074\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4896 --- loss: 0.000019\n",
      "tensor([7.1494e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4899 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4901 --- loss: 0.000119\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4904 --- loss: 0.000087\n",
      "tensor([1.0315e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4906 --- loss: 0.000001\n",
      "tensor([0.9955], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4909 --- loss: 0.004558\n",
      "tensor([2.4036e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4912 --- loss: 0.000002\n",
      "tensor([0.9895], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4914 --- loss: 0.010605\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4917 --- loss: 0.000134\n",
      "tensor([3.3522e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4919 --- loss: 0.000000\n",
      "tensor([0.9944], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4922 --- loss: 0.005664\n",
      "tensor([5.6035e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4924 --- loss: 0.000056\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4927 --- loss: 0.000339\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4929 --- loss: 0.000401\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4932 --- loss: 0.000131\n",
      "tensor([4.0790e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4934 --- loss: 0.000041\n",
      "tensor([8.2976e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4937 --- loss: 0.000000\n",
      "tensor([1.6370e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4939 --- loss: 0.000000\n",
      "tensor([0.9949], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4942 --- loss: 0.005100\n",
      "tensor([5.4569e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4944 --- loss: 0.000001\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4947 --- loss: 0.000624\n",
      "tensor([1.1753e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4949 --- loss: 0.000012\n",
      "tensor([2.0192e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4952 --- loss: 0.000002\n",
      "tensor([3.3517e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4954 --- loss: 0.000034\n",
      "tensor([0.7470], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4957 --- loss: 0.291741\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4960 --- loss: 0.001602\n",
      "tensor([2.4877e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4962 --- loss: 0.000025\n",
      "tensor([3.3209e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4965 --- loss: 0.000000\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4967 --- loss: 0.000675\n",
      "tensor([2.3092e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4970 --- loss: 0.000000\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4972 --- loss: 0.000563\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4975 --- loss: 0.000650\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4977 --- loss: 0.000010\n",
      "tensor([0.9977], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4980 --- loss: 0.002316\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4982 --- loss: 0.000178\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4985 --- loss: 0.001096\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4987 --- loss: 0.000041\n",
      "tensor([1.2324e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4990 --- loss: 0.000000\n",
      "tensor([0.9942], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4992 --- loss: 0.005789\n",
      "tensor([0.0039], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4995 --- loss: 0.003915\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4997 --- loss: 0.000194\n",
      "tensor([0.0050], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5000 --- loss: 0.004992\n",
      "tensor([9.2360e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5003 --- loss: 0.000009\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5005 --- loss: 0.000004\n",
      "tensor([0.9948], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5008 --- loss: 0.005200\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5010 --- loss: 0.000170\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5013 --- loss: 0.000449\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5015 --- loss: 0.000212\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5018 --- loss: 0.000198\n",
      "tensor([0.0014], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5020 --- loss: 0.001401\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5023 --- loss: 0.000288\n",
      "tensor([1.3702e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5025 --- loss: 0.000014\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5028 --- loss: 0.000043\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5030 --- loss: 0.000325\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5033 --- loss: 0.001223\n",
      "tensor([2.3000e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5035 --- loss: 0.000000\n",
      "tensor([4.1082e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5038 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5040 --- loss: 0.000249\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5043 --- loss: 0.000159\n",
      "tensor([2.4243e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5046 --- loss: 0.000000\n",
      "tensor([3.5146e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5048 --- loss: 0.000004\n",
      "tensor([4.0606e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5051 --- loss: 0.000000\n",
      "tensor([0.0066], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5053 --- loss: 0.006587\n",
      "tensor([1.6719e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5056 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5058 --- loss: 0.000128\n",
      "tensor([4.4283e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5061 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5063 --- loss: 0.000085\n",
      "tensor([1.4216e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5066 --- loss: 0.000014\n",
      "tensor([1.2509e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5068 --- loss: 0.000013\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5071 --- loss: 0.000004\n",
      "tensor([0.9981], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5073 --- loss: 0.001857\n",
      "tensor([0.0026], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5076 --- loss: 0.002648\n",
      "tensor([6.1147e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5078 --- loss: 0.000000\n",
      "tensor([0.9816], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5081 --- loss: 0.018531\n",
      "tensor([1.7734e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5083 --- loss: 0.000002\n",
      "tensor([1.4246e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5086 --- loss: 0.000014\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5088 --- loss: 0.000019\n",
      "tensor([2.8142e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5091 --- loss: 0.000000\n",
      "tensor([1.2981e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5094 --- loss: 0.000013\n",
      "tensor([2.3488e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5096 --- loss: 0.000000\n",
      "tensor([9.7772e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5099 --- loss: 0.000000\n",
      "tensor([7.3480e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5101 --- loss: 0.000007\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5104 --- loss: 0.000034\n",
      "tensor([2.5795e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5106 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5109 --- loss: 0.000153\n",
      "tensor([3.5344e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5111 --- loss: 0.000000\n",
      "tensor([1.4804e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5114 --- loss: 0.000000\n",
      "tensor([5.9569e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5116 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5119 --- loss: 0.000121\n",
      "tensor([5.1636e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5121 --- loss: 0.000000\n",
      "tensor([2.5006e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5124 --- loss: 0.000003\n",
      "tensor([1.9995e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5126 --- loss: 0.000000\n",
      "tensor([1.6742e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5129 --- loss: 0.000017\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5131 --- loss: 0.000116\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5134 --- loss: 0.000123\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5137 --- loss: 0.001117\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5139 --- loss: 0.000025\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5142 --- loss: 0.000306\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5144 --- loss: 0.000569\n",
      "tensor([7.2282e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5147 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5149 --- loss: 0.000027\n",
      "tensor([2.1508e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5152 --- loss: 0.000000\n",
      "tensor([4.8579e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5154 --- loss: 0.000005\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5157 --- loss: 0.000795\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5159 --- loss: 0.000472\n",
      "tensor([5.4063e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5162 --- loss: 0.000054\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5164 --- loss: 0.000025\n",
      "tensor([6.9171e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5167 --- loss: 0.000000\n",
      "tensor([3.2142e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5169 --- loss: 0.000003\n",
      "tensor([2.4933e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5172 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5174 --- loss: 0.000215\n",
      "tensor([1.1815e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5177 --- loss: 0.000000\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5179 --- loss: 0.000534\n",
      "tensor([1.5678e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5182 --- loss: 0.000000\n",
      "tensor([2.0914e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5185 --- loss: 0.000000\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5187 --- loss: 0.000333\n",
      "tensor([0.9986], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5190 --- loss: 0.001405\n",
      "tensor([2.2003e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5192 --- loss: 0.000000\n",
      "tensor([0.9965], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5195 --- loss: 0.003528\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5197 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5200 --- loss: 0.000012\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5202 --- loss: 0.000220\n",
      "tensor([0.3108], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5205 --- loss: 0.372277\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5207 --- loss: 0.000251\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5210 --- loss: 0.000223\n",
      "tensor([5.7790e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5212 --- loss: 0.000000\n",
      "tensor([0.0049], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5215 --- loss: 0.004868\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5217 --- loss: 0.000677\n",
      "tensor([2.6624e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5220 --- loss: 0.000027\n",
      "tensor([1.8500e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5222 --- loss: 0.000000\n",
      "tensor([1.7222e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5225 --- loss: 0.000000\n",
      "tensor([1.3311e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5228 --- loss: 0.000000\n",
      "tensor([0.9628], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5230 --- loss: 0.037917\n",
      "tensor([5.5507e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5233 --- loss: 0.000006\n",
      "tensor([0.9987], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5235 --- loss: 0.001259\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5238 --- loss: 0.000343\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5240 --- loss: 0.000263\n",
      "tensor([5.4791e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5243 --- loss: 0.000055\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5245 --- loss: 0.000080\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5248 --- loss: 0.000133\n",
      "tensor([9.3810e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5250 --- loss: 0.000001\n",
      "tensor([0.0032], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5253 --- loss: 0.003161\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5255 --- loss: 0.000169\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5258 --- loss: 0.000237\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5260 --- loss: 0.000056\n",
      "tensor([2.4278e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5263 --- loss: 0.000002\n",
      "tensor([2.9090e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5265 --- loss: 0.000000\n",
      "tensor([1.1998e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5268 --- loss: 0.000012\n",
      "tensor([5.0728e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5270 --- loss: 0.000000\n",
      "tensor([6.7855e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5273 --- loss: 0.000001\n",
      "tensor([3.3937e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5276 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5278 --- loss: 0.000008\n",
      "tensor([1.7812e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5281 --- loss: 0.000000\n",
      "tensor([7.9336e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5283 --- loss: 0.000008\n",
      "tensor([0.0012], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5286 --- loss: 0.001157\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5288 --- loss: 0.000290\n",
      "tensor([3.9738e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5291 --- loss: 0.000000\n",
      "tensor([1.5352e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5293 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5296 --- loss: 0.000035\n",
      "tensor([4.9089e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5298 --- loss: 0.000005\n",
      "tensor([1.9711e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5301 --- loss: 0.000000\n",
      "tensor([7.8230e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5303 --- loss: 0.000078\n",
      "tensor([3.7020e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5306 --- loss: 0.000000\n",
      "tensor([4.7402e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5308 --- loss: 0.000000\n",
      "tensor([5.4641e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5311 --- loss: 0.000055\n",
      "tensor([0.9977], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5313 --- loss: 0.002271\n",
      "tensor([1.4962e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5316 --- loss: 0.000000\n",
      "tensor([1.3820e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5319 --- loss: 0.000000\n",
      "tensor([1.2983e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5321 --- loss: 0.000000\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5324 --- loss: 0.000804\n",
      "tensor([9.4957e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5326 --- loss: 0.000000\n",
      "tensor([1.2047e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5329 --- loss: 0.000012\n",
      "tensor([8.3002e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5331 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5334 --- loss: 0.000013\n",
      "tensor([0.9867], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5336 --- loss: 0.013414\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5339 --- loss: 0.000669\n",
      "tensor([7.1138e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5341 --- loss: 0.000001\n",
      "tensor([3.3206e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5344 --- loss: 0.000033\n",
      "tensor([3.7239e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5346 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5349 --- loss: 0.000067\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5351 --- loss: 0.000042\n",
      "tensor([9.6267e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5354 --- loss: 0.000000\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5356 --- loss: 0.000999\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5359 --- loss: 0.000196\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5361 --- loss: 0.000835\n",
      "tensor([1.1739e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5364 --- loss: 0.000001\n",
      "tensor([1.0662e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5367 --- loss: 0.000011\n",
      "tensor([0.9979], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5369 --- loss: 0.002067\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5372 --- loss: 0.000347\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5374 --- loss: 0.000065\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5377 --- loss: 0.000166\n",
      "tensor([1.7297e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5379 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5382 --- loss: 0.000070\n",
      "tensor([0.9971], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5384 --- loss: 0.002943\n",
      "tensor([2.1200e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5387 --- loss: 0.000000\n",
      "tensor([3.3594e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5389 --- loss: 0.000000\n",
      "tensor([8.9422e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5392 --- loss: 0.000009\n",
      "tensor([6.7925e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5394 --- loss: 0.000000\n",
      "tensor([6.7893e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5397 --- loss: 0.000000\n",
      "tensor([2.9997e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5399 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5402 --- loss: 0.000006\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5404 --- loss: 0.000126\n",
      "tensor([3.2930e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5407 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5410 --- loss: 0.000025\n",
      "tensor([9.5429e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5412 --- loss: 0.000095\n",
      "tensor([2.4804e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5415 --- loss: 0.000000\n",
      "tensor([1.3670e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5417 --- loss: 0.000001\n",
      "tensor([0.9985], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5420 --- loss: 0.001507\n",
      "tensor([4.5029e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5422 --- loss: 0.000045\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5425 --- loss: 0.000100\n",
      "tensor([8.5055e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5427 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5430 --- loss: 0.000102\n",
      "tensor([1.4328e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5432 --- loss: 0.000014\n",
      "tensor([2.9436e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5435 --- loss: 0.000029\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5437 --- loss: 0.000033\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5440 --- loss: 0.000140\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5442 --- loss: 0.001212\n",
      "tensor([5.3174e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5445 --- loss: 0.000001\n",
      "tensor([1.5178e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5447 --- loss: 0.000000\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5450 --- loss: 0.001565\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5452 --- loss: 0.000269\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5455 --- loss: 0.000048\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5458 --- loss: 0.000060\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5460 --- loss: 0.000295\n",
      "tensor([0.9953], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5463 --- loss: 0.004709\n",
      "tensor([7.7668e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5465 --- loss: 0.000000\n",
      "tensor([1.3417e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5468 --- loss: 0.000013\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5470 --- loss: 0.000021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5473 --- loss: 0.000115\n",
      "tensor([9.8318e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5475 --- loss: 0.000010\n",
      "tensor([0.0029], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5478 --- loss: 0.002898\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5480 --- loss: 0.000194\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5483 --- loss: 0.000391\n",
      "tensor([1.0542e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5485 --- loss: 0.000001\n",
      "tensor([3.3401e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5488 --- loss: 0.000033\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5490 --- loss: 0.000032\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5493 --- loss: 0.000039\n",
      "tensor([4.9630e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5495 --- loss: 0.000005\n",
      "tensor([2.3814e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5498 --- loss: 0.000002\n",
      "tensor([1.3470e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5501 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5503 --- loss: 0.000070\n",
      "tensor([5.4597e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5506 --- loss: 0.000005\n",
      "tensor([4.2564e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5508 --- loss: 0.000000\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5511 --- loss: 0.001129\n",
      "tensor([0.0009], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5513 --- loss: 0.000949\n",
      "tensor([8.0185e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5516 --- loss: 0.000000\n",
      "tensor([1.0348e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5518 --- loss: 0.000000\n",
      "tensor([1.8959e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5521 --- loss: 0.000000\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5523 --- loss: 0.000496\n",
      "tensor([6.5657e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5526 --- loss: 0.000000\n",
      "tensor([3.1055e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5528 --- loss: 0.000003\n",
      "tensor([1.4598e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5531 --- loss: 0.000015\n",
      "tensor([5.1204e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5533 --- loss: 0.000000\n",
      "tensor([1.1122e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5536 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5538 --- loss: 0.000174\n",
      "tensor([0.9966], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5541 --- loss: 0.003383\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5543 --- loss: 0.000188\n",
      "tensor([1.4967e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5546 --- loss: 0.000001\n",
      "tensor([1.2298e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5549 --- loss: 0.000000\n",
      "tensor([0.9979], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5551 --- loss: 0.002106\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5554 --- loss: 0.000191\n",
      "tensor([5.8964e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5556 --- loss: 0.000001\n",
      "tensor([3.1094e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5559 --- loss: 0.000003\n",
      "tensor([2.3789e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5561 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5564 --- loss: 0.000021\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5566 --- loss: 0.000005\n",
      "tensor([1.7264e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5569 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5571 --- loss: 0.000057\n",
      "tensor([1.4977e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5574 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5576 --- loss: 0.000005\n",
      "tensor([2.6742e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5579 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5581 --- loss: 0.000117\n",
      "tensor([0.9960], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5584 --- loss: 0.003964\n",
      "tensor([1.5106e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5586 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5589 --- loss: 0.000164\n",
      "tensor([4.8765e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5592 --- loss: 0.000049\n",
      "tensor([0.9978], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5594 --- loss: 0.002201\n",
      "tensor([9.7149e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5597 --- loss: 0.000001\n",
      "tensor([3.0506e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5599 --- loss: 0.000031\n",
      "tensor([4.3336e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5602 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5604 --- loss: 0.000137\n",
      "tensor([0.0217], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5607 --- loss: 0.021931\n",
      "tensor([5.0636e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5609 --- loss: 0.000005\n",
      "tensor([8.5422e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5612 --- loss: 0.000085\n",
      "tensor([1.4189e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5614 --- loss: 0.000014\n",
      "tensor([1.6315e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5617 --- loss: 0.000000\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5619 --- loss: 0.000875\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5622 --- loss: 0.000083\n",
      "tensor([1.3826e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5624 --- loss: 0.000000\n",
      "tensor([0.7495], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5627 --- loss: 0.288359\n",
      "tensor([0.9970], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5629 --- loss: 0.002996\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5632 --- loss: 0.000100\n",
      "tensor([3.0027e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5634 --- loss: 0.000000\n",
      "tensor([3.3448e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5637 --- loss: 0.000000\n",
      "tensor([8.7014e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5640 --- loss: 0.000087\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5642 --- loss: 0.000020\n",
      "tensor([0.9930], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5645 --- loss: 0.007022\n",
      "tensor([0.9990], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5647 --- loss: 0.001012\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5650 --- loss: 0.000654\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5652 --- loss: 0.000111\n",
      "tensor([1.0098e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5655 --- loss: 0.000010\n",
      "tensor([4.8248e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5657 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5660 --- loss: 0.000003\n",
      "tensor([1.3049e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5662 --- loss: 0.000013\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5665 --- loss: 0.000685\n",
      "tensor([8.5830e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5667 --- loss: 0.000000\n",
      "tensor([1.0910e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5670 --- loss: 0.000000\n",
      "tensor([2.7208e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5672 --- loss: 0.000000\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5675 --- loss: 0.000401\n",
      "tensor([1.1954e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5677 --- loss: 0.000001\n",
      "tensor([0.0054], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5680 --- loss: 0.005381\n",
      "tensor([0.9942], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5683 --- loss: 0.005811\n",
      "tensor([2.7051e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5685 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5688 --- loss: 0.000009\n",
      "tensor([0.1661], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5690 --- loss: 0.181599\n",
      "tensor([9.9609e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5693 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5695 --- loss: 0.000238\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5698 --- loss: 0.000052\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5700 --- loss: 0.000011\n",
      "tensor([1.4635e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5703 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5705 --- loss: 0.000006\n",
      "tensor([0.9981], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5708 --- loss: 0.001867\n",
      "tensor([6.4190e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5710 --- loss: 0.000001\n",
      "tensor([2.2596e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5713 --- loss: 0.000000\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5715 --- loss: 0.000396\n",
      "tensor([5.1739e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5718 --- loss: 0.000000\n",
      "tensor([4.4254e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5720 --- loss: 0.000000\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5723 --- loss: 0.000731\n",
      "tensor([1.6436e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5725 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5728 --- loss: 0.000328\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5731 --- loss: 0.000144\n",
      "tensor([2.0140e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5733 --- loss: 0.000000\n",
      "tensor([0.3080], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5736 --- loss: 0.368240\n",
      "tensor([9.1452e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5738 --- loss: 0.000001\n",
      "tensor([0.0040], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5741 --- loss: 0.004027\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5743 --- loss: 0.000037\n",
      "tensor([0.9977], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5746 --- loss: 0.002265\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5748 --- loss: 0.000693\n",
      "tensor([1.3538e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5751 --- loss: 0.000014\n",
      "tensor([2.3974e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5753 --- loss: 0.000000\n",
      "tensor([0.9784], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5756 --- loss: 0.021856\n",
      "tensor([0.9965], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5758 --- loss: 0.003484\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5761 --- loss: 0.000615\n",
      "tensor([1.2887e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5763 --- loss: 0.000000\n",
      "tensor([5.3368e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5766 --- loss: 0.000000\n",
      "tensor([6.0021e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5768 --- loss: 0.000000\n",
      "tensor([1.4454e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5771 --- loss: 0.000014\n",
      "tensor([1.4594e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5774 --- loss: 0.000000\n",
      "tensor([1.8609e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5776 --- loss: 0.000000\n",
      "tensor([6.6819e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5779 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5781 --- loss: 0.000309\n",
      "tensor([3.8503e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5784 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5786 --- loss: 0.000034\n",
      "tensor([0.9598], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5789 --- loss: 0.041008\n",
      "tensor([0.9962], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5791 --- loss: 0.003787\n",
      "tensor([2.3084e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5794 --- loss: 0.000000\n",
      "tensor([1.0209e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5796 --- loss: 0.000001\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5799 --- loss: 0.000221\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5801 --- loss: 0.000037\n",
      "tensor([0.9908], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5804 --- loss: 0.009282\n",
      "tensor([1.4916e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5806 --- loss: 0.000000\n",
      "tensor([1.2855e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5809 --- loss: 0.000000\n",
      "tensor([2.1442e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5811 --- loss: 0.000021\n",
      "tensor([4.5257e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5814 --- loss: 0.000000\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5816 --- loss: 0.001197\n",
      "tensor([0.9410], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5819 --- loss: 0.060857\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5822 --- loss: 0.000297\n",
      "tensor([8.7353e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5824 --- loss: 0.000000\n",
      "tensor([1.3336e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5827 --- loss: 0.000001\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5829 --- loss: 0.000276\n",
      "tensor([2.1471e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5832 --- loss: 0.000000\n",
      "tensor([3.5342e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5834 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5837 --- loss: 0.000242\n",
      "tensor([0.9986], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5839 --- loss: 0.001377\n",
      "tensor([0.9990], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5842 --- loss: 0.001035\n",
      "tensor([6.5896e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5844 --- loss: 0.000000\n",
      "tensor([7.8038e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5847 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5849 --- loss: 0.000014\n",
      "tensor([5.9325e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5852 --- loss: 0.000001\n",
      "tensor([0.9951], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5854 --- loss: 0.004901\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5857 --- loss: 0.000013\n",
      "tensor([8.4123e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5859 --- loss: 0.000000\n",
      "tensor([1.1787e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5862 --- loss: 0.000000\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5865 --- loss: 0.000939\n",
      "tensor([3.3199e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5867 --- loss: 0.000000\n",
      "tensor([3.9791e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5870 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5872 --- loss: 0.000036\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5875 --- loss: 0.000350\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5877 --- loss: 0.000160\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5880 --- loss: 0.000641\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5882 --- loss: 0.000045\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5885 --- loss: 0.000598\n",
      "tensor([1.1861e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5887 --- loss: 0.000001\n",
      "tensor([1.8133e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5890 --- loss: 0.000000\n",
      "tensor([3.5342e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5892 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5895 --- loss: 0.000221\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5897 --- loss: 0.000045\n",
      "tensor([2.6636e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5900 --- loss: 0.000027\n",
      "tensor([2.1580e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5902 --- loss: 0.000000\n",
      "tensor([6.5988e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5905 --- loss: 0.000000\n",
      "tensor([1.3592e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5907 --- loss: 0.000000\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5910 --- loss: 0.000507\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5913 --- loss: 0.000004\n",
      "tensor([3.7820e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5915 --- loss: 0.000000\n",
      "tensor([5.5879e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5918 --- loss: 0.000000\n",
      "tensor([1.6022e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5920 --- loss: 0.000016\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5923 --- loss: 0.000051\n",
      "tensor([4.1401e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5925 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5928 --- loss: 0.000021\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5930 --- loss: 0.000229\n",
      "tensor([0.0011], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5933 --- loss: 0.001143\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5935 --- loss: 0.000112\n",
      "tensor([0.9974], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5938 --- loss: 0.002624\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5940 --- loss: 0.000142\n",
      "tensor([7.8756e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5943 --- loss: 0.000008\n",
      "tensor([2.7057e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5945 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5948 --- loss: 0.000009\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5950 --- loss: 0.000245\n",
      "tensor([8.4319e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5953 --- loss: 0.000084\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5956 --- loss: 0.000392\n",
      "tensor([1.5881e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5958 --- loss: 0.000002\n",
      "tensor([6.5446e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5961 --- loss: 0.000007\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5963 --- loss: 0.000105\n",
      "tensor([3.5593e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5966 --- loss: 0.000000\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5968 --- loss: 0.000382\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5971 --- loss: 0.000064\n",
      "tensor([3.2494e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5973 --- loss: 0.000000\n",
      "tensor([0.1581], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5976 --- loss: 0.172074\n",
      "tensor([2.9097e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5978 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5981 --- loss: 0.000121\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5983 --- loss: 0.000097\n",
      "tensor([7.8341e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5986 --- loss: 0.000001\n",
      "tensor([0.9962], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5988 --- loss: 0.003850\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5991 --- loss: 0.000303\n",
      "tensor([7.9670e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5993 --- loss: 0.000000\n",
      "tensor([2.9710e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5996 --- loss: 0.000003\n",
      "tensor([0.9987], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5998 --- loss: 0.001333\n",
      "tensor([1.2656e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6001 --- loss: 0.000000\n",
      "tensor([7.7431e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6004 --- loss: 0.000000\n",
      "tensor([3.3163e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6006 --- loss: 0.000033\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6009 --- loss: 0.000902\n",
      "tensor([8.7759e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6011 --- loss: 0.000009\n",
      "tensor([0.9950], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6014 --- loss: 0.005004\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6016 --- loss: 0.000053\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6019 --- loss: 0.000179\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6021 --- loss: 0.000021\n",
      "tensor([3.0735e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6024 --- loss: 0.000000\n",
      "tensor([0.9983], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6026 --- loss: 0.001718\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6029 --- loss: 0.000427\n",
      "tensor([2.2636e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6031 --- loss: 0.000002\n",
      "tensor([4.6000e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6034 --- loss: 0.000046\n",
      "tensor([0.0011], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6036 --- loss: 0.001079\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6039 --- loss: 0.000021\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6041 --- loss: 0.000320\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6044 --- loss: 0.000061\n",
      "tensor([5.8396e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6047 --- loss: 0.000000\n",
      "tensor([1.3702e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6049 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6052 --- loss: 0.000162\n",
      "tensor([0.9943], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6054 --- loss: 0.005742\n",
      "tensor([2.8407e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6057 --- loss: 0.000028\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6059 --- loss: 0.000032\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6062 --- loss: 0.000248\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6064 --- loss: 0.000846\n",
      "tensor([5.6848e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6067 --- loss: 0.000000\n",
      "tensor([5.2471e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6069 --- loss: 0.000000\n",
      "tensor([9.8058e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6072 --- loss: 0.000000\n",
      "tensor([2.5591e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6074 --- loss: 0.000003\n",
      "tensor([1.0675e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6077 --- loss: 0.000000\n",
      "tensor([1.0040e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6079 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6082 --- loss: 0.000161\n",
      "tensor([1.9004e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6084 --- loss: 0.000000\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6087 --- loss: 0.000616\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6089 --- loss: 0.000075\n",
      "tensor([1.7326e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6092 --- loss: 0.000017\n",
      "tensor([2.9099e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6095 --- loss: 0.000000\n",
      "tensor([4.8448e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6097 --- loss: 0.000048\n",
      "tensor([2.0280e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6100 --- loss: 0.000002\n",
      "tensor([2.3572e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6102 --- loss: 0.000024\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6105 --- loss: 0.000047\n",
      "tensor([0.9953], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6107 --- loss: 0.004700\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6110 --- loss: 0.000632\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6112 --- loss: 0.000115\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6115 --- loss: 0.000203\n",
      "tensor([9.2776e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6117 --- loss: 0.000001\n",
      "tensor([1.8974e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6120 --- loss: 0.000000\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6122 --- loss: 0.000750\n",
      "tensor([8.6862e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6125 --- loss: 0.000000\n",
      "tensor([0.7629], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6127 --- loss: 1.439154\n",
      "tensor([5.5891e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6130 --- loss: 0.000056\n",
      "tensor([1.2643e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6132 --- loss: 0.000013\n",
      "tensor([6.2010e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6135 --- loss: 0.000062\n",
      "tensor([0.9865], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6138 --- loss: 0.013635\n",
      "tensor([1.6154e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6140 --- loss: 0.000000\n",
      "tensor([1.1328e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6143 --- loss: 0.000001\n",
      "tensor([1.7401e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6145 --- loss: 0.000000\n",
      "tensor([9.0108e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6148 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6150 --- loss: 0.000184\n",
      "tensor([1.5304e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6153 --- loss: 0.000000\n",
      "tensor([0.9960], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6155 --- loss: 0.003996\n",
      "tensor([4.9510e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6158 --- loss: 0.000005\n",
      "tensor([1.9557e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6160 --- loss: 0.000002\n",
      "tensor([1.0149e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6163 --- loss: 0.000010\n",
      "tensor([0.3969], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6165 --- loss: 0.923989\n",
      "tensor([3.0563e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6168 --- loss: 0.000000\n",
      "tensor([5.1832e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6170 --- loss: 0.000000\n",
      "tensor([0.9907], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6173 --- loss: 0.009332\n",
      "tensor([7.2826e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6175 --- loss: 0.000000\n",
      "tensor([7.9214e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6178 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6180 --- loss: 0.000030\n",
      "tensor([1.5539e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6183 --- loss: 0.000000\n",
      "tensor([1.8676e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6186 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6188 --- loss: 0.000270\n",
      "tensor([0.9804], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6191 --- loss: 0.019775\n",
      "tensor([4.4440e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6193 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6196 --- loss: 0.000096\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6198 --- loss: 0.000561\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6201 --- loss: 0.000233\n",
      "tensor([7.8476e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6203 --- loss: 0.000078\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6206 --- loss: 0.000002\n",
      "tensor([0.9969], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6208 --- loss: 0.003058\n",
      "tensor([3.4184e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6211 --- loss: 0.000003\n",
      "tensor([1.7007e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6213 --- loss: 0.000000\n",
      "tensor([2.1615e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6216 --- loss: 0.000000\n",
      "tensor([1.7909e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6218 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6221 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6223 --- loss: 0.000016\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6226 --- loss: 0.000013\n",
      "tensor([7.9530e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6229 --- loss: 0.000000\n",
      "tensor([1.7196e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6231 --- loss: 0.000000\n",
      "tensor([9.5239e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6234 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6236 --- loss: 0.000002\n",
      "tensor([3.7373e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6239 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6241 --- loss: 0.000114\n",
      "tensor([2.2724e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6244 --- loss: 0.000023\n",
      "tensor([6.5129e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6246 --- loss: 0.000007\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6249 --- loss: 0.000110\n",
      "tensor([0.0390], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6251 --- loss: 0.039772\n",
      "tensor([5.8958e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6254 --- loss: 0.000000\n",
      "tensor([2.0274e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6256 --- loss: 0.000000\n",
      "tensor([2.3543e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6259 --- loss: 0.000002\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6261 --- loss: 0.000105\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6264 --- loss: 0.000538\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6266 --- loss: 0.000000\n",
      "tensor([6.9238e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6269 --- loss: 0.000001\n",
      "tensor([6.3561e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6271 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6274 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6277 --- loss: 0.000002\n",
      "tensor([1.4359e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6279 --- loss: 0.000001\n",
      "tensor([3.4015e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6282 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6284 --- loss: 0.000124\n",
      "tensor([2.6217e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6287 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6289 --- loss: 0.000243\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6292 --- loss: 0.000031\n",
      "tensor([2.0858e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6294 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6297 --- loss: 0.000000\n",
      "tensor([4.7031e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6299 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6302 --- loss: 0.000161\n",
      "tensor([3.6920e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6304 --- loss: 0.000037\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6307 --- loss: 0.000151\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6309 --- loss: 0.000002\n",
      "tensor([3.2228e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6312 --- loss: 0.000000\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6314 --- loss: 0.000767\n",
      "tensor([5.4202e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6317 --- loss: 0.000054\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6320 --- loss: 0.000001\n",
      "tensor([1.3664e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6322 --- loss: 0.000000\n",
      "tensor([1.7576e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6325 --- loss: 0.000000\n",
      "tensor([2.1204e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6327 --- loss: 0.000000\n",
      "tensor([7.7727e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6330 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6332 --- loss: 0.000175\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6335 --- loss: 0.000033\n",
      "tensor([8.6364e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6337 --- loss: 0.000000\n",
      "tensor([4.9968e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6340 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6342 --- loss: 0.000006\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6345 --- loss: 0.000060\n",
      "tensor([3.0171e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6347 --- loss: 0.000000\n",
      "tensor([2.5727e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6350 --- loss: 0.000026\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6352 --- loss: 0.000001\n",
      "tensor([0.1102], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6355 --- loss: 0.116709\n",
      "tensor([6.2891e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6357 --- loss: 0.000000\n",
      "tensor([4.8350e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6360 --- loss: 0.000005\n",
      "tensor([1.1237e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6362 --- loss: 0.000000\n",
      "tensor([6.9312e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6365 --- loss: 0.000007\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6368 --- loss: 0.000005\n",
      "tensor([0.8585], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6370 --- loss: 0.152528\n",
      "tensor([1.7503e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6373 --- loss: 0.000002\n",
      "tensor([1.0439e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6375 --- loss: 0.000010\n",
      "tensor([4.0465e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6378 --- loss: 0.000000\n",
      "tensor([7.5829e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6380 --- loss: 0.000000\n",
      "tensor([0.9971], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6383 --- loss: 0.002919\n",
      "tensor([4.4691e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6385 --- loss: 0.000000\n",
      "tensor([1.0357e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6388 --- loss: 0.000000\n",
      "tensor([0.0018], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6390 --- loss: 0.001798\n",
      "tensor([6.5043e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6393 --- loss: 0.000000\n",
      "tensor([3.4633e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6395 --- loss: 0.000000\n",
      "tensor([3.1091e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6398 --- loss: 0.000031\n",
      "tensor([0.0256], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6400 --- loss: 0.025906\n",
      "tensor([2.5503e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6403 --- loss: 0.000000\n",
      "tensor([1.1774e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6405 --- loss: 0.000001\n",
      "tensor([0.9789], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6408 --- loss: 0.021336\n",
      "tensor([0.9890], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6411 --- loss: 0.011038\n",
      "tensor([6.2720e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6413 --- loss: 0.000000\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6416 --- loss: 0.000353\n",
      "tensor([2.6419e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6418 --- loss: 0.000026\n",
      "tensor([4.2066e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6421 --- loss: 0.000000\n",
      "tensor([0.0123], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6423 --- loss: 0.012410\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6426 --- loss: 0.000480\n",
      "tensor([6.8946e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6428 --- loss: 0.000069\n",
      "tensor([1.2998e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6431 --- loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.4898e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6433 --- loss: 0.000000\n",
      "tensor([0.9897], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6436 --- loss: 0.010304\n",
      "tensor([7.9196e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6438 --- loss: 0.000000\n",
      "tensor([8.2642e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6441 --- loss: 0.000083\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6443 --- loss: 0.000050\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6446 --- loss: 0.000001\n",
      "tensor([1.8095e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6448 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6451 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6453 --- loss: 0.000032\n",
      "tensor([0.0018], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6456 --- loss: 0.001780\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6459 --- loss: 0.000294\n",
      "tensor([1.6255e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6461 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6464 --- loss: 0.000005\n",
      "tensor([0.9969], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6466 --- loss: 0.003112\n",
      "tensor([4.2302e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6469 --- loss: 0.000000\n",
      "tensor([9.7688e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6471 --- loss: 0.000000\n",
      "tensor([9.5165e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6474 --- loss: 0.000000\n",
      "tensor([4.6840e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6476 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6479 --- loss: 0.000175\n",
      "tensor([8.0511e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6481 --- loss: 0.000008\n",
      "tensor([5.3253e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6484 --- loss: 0.000053\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6486 --- loss: 0.000041\n",
      "tensor([1.8720e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6489 --- loss: 0.000000\n",
      "tensor([0.0233], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6491 --- loss: 0.023535\n",
      "tensor([5.3896e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6494 --- loss: 0.000000\n",
      "tensor([9.5494e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6496 --- loss: 0.000000\n",
      "tensor([2.1030e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6499 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6502 --- loss: 0.000086\n",
      "tensor([1.8745e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6504 --- loss: 0.000000\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6507 --- loss: 0.000646\n",
      "tensor([1.8704e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6509 --- loss: 0.000000\n",
      "tensor([5.4103e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6512 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6514 --- loss: 0.000001\n",
      "tensor([6.7985e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6517 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6519 --- loss: 0.000001\n",
      "tensor([1.1505e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6522 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6524 --- loss: 0.000015\n",
      "tensor([1.3059e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6527 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6529 --- loss: 0.000022\n",
      "tensor([1.9036e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6532 --- loss: 0.000000\n",
      "tensor([9.3084e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6534 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6537 --- loss: 0.000000\n",
      "tensor([5.6634e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6539 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6542 --- loss: 0.000003\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6544 --- loss: 0.000236\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6547 --- loss: 0.000013\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6550 --- loss: 0.000478\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6552 --- loss: 0.000054\n",
      "tensor([6.2778e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6555 --- loss: 0.000006\n",
      "tensor([9.7267e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6557 --- loss: 0.000097\n",
      "tensor([8.5524e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6560 --- loss: 0.000086\n",
      "tensor([6.1943e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6562 --- loss: 0.000000\n",
      "tensor([3.1817e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6565 --- loss: 0.000000\n",
      "tensor([0.0067], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6567 --- loss: 0.006686\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6570 --- loss: 0.000011\n",
      "tensor([0.0038], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6572 --- loss: 0.003820\n",
      "tensor([5.7429e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6575 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6577 --- loss: 0.000019\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6580 --- loss: 0.000772\n",
      "tensor([0.9923], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6582 --- loss: 0.007739\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6585 --- loss: 0.000016\n",
      "tensor([2.6857e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6587 --- loss: 0.000000\n",
      "tensor([7.0723e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6590 --- loss: 0.000000\n",
      "tensor([6.6753e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6593 --- loss: 0.000001\n",
      "tensor([2.5500e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6595 --- loss: 0.000000\n",
      "tensor([5.0494e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6598 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6600 --- loss: 0.000002\n",
      "tensor([2.8305e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6603 --- loss: 0.000003\n",
      "tensor([2.6332e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6605 --- loss: 0.000003\n",
      "tensor([2.7161e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6608 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6610 --- loss: 0.000007\n",
      "tensor([1.5306e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6613 --- loss: 0.000015\n",
      "tensor([4.5968e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6615 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6618 --- loss: 0.000006\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6620 --- loss: 0.000057\n",
      "tensor([1.2866e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6623 --- loss: 0.000000\n",
      "tensor([1.7779e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6625 --- loss: 0.000000\n",
      "tensor([3.7372e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6628 --- loss: 0.000000\n",
      "tensor([6.4096e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6630 --- loss: 0.000000\n",
      "tensor([6.2052e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6633 --- loss: 0.000062\n",
      "tensor([0.0028], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6635 --- loss: 0.002757\n",
      "tensor([2.8523e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6638 --- loss: 0.000003\n",
      "tensor([3.7896e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6641 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6643 --- loss: 0.000001\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6646 --- loss: 0.000602\n",
      "tensor([4.4496e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6648 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6651 --- loss: 0.000102\n",
      "tensor([2.2010e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6653 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6656 --- loss: 0.000003\n",
      "tensor([1.8063e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6658 --- loss: 0.000000\n",
      "tensor([4.6967e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6661 --- loss: 0.000005\n",
      "tensor([0.0048], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6663 --- loss: 0.004799\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6666 --- loss: 0.000020\n",
      "tensor([1.3406e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6668 --- loss: 0.000000\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6671 --- loss: 0.000628\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6673 --- loss: 0.000378\n",
      "tensor([2.9896e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6676 --- loss: 0.000000\n",
      "tensor([5.5897e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6678 --- loss: 0.000001\n",
      "tensor([1.2174e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6681 --- loss: 0.000012\n",
      "tensor([3.8531e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6684 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6686 --- loss: 0.000264\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6689 --- loss: 0.000170\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6691 --- loss: 0.000001\n",
      "tensor([3.5343e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6694 --- loss: 0.000000\n",
      "tensor([5.7339e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6696 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6699 --- loss: 0.000177\n",
      "tensor([5.6884e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6701 --- loss: 0.000000\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6704 --- loss: 0.000485\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6706 --- loss: 0.000003\n",
      "tensor([3.9173e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6709 --- loss: 0.000039\n",
      "tensor([1.9260e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6711 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6714 --- loss: 0.000044\n",
      "tensor([1.1291e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6716 --- loss: 0.000000\n",
      "tensor([2.0436e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6719 --- loss: 0.000002\n",
      "tensor([1.7858e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6721 --- loss: 0.000000\n",
      "tensor([5.2300e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6724 --- loss: 0.000005\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6726 --- loss: 0.000129\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6729 --- loss: 0.000433\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6732 --- loss: 0.000010\n",
      "tensor([2.1074e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6734 --- loss: 0.000002\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6737 --- loss: 0.000236\n",
      "tensor([2.6257e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6739 --- loss: 0.000000\n",
      "tensor([2.8010e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6742 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6744 --- loss: 0.000000\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6747 --- loss: 0.000389\n",
      "tensor([6.2266e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6749 --- loss: 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.1533e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6752 --- loss: 0.000000\n",
      "tensor([2.0253e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6754 --- loss: 0.000000\n",
      "tensor([4.2214e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6757 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6759 --- loss: 0.000090\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6762 --- loss: 0.000170\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6764 --- loss: 0.000013\n",
      "tensor([2.4105e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6767 --- loss: 0.000000\n",
      "tensor([5.3053e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6769 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6772 --- loss: 0.000032\n",
      "tensor([1.9410e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6775 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6777 --- loss: 0.000008\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6780 --- loss: 0.000175\n",
      "tensor([0.0023], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6782 --- loss: 0.002280\n",
      "tensor([5.1641e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6785 --- loss: 0.000052\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6787 --- loss: 0.000116\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6790 --- loss: 0.000001\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6792 --- loss: 0.000338\n",
      "tensor([6.2961e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6795 --- loss: 0.000000\n",
      "tensor([2.3977e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6797 --- loss: 0.000000\n",
      "tensor([9.2404e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6800 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6802 --- loss: 0.000001\n",
      "tensor([2.7766e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6805 --- loss: 0.000028\n",
      "tensor([2.2083e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6807 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6810 --- loss: 0.000007\n",
      "tensor([1.2120e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6812 --- loss: 0.000012\n",
      "tensor([1.8018e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6815 --- loss: 0.000000\n",
      "tensor([1.1683e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6817 --- loss: 0.000000\n",
      "tensor([1.0967e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6820 --- loss: 0.000011\n",
      "tensor([3.2382e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6823 --- loss: 0.000000\n",
      "tensor([7.9789e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6825 --- loss: 0.000000\n",
      "tensor([4.5864e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6828 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6830 --- loss: 0.000001\n",
      "tensor([3.6117e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6833 --- loss: 0.000036\n",
      "tensor([0.9980], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6835 --- loss: 0.002033\n",
      "tensor([0.9987], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6838 --- loss: 0.001289\n",
      "tensor([0.0014], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6840 --- loss: 0.001385\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6843 --- loss: 0.000446\n",
      "tensor([3.1980e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6845 --- loss: 0.000003\n",
      "tensor([9.5107e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6848 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6850 --- loss: 0.000007\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6853 --- loss: 0.000128\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6855 --- loss: 0.000111\n",
      "tensor([1.3968e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6858 --- loss: 0.000000\n",
      "tensor([0.9149], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6860 --- loss: 0.088889\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6863 --- loss: 0.000113\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6866 --- loss: 0.000026\n",
      "tensor([1.9347e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6868 --- loss: 0.000019\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6871 --- loss: 0.000013\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6873 --- loss: 0.000006\n",
      "tensor([1.9317e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6876 --- loss: 0.000019\n",
      "tensor([3.8320e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6878 --- loss: 0.000038\n",
      "tensor([0.0009], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6881 --- loss: 0.000884\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6883 --- loss: 0.000275\n",
      "tensor([1.8570e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6886 --- loss: 0.000002\n",
      "tensor([1.6481e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6888 --- loss: 0.000016\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6891 --- loss: 0.000360\n",
      "tensor([0.0009], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6893 --- loss: 0.000877\n",
      "tensor([0.0035], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6896 --- loss: 0.003504\n",
      "tensor([4.5791e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6898 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6901 --- loss: 0.000246\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6903 --- loss: 0.000000\n",
      "tensor([3.5811e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6906 --- loss: 0.000000\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6908 --- loss: 0.000517\n",
      "tensor([6.9018e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6911 --- loss: 0.000069\n",
      "tensor([4.9964e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6914 --- loss: 0.000050\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6916 --- loss: 0.000383\n",
      "tensor([4.6174e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6919 --- loss: 0.000000\n",
      "tensor([1.4200e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6921 --- loss: 0.000001\n",
      "tensor([1.6014e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6924 --- loss: 0.000000\n",
      "tensor([1.3572e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6926 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6929 --- loss: 0.000053\n",
      "tensor([0.0009], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6931 --- loss: 0.000879\n",
      "tensor([0.0015], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6934 --- loss: 0.001453\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6936 --- loss: 0.000010\n",
      "tensor([1.3110e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6939 --- loss: 0.000000\n",
      "tensor([1.8650e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6941 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6944 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6946 --- loss: 0.000016\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6949 --- loss: 0.000011\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6951 --- loss: 0.000000\n",
      "tensor([6.3474e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6954 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6957 --- loss: 0.000209\n",
      "tensor([3.3542e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6959 --- loss: 0.000000\n",
      "tensor([3.7705e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6962 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6964 --- loss: 0.000057\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6967 --- loss: 0.000000\n",
      "tensor([6.0225e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6969 --- loss: 0.000006\n",
      "tensor([5.1414e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6972 --- loss: 0.000051\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6974 --- loss: 0.000001\n",
      "tensor([2.3886e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6977 --- loss: 0.000024\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6979 --- loss: 0.000467\n",
      "tensor([5.5844e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6982 --- loss: 0.000006\n",
      "tensor([4.3189e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6984 --- loss: 0.000000\n",
      "tensor([6.0694e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6987 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6989 --- loss: 0.000116\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6992 --- loss: 0.000692\n",
      "tensor([1.8457e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6994 --- loss: 0.000000\n",
      "tensor([5.8399e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6997 --- loss: 0.000058\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6999 --- loss: 0.000001\n",
      "tensor([1.7478e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7002 --- loss: 0.000000\n",
      "tensor([2.0412e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7005 --- loss: 0.000000\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7007 --- loss: 0.000425\n",
      "tensor([6.4922e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7010 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7012 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7015 --- loss: 0.000000\n",
      "tensor([7.5134e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7017 --- loss: 0.000075\n",
      "tensor([5.5411e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7020 --- loss: 0.000001\n",
      "tensor([1.6326e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7022 --- loss: 0.000002\n",
      "tensor([8.0226e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7025 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7027 --- loss: 0.000005\n",
      "tensor([2.0623e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7030 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7032 --- loss: 0.000018\n",
      "tensor([6.5740e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7035 --- loss: 0.000000\n",
      "tensor([1.5656e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7037 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7040 --- loss: 0.000001\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7042 --- loss: 0.000105\n",
      "tensor([1.4510e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7045 --- loss: 0.000015\n",
      "tensor([6.1972e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7048 --- loss: 0.000000\n",
      "tensor([1.4949e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7050 --- loss: 0.000001\n",
      "tensor([3.1563e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7053 --- loss: 0.000000\n",
      "tensor([5.3833e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7055 --- loss: 0.000054\n",
      "tensor([0.4931], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7058 --- loss: 0.707001\n",
      "tensor([0.0028], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7060 --- loss: 0.002800\n",
      "tensor([1.1711e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7063 --- loss: 0.000012\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7065 --- loss: 0.000104\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7068 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7070 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7073 --- loss: 0.000012\n",
      "tensor([0.0018], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7075 --- loss: 0.001788\n",
      "tensor([0.0051], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7078 --- loss: 0.005067\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7080 --- loss: 0.000008\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7083 --- loss: 0.000015\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7085 --- loss: 0.000133\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7088 --- loss: 0.000012\n",
      "tensor([7.4769e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7090 --- loss: 0.000075\n",
      "tensor([4.1775e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7093 --- loss: 0.000042\n",
      "tensor([0.0680], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7096 --- loss: 0.070430\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7098 --- loss: 0.000121\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7101 --- loss: 0.000002\n",
      "tensor([4.9122e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7103 --- loss: 0.000049\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7106 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7108 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7111 --- loss: 0.000007\n",
      "tensor([0.0052], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7113 --- loss: 0.005248\n",
      "tensor([1.4753e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7116 --- loss: 0.000015\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7118 --- loss: 0.000003\n",
      "tensor([4.5953e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7121 --- loss: 0.000005\n",
      "tensor([1.0627e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7123 --- loss: 0.000001\n",
      "tensor([3.7381e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7126 --- loss: 0.000000\n",
      "tensor([5.0723e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7128 --- loss: 0.000000\n",
      "tensor([1.1570e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7131 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7133 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7136 --- loss: 0.000002\n",
      "tensor([0.0049], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7139 --- loss: 0.004916\n",
      "tensor([1.4308e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7141 --- loss: 0.000000\n",
      "tensor([0.9986], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7144 --- loss: 0.001428\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7146 --- loss: 0.000021\n",
      "tensor([5.0544e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7149 --- loss: 0.000051\n",
      "tensor([1.9572e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7151 --- loss: 0.000000\n",
      "tensor([0.0019], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7154 --- loss: 0.001883\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7156 --- loss: 0.000291\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7159 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7161 --- loss: 0.000005\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7164 --- loss: 0.000744\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7166 --- loss: 0.000332\n",
      "tensor([8.8513e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7169 --- loss: 0.000009\n",
      "tensor([1.8086e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7171 --- loss: 0.000000\n",
      "tensor([4.8755e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7174 --- loss: 0.000005\n",
      "tensor([8.3468e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7176 --- loss: 0.000083\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7179 --- loss: 0.000003\n",
      "tensor([0.0039], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7181 --- loss: 0.003890\n",
      "tensor([3.0257e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7184 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7187 --- loss: 0.000109\n",
      "tensor([4.4165e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7189 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7192 --- loss: 0.000091\n",
      "tensor([1.1736e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7194 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7197 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7199 --- loss: 0.000162\n",
      "tensor([3.3498e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7202 --- loss: 0.000000\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7204 --- loss: 0.000999\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7207 --- loss: 0.000619\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7209 --- loss: 0.000686\n",
      "tensor([0.0106], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7212 --- loss: 0.010664\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7214 --- loss: 0.000000\n",
      "tensor([9.8388e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7217 --- loss: 0.000098\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7219 --- loss: 0.000141\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7222 --- loss: 0.000850\n",
      "tensor([7.9881e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7224 --- loss: 0.000080\n",
      "tensor([1.3720e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7227 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7230 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7232 --- loss: 0.000000\n",
      "tensor([0.0051], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7235 --- loss: 0.005125\n",
      "tensor([2.1619e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7237 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7240 --- loss: 0.000012\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7242 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7245 --- loss: 0.000000\n",
      "tensor([1.6975e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7247 --- loss: 0.000000\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7250 --- loss: 0.000403\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7252 --- loss: 0.000000\n",
      "tensor([8.2383e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7255 --- loss: 0.000000\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7257 --- loss: 0.000420\n",
      "tensor([0.0014], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7260 --- loss: 0.001352\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7262 --- loss: 0.000012\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7265 --- loss: 0.000012\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7267 --- loss: 0.001050\n",
      "tensor([9.8835e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7270 --- loss: 0.000099\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7272 --- loss: 0.000008\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7275 --- loss: 0.000075\n",
      "tensor([6.2517e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7278 --- loss: 0.000000\n",
      "tensor([1.3199e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7280 --- loss: 0.000000\n",
      "tensor([6.0645e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7283 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7285 --- loss: 0.000143\n",
      "tensor([0.0060], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7288 --- loss: 0.006015\n",
      "tensor([2.5287e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7290 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7293 --- loss: 0.000161\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7295 --- loss: 0.000045\n",
      "tensor([0.0139], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7298 --- loss: 0.014033\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7300 --- loss: 0.000127\n",
      "tensor([0.0017], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7303 --- loss: 0.001749\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7305 --- loss: 0.000009\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7308 --- loss: 0.000080\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7310 --- loss: 0.000247\n",
      "tensor([0.9945], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7313 --- loss: 0.005532\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7315 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7318 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7321 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7323 --- loss: 0.000124\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7326 --- loss: 0.000018\n",
      "tensor([1.0760e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7328 --- loss: 0.000000\n",
      "tensor([2.7578e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7331 --- loss: 0.000000\n",
      "tensor([9.3351e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7333 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7336 --- loss: 0.000036\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7338 --- loss: 0.000022\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7341 --- loss: 0.000698\n",
      "tensor([8.2131e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7343 --- loss: 0.000000\n",
      "tensor([1.2545e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7346 --- loss: 0.000001\n",
      "tensor([0.0036], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7348 --- loss: 0.003652\n",
      "tensor([1.8039e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7351 --- loss: 0.000000\n",
      "tensor([1.6486e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7353 --- loss: 0.000000\n",
      "tensor([1.7925e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7356 --- loss: 0.000018\n",
      "tensor([4.8485e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7358 --- loss: 0.000048\n",
      "tensor([5.5432e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7361 --- loss: 0.000000\n",
      "tensor([2.7523e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7363 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7366 --- loss: 0.000012\n",
      "tensor([4.0565e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7369 --- loss: 0.000000\n",
      "tensor([0.9986], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7371 --- loss: 0.001440\n",
      "tensor([4.1255e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7374 --- loss: 0.000000\n",
      "tensor([3.4249e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7376 --- loss: 0.000000\n",
      "tensor([8.9624e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7379 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7381 --- loss: 0.000007\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7384 --- loss: 0.000449\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7386 --- loss: 0.000008\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7389 --- loss: 0.000028\n",
      "tensor([3.4250e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7391 --- loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7394 --- loss: 0.000153\n",
      "tensor([0.9986], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7396 --- loss: 0.001377\n",
      "tensor([3.9669e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7399 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7401 --- loss: 0.000013\n",
      "tensor([1.7808e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7404 --- loss: 0.000000\n",
      "tensor([2.2272e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7406 --- loss: 0.000002\n",
      "tensor([0.9967], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7409 --- loss: 0.003345\n",
      "tensor([6.2050e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7412 --- loss: 0.000000\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7414 --- loss: 0.000519\n",
      "tensor([0.0266], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7417 --- loss: 0.027008\n",
      "tensor([7.0499e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7419 --- loss: 0.000000\n",
      "tensor([9.5789e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7422 --- loss: 0.000001\n",
      "tensor([3.4388e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7424 --- loss: 0.000003\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7427 --- loss: 0.000702\n",
      "tensor([1.3692e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7429 --- loss: 0.000000\n",
      "tensor([0.0009], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7432 --- loss: 0.000856\n",
      "tensor([4.2555e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7434 --- loss: 0.000000\n",
      "tensor([9.8824e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7437 --- loss: 0.000099\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7439 --- loss: 0.000002\n",
      "tensor([0.0062], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7442 --- loss: 0.006251\n",
      "tensor([0.0111], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7444 --- loss: 0.011169\n",
      "tensor([0.0054], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7447 --- loss: 0.005428\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7449 --- loss: 0.000008\n",
      "tensor([5.8607e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7452 --- loss: 0.000059\n",
      "tensor([1.6068e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7454 --- loss: 0.000000\n",
      "tensor([1.3596e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7457 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7460 --- loss: 0.000002\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7462 --- loss: 0.000131\n",
      "tensor([1.2600e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7465 --- loss: 0.000013\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7467 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7470 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7472 --- loss: 0.000000\n",
      "tensor([3.4698e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7475 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7477 --- loss: 0.000191\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7480 --- loss: 0.000069\n",
      "tensor([4.6713e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7482 --- loss: 0.000000\n",
      "tensor([4.8685e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7485 --- loss: 0.000005\n",
      "tensor([1.3431e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7487 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7490 --- loss: 0.000038\n",
      "tensor([2.9978e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7492 --- loss: 0.000030\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7495 --- loss: 0.000003\n",
      "tensor([0.9969], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7497 --- loss: 0.003106\n",
      "tensor([1.8317e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7500 --- loss: 0.000002\n",
      "tensor([1.5954e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7503 --- loss: 0.000016\n",
      "tensor([1.2370e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7505 --- loss: 0.000012\n",
      "tensor([5.8394e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7508 --- loss: 0.000000\n",
      "tensor([2.0471e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7510 --- loss: 0.000000\n",
      "tensor([6.5157e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7513 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7515 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7518 --- loss: 0.000000\n",
      "tensor([9.0622e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7520 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7523 --- loss: 0.000001\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7525 --- loss: 0.000763\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7528 --- loss: 0.000092\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7530 --- loss: 0.000420\n",
      "tensor([1.0590e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7533 --- loss: 0.000001\n",
      "tensor([2.2823e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7535 --- loss: 0.000000\n",
      "tensor([0.0166], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7538 --- loss: 0.016720\n",
      "tensor([6.0950e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7540 --- loss: 0.000061\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7543 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7546 --- loss: 0.000001\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7548 --- loss: 0.000589\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7551 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7553 --- loss: 0.000030\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7556 --- loss: 0.000002\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7558 --- loss: 0.000975\n",
      "tensor([7.4247e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7561 --- loss: 0.000000\n",
      "tensor([9.4851e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7563 --- loss: 0.000095\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7566 --- loss: 0.000107\n",
      "tensor([0.9979], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7568 --- loss: 0.002056\n",
      "tensor([4.1087e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7571 --- loss: 0.000000\n",
      "tensor([6.3062e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7573 --- loss: 0.000006\n",
      "tensor([6.0546e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7576 --- loss: 0.000061\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7578 --- loss: 0.000036\n",
      "tensor([0.8471], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7581 --- loss: 1.877928\n",
      "tensor([1.0266e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7583 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7586 --- loss: 0.000096\n",
      "tensor([8.9730e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7588 --- loss: 0.000000\n",
      "tensor([6.9079e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7591 --- loss: 0.000069\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7594 --- loss: 0.000290\n",
      "tensor([2.8865e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7596 --- loss: 0.000029\n",
      "tensor([4.0309e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7599 --- loss: 0.000000\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7601 --- loss: 0.000352\n",
      "tensor([8.9584e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7604 --- loss: 0.000090\n",
      "tensor([0.9975], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7606 --- loss: 0.002521\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7609 --- loss: 0.000891\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7611 --- loss: 0.000067\n",
      "tensor([2.2736e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7614 --- loss: 0.000023\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7616 --- loss: 0.000764\n",
      "tensor([9.2438e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7619 --- loss: 0.000009\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7621 --- loss: 0.000072\n",
      "tensor([7.5857e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7624 --- loss: 0.000000\n",
      "tensor([5.7253e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7626 --- loss: 0.000001\n",
      "tensor([5.3857e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7629 --- loss: 0.000000\n",
      "tensor([1.4036e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7631 --- loss: 0.000000\n",
      "tensor([2.2345e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7634 --- loss: 0.000000\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7637 --- loss: 0.000387\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7639 --- loss: 0.000180\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7642 --- loss: 0.000253\n",
      "tensor([1.0149e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7644 --- loss: 0.000000\n",
      "tensor([5.2465e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7647 --- loss: 0.000005\n",
      "tensor([3.0900e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7649 --- loss: 0.000000\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7652 --- loss: 0.000414\n",
      "tensor([2.1384e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7654 --- loss: 0.000000\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7657 --- loss: 0.000512\n",
      "tensor([1.5902e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7659 --- loss: 0.000002\n",
      "tensor([7.4070e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7662 --- loss: 0.000007\n",
      "tensor([8.2826e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7664 --- loss: 0.000083\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7667 --- loss: 0.000849\n",
      "tensor([1.5916e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7669 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7672 --- loss: 0.000246\n",
      "tensor([1.2133e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7674 --- loss: 0.000000\n",
      "tensor([4.9384e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7677 --- loss: 0.000000\n",
      "tensor([0.9977], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7679 --- loss: 0.002257\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7682 --- loss: 0.000102\n",
      "tensor([0.0029], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7685 --- loss: 0.002920\n",
      "tensor([0.0016], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7687 --- loss: 0.001641\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7690 --- loss: 0.000217\n",
      "tensor([0.6264], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7692 --- loss: 0.467747\n",
      "tensor([1.2455e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7695 --- loss: 0.000012\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7697 --- loss: 0.000178\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7700 --- loss: 0.000002\n",
      "tensor([6.2496e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7702 --- loss: 0.000001\n",
      "tensor([7.3084e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7705 --- loss: 0.000007\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7707 --- loss: 0.000126\n",
      "tensor([0.9966], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7710 --- loss: 0.003356\n",
      "tensor([4.4039e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7712 --- loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5038e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7715 --- loss: 0.000000\n",
      "tensor([9.9413e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7717 --- loss: 0.000010\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7720 --- loss: 0.000572\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7722 --- loss: 0.000000\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7725 --- loss: 0.000704\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7728 --- loss: 0.001168\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7730 --- loss: 0.000450\n",
      "tensor([1.8568e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7733 --- loss: 0.000000\n",
      "tensor([1.1029e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7735 --- loss: 0.000011\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7738 --- loss: 0.000001\n",
      "tensor([3.7562e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7740 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7743 --- loss: 0.000091\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7745 --- loss: 0.000001\n",
      "tensor([2.9382e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7748 --- loss: 0.000003\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7750 --- loss: 0.000269\n",
      "tensor([3.2093e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7753 --- loss: 0.000000\n",
      "tensor([6.3908e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7755 --- loss: 0.000000\n",
      "tensor([1.6468e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7758 --- loss: 0.000000\n",
      "tensor([4.0213e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7760 --- loss: 0.000000\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7763 --- loss: 0.000272\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7765 --- loss: 0.000890\n",
      "tensor([1.0448e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7768 --- loss: 0.000000\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7770 --- loss: 0.000572\n",
      "tensor([3.6775e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7773 --- loss: 0.000037\n",
      "tensor([7.4029e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7776 --- loss: 0.000074\n",
      "tensor([1.8420e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7778 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7781 --- loss: 0.000009\n",
      "tensor([1.3014e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7783 --- loss: 0.000013\n",
      "tensor([2.4953e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7786 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7788 --- loss: 0.000001\n",
      "tensor([4.6527e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7791 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7793 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7796 --- loss: 0.000010\n",
      "tensor([4.6095e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7798 --- loss: 0.000005\n",
      "tensor([1.8308e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7801 --- loss: 0.000000\n",
      "tensor([9.2754e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7803 --- loss: 0.000000\n",
      "tensor([4.1168e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7806 --- loss: 0.000000\n",
      "tensor([1.0396e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7808 --- loss: 0.000001\n",
      "tensor([0.0022], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7811 --- loss: 0.002220\n",
      "tensor([3.0070e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7813 --- loss: 0.000000\n",
      "tensor([0.0016], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7816 --- loss: 0.001635\n",
      "tensor([0.9944], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7819 --- loss: 0.005620\n",
      "tensor([2.1887e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7821 --- loss: 0.000000\n",
      "tensor([3.0967e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7824 --- loss: 0.000000\n",
      "tensor([7.6746e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7826 --- loss: 0.000077\n",
      "tensor([2.0099e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7829 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7831 --- loss: 0.000004\n",
      "tensor([0.9873], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7834 --- loss: 0.012819\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7836 --- loss: 0.000003\n",
      "tensor([3.4609e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7839 --- loss: 0.000000\n",
      "tensor([0.0016], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7841 --- loss: 0.001631\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7844 --- loss: 0.000001\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7846 --- loss: 0.000609\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7849 --- loss: 0.000020\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7851 --- loss: 0.000682\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7854 --- loss: 0.000008\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7856 --- loss: 0.000301\n",
      "tensor([0.9986], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7859 --- loss: 0.001431\n",
      "tensor([3.5964e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7861 --- loss: 0.000000\n",
      "tensor([1.5089e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7864 --- loss: 0.000000\n",
      "tensor([5.0479e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7867 --- loss: 0.000000\n",
      "tensor([3.4443e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7869 --- loss: 0.000034\n",
      "tensor([4.9568e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7872 --- loss: 0.000000\n",
      "tensor([1.0554e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7874 --- loss: 0.000011\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7877 --- loss: 0.000003\n",
      "tensor([6.7638e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7879 --- loss: 0.000068\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7882 --- loss: 0.000006\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7884 --- loss: 0.000090\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7887 --- loss: 0.000004\n",
      "tensor([2.0107e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7889 --- loss: 0.000002\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7892 --- loss: 0.000272\n",
      "tensor([7.4344e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7894 --- loss: 0.000007\n",
      "tensor([2.0107e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7897 --- loss: 0.000000\n",
      "tensor([1.2786e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7899 --- loss: 0.000013\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7902 --- loss: 0.000004\n",
      "tensor([0.0013], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7904 --- loss: 0.001307\n",
      "tensor([2.0356e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7907 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7910 --- loss: 0.000002\n",
      "tensor([3.1097e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7912 --- loss: 0.000031\n",
      "tensor([5.9314e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7915 --- loss: 0.000000\n",
      "tensor([0.0012], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7917 --- loss: 0.001180\n",
      "tensor([1.2038e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7920 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7922 --- loss: 0.000001\n",
      "tensor([1.5014e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7925 --- loss: 0.000015\n",
      "tensor([0.0101], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7927 --- loss: 0.010135\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7930 --- loss: 0.000005\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7932 --- loss: 0.000533\n",
      "tensor([0.9343], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7935 --- loss: 0.067961\n",
      "tensor([2.0209e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7937 --- loss: 0.000020\n",
      "tensor([1.7301e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7940 --- loss: 0.000002\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7942 --- loss: 0.000429\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7945 --- loss: 0.000617\n",
      "tensor([2.1945e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7947 --- loss: 0.000022\n",
      "tensor([2.1372e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7950 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7952 --- loss: 0.000018\n",
      "tensor([3.7721e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7955 --- loss: 0.000000\n",
      "tensor([1.6542e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7958 --- loss: 0.000002\n",
      "tensor([1.6194e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7960 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7963 --- loss: 0.000005\n",
      "tensor([3.2676e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7965 --- loss: 0.000033\n",
      "tensor([8.2295e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7968 --- loss: 0.000000\n",
      "tensor([5.5813e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7970 --- loss: 0.000000\n",
      "tensor([0.0051], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7973 --- loss: 0.005122\n",
      "tensor([6.9214e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7975 --- loss: 0.000069\n",
      "tensor([0.9986], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7978 --- loss: 0.001373\n",
      "tensor([2.8759e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7980 --- loss: 0.000003\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7983 --- loss: 0.000281\n",
      "tensor([6.9044e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7985 --- loss: 0.000001\n",
      "tensor([1.6077e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7988 --- loss: 0.000000\n",
      "tensor([1.0801e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7990 --- loss: 0.000000\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7993 --- loss: 0.000733\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7995 --- loss: 0.000008\n",
      "tensor([0.0014], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7998 --- loss: 0.001392\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8001 --- loss: 0.000000\n",
      "tensor([0.0080], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8003 --- loss: 0.007990\n",
      "tensor([0.0075], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8006 --- loss: 0.007575\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8008 --- loss: 0.000496\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8011 --- loss: 0.000025\n",
      "tensor([1.2102e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8013 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8016 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8018 --- loss: 0.000045\n",
      "tensor([0.0074], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8021 --- loss: 0.007458\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8023 --- loss: 0.000147\n",
      "tensor([2.6057e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8026 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8028 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8031 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8033 --- loss: 0.000006\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8036 --- loss: 0.000378\n",
      "tensor([1.2346e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8038 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8041 --- loss: 0.000005\n",
      "tensor([1.8183e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8043 --- loss: 0.000018\n",
      "tensor([4.3318e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8046 --- loss: 0.000000\n",
      "tensor([2.9162e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8049 --- loss: 0.000000\n",
      "tensor([7.4155e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8051 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8054 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8056 --- loss: 0.000014\n",
      "tensor([7.1266e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8059 --- loss: 0.000000\n",
      "tensor([3.6978e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8061 --- loss: 0.000000\n",
      "tensor([6.2604e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8064 --- loss: 0.000000\n",
      "tensor([1.4704e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8066 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8069 --- loss: 0.000005\n",
      "tensor([7.5652e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8071 --- loss: 0.000008\n",
      "tensor([1.8589e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8074 --- loss: 0.000002\n",
      "tensor([6.2672e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8076 --- loss: 0.000063\n",
      "tensor([9.2034e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8079 --- loss: 0.000000\n",
      "tensor([1.5019e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8081 --- loss: 0.000000\n",
      "tensor([8.9389e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8084 --- loss: 0.000000\n",
      "tensor([2.7946e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8086 --- loss: 0.000000\n",
      "tensor([2.0971e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8089 --- loss: 0.000000\n",
      "tensor([1.1275e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8092 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8094 --- loss: 0.000002\n",
      "tensor([2.4892e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8097 --- loss: 0.000000\n",
      "tensor([5.0745e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8099 --- loss: 0.000005\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8102 --- loss: 0.000149\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8104 --- loss: 0.000002\n",
      "tensor([1.8836e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8107 --- loss: 0.000002\n",
      "tensor([1.7613e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8109 --- loss: 0.000000\n",
      "tensor([4.4726e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8112 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8114 --- loss: 0.000205\n",
      "tensor([3.1212e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8117 --- loss: 0.000000\n",
      "tensor([3.7685e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8119 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8122 --- loss: 0.000003\n",
      "tensor([1.2421e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8124 --- loss: 0.000012\n",
      "tensor([4.1809e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8127 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8129 --- loss: 0.000226\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8132 --- loss: 0.000557\n",
      "tensor([4.9672e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8134 --- loss: 0.000000\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8137 --- loss: 0.000844\n",
      "tensor([6.2013e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8140 --- loss: 0.000000\n",
      "tensor([3.5587e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8142 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8145 --- loss: 0.000007\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8147 --- loss: 0.000035\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8150 --- loss: 0.000038\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8152 --- loss: 0.000012\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8155 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8157 --- loss: 0.000051\n",
      "tensor([0.0049], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8160 --- loss: 0.004917\n",
      "tensor([0.0038], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8162 --- loss: 0.003814\n",
      "tensor([1.4721e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8165 --- loss: 0.000015\n",
      "tensor([4.2464e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8167 --- loss: 0.000000\n",
      "tensor([5.1550e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8170 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8172 --- loss: 0.000009\n",
      "tensor([1.9525e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8175 --- loss: 0.000000\n",
      "tensor([2.6780e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8177 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8180 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8183 --- loss: 0.000000\n",
      "tensor([4.2088e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8185 --- loss: 0.000000\n",
      "tensor([0.0053], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8188 --- loss: 0.005354\n",
      "tensor([1.1264e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8190 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8193 --- loss: 0.000005\n",
      "tensor([1.7655e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8195 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8198 --- loss: 0.000009\n",
      "tensor([2.9493e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8200 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8203 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8205 --- loss: 0.000007\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8208 --- loss: 0.000001\n",
      "tensor([0.9985], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8210 --- loss: 0.001511\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8213 --- loss: 0.000007\n",
      "tensor([2.3328e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8215 --- loss: 0.000002\n",
      "tensor([0.9919], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8218 --- loss: 0.008107\n",
      "tensor([5.4932e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8220 --- loss: 0.000000\n",
      "tensor([1.4044e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8223 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8225 --- loss: 0.000173\n",
      "tensor([6.0260e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8228 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8231 --- loss: 0.000006\n",
      "tensor([5.6636e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8233 --- loss: 0.000057\n",
      "tensor([4.2274e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8236 --- loss: 0.000000\n",
      "tensor([4.5204e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8238 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8241 --- loss: 0.000145\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8243 --- loss: 0.000187\n",
      "tensor([0.0088], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8246 --- loss: 0.008808\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8248 --- loss: 0.000001\n",
      "tensor([0.0329], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8251 --- loss: 0.033455\n",
      "tensor([3.0758e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8253 --- loss: 0.000003\n",
      "tensor([1.8455e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8256 --- loss: 0.000018\n",
      "tensor([6.2814e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8258 --- loss: 0.000006\n",
      "tensor([5.3079e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8261 --- loss: 0.000005\n",
      "tensor([3.3357e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8263 --- loss: 0.000003\n",
      "tensor([2.0191e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8266 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8268 --- loss: 0.000013\n",
      "tensor([1.4185e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8271 --- loss: 0.000000\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8274 --- loss: 0.001045\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8276 --- loss: 0.000008\n",
      "tensor([4.2304e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8279 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8281 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8284 --- loss: 0.000017\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8286 --- loss: 0.000015\n",
      "tensor([6.5164e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8289 --- loss: 0.000007\n",
      "tensor([3.2587e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8291 --- loss: 0.000000\n",
      "tensor([3.5581e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8294 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8296 --- loss: 0.000003\n",
      "tensor([4.3631e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8299 --- loss: 0.000000\n",
      "tensor([0.9940], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8301 --- loss: 0.005971\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8304 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8306 --- loss: 0.000004\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8309 --- loss: 0.000222\n",
      "tensor([1.6855e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8311 --- loss: 0.000000\n",
      "tensor([2.6904e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8314 --- loss: 0.000000\n",
      "tensor([1.5451e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8316 --- loss: 0.000000\n",
      "tensor([0.0014], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8319 --- loss: 0.001375\n",
      "tensor([4.0936e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8322 --- loss: 0.000041\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8324 --- loss: 0.000024\n",
      "tensor([8.2171e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8327 --- loss: 0.000000\n",
      "tensor([1.9493e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8329 --- loss: 0.000002\n",
      "tensor([1.0595e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8332 --- loss: 0.000001\n",
      "tensor([1.8068e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8334 --- loss: 0.000018\n",
      "tensor([3.7259e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8337 --- loss: 0.000037\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8339 --- loss: 0.000009\n",
      "tensor([4.1293e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8342 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8344 --- loss: 0.000000\n",
      "tensor([1.3356e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8347 --- loss: 0.000013\n",
      "tensor([6.1752e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8349 --- loss: 0.000062\n",
      "tensor([2.5170e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8352 --- loss: 0.000003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.6621e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8354 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8357 --- loss: 0.000001\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8359 --- loss: 0.000194\n",
      "tensor([0.0015], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8362 --- loss: 0.001485\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8365 --- loss: 0.000012\n",
      "tensor([4.6334e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8367 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8370 --- loss: 0.000145\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8372 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8375 --- loss: 0.000015\n",
      "tensor([1.0157e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8377 --- loss: 0.000001\n",
      "tensor([1.8602e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8380 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8382 --- loss: 0.000011\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8385 --- loss: 0.000995\n",
      "tensor([6.4822e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8387 --- loss: 0.000065\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8390 --- loss: 0.000014\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8392 --- loss: 0.000001\n",
      "tensor([1.3473e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8395 --- loss: 0.000000\n",
      "tensor([5.4598e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8397 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8400 --- loss: 0.000108\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8402 --- loss: 0.000195\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8405 --- loss: 0.000001\n",
      "tensor([1.8058e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8407 --- loss: 0.000002\n",
      "tensor([9.3100e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8410 --- loss: 0.000093\n",
      "tensor([2.7019e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8413 --- loss: 0.000003\n",
      "tensor([4.0310e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8415 --- loss: 0.000040\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8418 --- loss: 0.000009\n",
      "tensor([3.6893e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8420 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8423 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8425 --- loss: 0.000004\n",
      "tensor([5.8653e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8428 --- loss: 0.000000\n",
      "tensor([6.4432e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8430 --- loss: 0.000006\n",
      "tensor([9.2294e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8433 --- loss: 0.000009\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8435 --- loss: 0.000105\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8438 --- loss: 0.000008\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8440 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8443 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8445 --- loss: 0.000001\n",
      "tensor([1.1388e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8448 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8450 --- loss: 0.000005\n",
      "tensor([0.0011], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8453 --- loss: 0.001127\n",
      "tensor([2.3254e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8456 --- loss: 0.000002\n",
      "tensor([2.7562e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8458 --- loss: 0.000000\n",
      "tensor([0.9858], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8461 --- loss: 0.014291\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8463 --- loss: 0.000204\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8466 --- loss: 0.000010\n",
      "tensor([8.3913e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8468 --- loss: 0.000008\n",
      "tensor([5.3874e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8471 --- loss: 0.000000\n",
      "tensor([7.0631e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8473 --- loss: 0.000000\n",
      "tensor([3.0533e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8476 --- loss: 0.000031\n",
      "tensor([1.8962e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8478 --- loss: 0.000000\n",
      "tensor([2.8607e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8481 --- loss: 0.000029\n",
      "tensor([6.7599e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8483 --- loss: 0.000068\n",
      "tensor([0.9983], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8486 --- loss: 0.001713\n",
      "tensor([8.8084e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8488 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8491 --- loss: 0.000005\n",
      "tensor([4.1342e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8493 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8496 --- loss: 0.000001\n",
      "tensor([2.3797e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8498 --- loss: 0.000000\n",
      "tensor([4.7519e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8501 --- loss: 0.000048\n",
      "tensor([3.5747e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8504 --- loss: 0.000000\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8506 --- loss: 0.000394\n",
      "tensor([7.4580e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8509 --- loss: 0.000001\n",
      "tensor([2.2489e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8511 --- loss: 0.000000\n",
      "tensor([1.3171e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8514 --- loss: 0.000013\n",
      "tensor([1.9599e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8516 --- loss: 0.000020\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8519 --- loss: 0.000296\n",
      "tensor([5.9813e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8521 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8524 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8526 --- loss: 0.000012\n",
      "tensor([9.1595e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8529 --- loss: 0.000001\n",
      "tensor([1.3256e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8531 --- loss: 0.000013\n",
      "tensor([0.0014], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8534 --- loss: 0.001369\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8536 --- loss: 0.000007\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8539 --- loss: 0.000913\n",
      "tensor([1.5710e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8541 --- loss: 0.000000\n",
      "tensor([3.1020e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8544 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8547 --- loss: 0.000087\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8549 --- loss: 0.000001\n",
      "tensor([4.1265e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8552 --- loss: 0.000000\n",
      "tensor([0.0065], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8554 --- loss: 0.006561\n",
      "tensor([3.2132e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8557 --- loss: 0.000032\n",
      "tensor([8.0470e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8559 --- loss: 0.000000\n",
      "tensor([7.2192e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8562 --- loss: 0.000000\n",
      "tensor([1.3965e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8564 --- loss: 0.000014\n",
      "tensor([1.1443e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8567 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8569 --- loss: 0.000042\n",
      "tensor([0.9960], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8572 --- loss: 0.004043\n",
      "tensor([3.3240e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8574 --- loss: 0.000003\n",
      "tensor([0.6836], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8577 --- loss: 0.380455\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8579 --- loss: 0.000076\n",
      "tensor([1.3070e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8582 --- loss: 0.000013\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8584 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8587 --- loss: 0.000033\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8589 --- loss: 0.000003\n",
      "tensor([7.9686e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8592 --- loss: 0.000080\n",
      "tensor([1.0503e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8595 --- loss: 0.000000\n",
      "tensor([3.6030e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8597 --- loss: 0.000036\n",
      "tensor([1.5033e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8600 --- loss: 0.000002\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8602 --- loss: 0.000363\n",
      "tensor([2.9590e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8605 --- loss: 0.000030\n",
      "tensor([6.2209e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8607 --- loss: 0.000062\n",
      "tensor([1.1618e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8610 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8612 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8615 --- loss: 0.000011\n",
      "tensor([9.3425e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8617 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8620 --- loss: 0.000000\n",
      "tensor([4.3434e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8622 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8625 --- loss: 0.000000\n",
      "tensor([1.4131e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8627 --- loss: 0.000000\n",
      "tensor([4.9755e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8630 --- loss: 0.000000\n",
      "tensor([0.0017], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8632 --- loss: 0.001653\n",
      "tensor([2.7967e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8635 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8638 --- loss: 0.000007\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8640 --- loss: 0.000182\n",
      "tensor([2.4470e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8643 --- loss: 0.000002\n",
      "tensor([5.7412e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8645 --- loss: 0.000057\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8648 --- loss: 0.000000\n",
      "tensor([6.9141e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8650 --- loss: 0.000000\n",
      "tensor([1.2395e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8653 --- loss: 0.000001\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8655 --- loss: 0.000314\n",
      "tensor([7.2266e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8658 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8660 --- loss: 0.000105\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8663 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8665 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8668 --- loss: 0.000103\n",
      "tensor([6.1453e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8670 --- loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7.7208e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8673 --- loss: 0.000077\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8675 --- loss: 0.000001\n",
      "tensor([1.2218e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8678 --- loss: 0.000000\n",
      "tensor([2.5743e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8680 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8683 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8686 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8688 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8691 --- loss: 0.000000\n",
      "tensor([7.3556e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8693 --- loss: 0.000007\n",
      "tensor([3.4010e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8696 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8698 --- loss: 0.000005\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8701 --- loss: 0.000434\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8703 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8706 --- loss: 0.000001\n",
      "tensor([2.9449e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8708 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8711 --- loss: 0.000019\n",
      "tensor([3.5352e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8713 --- loss: 0.000000\n",
      "tensor([7.2921e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8716 --- loss: 0.000073\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8718 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8721 --- loss: 0.000001\n",
      "tensor([1.4668e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8723 --- loss: 0.000000\n",
      "tensor([3.7230e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8726 --- loss: 0.000037\n",
      "tensor([0.0070], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8729 --- loss: 0.007029\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8731 --- loss: 0.000001\n",
      "tensor([2.3986e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8734 --- loss: 0.000000\n",
      "tensor([0.0175], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8736 --- loss: 0.017631\n",
      "tensor([1.6988e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8739 --- loss: 0.000017\n",
      "tensor([0.0266], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8741 --- loss: 0.026909\n",
      "tensor([2.4973e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8744 --- loss: 0.000002\n",
      "tensor([1.3680e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8746 --- loss: 0.000001\n",
      "tensor([3.3676e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8749 --- loss: 0.000003\n",
      "tensor([1.8407e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8751 --- loss: 0.000002\n",
      "tensor([8.0543e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8754 --- loss: 0.000081\n",
      "tensor([5.6884e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8756 --- loss: 0.000006\n",
      "tensor([0.0072], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8759 --- loss: 0.007258\n",
      "tensor([2.0588e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8761 --- loss: 0.000021\n",
      "tensor([0.0078], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8764 --- loss: 0.007876\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8766 --- loss: 0.000000\n",
      "tensor([3.6399e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8769 --- loss: 0.000004\n",
      "tensor([1.3219e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8771 --- loss: 0.000013\n",
      "tensor([2.1466e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8774 --- loss: 0.000021\n",
      "tensor([8.8968e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8777 --- loss: 0.000009\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8779 --- loss: 0.000001\n",
      "tensor([1.5314e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8782 --- loss: 0.000002\n",
      "tensor([0.0082], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8784 --- loss: 0.008252\n",
      "tensor([1.8792e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8787 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8789 --- loss: 0.000000\n",
      "tensor([2.4374e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8792 --- loss: 0.000000\n",
      "tensor([7.3196e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8794 --- loss: 0.000073\n",
      "tensor([2.5332e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8797 --- loss: 0.000025\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8799 --- loss: 0.000155\n",
      "tensor([8.5296e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8802 --- loss: 0.000000\n",
      "tensor([4.5869e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8804 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8807 --- loss: 0.000000\n",
      "tensor([1.9430e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8809 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8812 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8814 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8817 --- loss: 0.000003\n",
      "tensor([0.0014], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8820 --- loss: 0.001365\n",
      "tensor([1.0640e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8822 --- loss: 0.000011\n",
      "tensor([2.5663e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8825 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8827 --- loss: 0.000001\n",
      "tensor([0.0241], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8830 --- loss: 0.024396\n",
      "tensor([3.2163e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8832 --- loss: 0.000000\n",
      "tensor([5.5155e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8835 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8837 --- loss: 0.000001\n",
      "tensor([9.8261e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8840 --- loss: 0.000001\n",
      "tensor([0.0015], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8842 --- loss: 0.001515\n",
      "tensor([2.7723e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8845 --- loss: 0.000003\n",
      "tensor([2.8424e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8847 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8850 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8852 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8855 --- loss: 0.000002\n",
      "tensor([2.9917e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8857 --- loss: 0.000000\n",
      "tensor([1.8459e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8860 --- loss: 0.000002\n",
      "tensor([4.5614e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8862 --- loss: 0.000046\n",
      "tensor([6.1402e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8865 --- loss: 0.000006\n",
      "tensor([0.0016], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8868 --- loss: 0.001574\n",
      "tensor([3.0402e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8870 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8873 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8875 --- loss: 0.000037\n",
      "tensor([1.8590e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8878 --- loss: 0.000019\n",
      "tensor([2.1193e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8880 --- loss: 0.000002\n",
      "tensor([4.8087e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8883 --- loss: 0.000000\n",
      "tensor([7.0545e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8885 --- loss: 0.000007\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8888 --- loss: 0.000023\n",
      "tensor([3.4559e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8890 --- loss: 0.000000\n",
      "tensor([1.6644e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8893 --- loss: 0.000002\n",
      "tensor([9.7172e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8895 --- loss: 0.000000\n",
      "tensor([0.0041], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8898 --- loss: 0.004154\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8900 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8903 --- loss: 0.000005\n",
      "tensor([3.2268e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8905 --- loss: 0.000032\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8908 --- loss: 0.000001\n",
      "tensor([3.1312e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8911 --- loss: 0.000000\n",
      "tensor([0.0899], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8913 --- loss: 0.094176\n",
      "tensor([1.5268e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8916 --- loss: 0.000000\n",
      "tensor([1.3036e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8918 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8921 --- loss: 0.000016\n",
      "tensor([9.3553e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8923 --- loss: 0.000009\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8926 --- loss: 0.000002\n",
      "tensor([2.7479e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8928 --- loss: 0.000003\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8931 --- loss: 0.000124\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8933 --- loss: 0.000014\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8936 --- loss: 0.000417\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8938 --- loss: 0.000001\n",
      "tensor([4.6767e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8941 --- loss: 0.000000\n",
      "tensor([9.0588e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8943 --- loss: 0.000091\n",
      "tensor([4.9113e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8946 --- loss: 0.000005\n",
      "tensor([9.8667e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8948 --- loss: 0.000001\n",
      "tensor([5.3529e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8951 --- loss: 0.000001\n",
      "tensor([1.6346e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8953 --- loss: 0.000002\n",
      "tensor([2.0558e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8956 --- loss: 0.000000\n",
      "tensor([0.0477], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8959 --- loss: 0.048880\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8961 --- loss: 0.000299\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8964 --- loss: 0.000000\n",
      "tensor([6.7237e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8966 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8969 --- loss: 0.000006\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8971 --- loss: 0.000129\n",
      "tensor([0.0091], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8974 --- loss: 0.009175\n",
      "tensor([8.5023e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8976 --- loss: 0.000000\n",
      "tensor([1.7677e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8979 --- loss: 0.000000\n",
      "tensor([3.1294e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8981 --- loss: 0.000031\n",
      "tensor([8.3612e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8984 --- loss: 0.000001\n",
      "tensor([1.7670e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8986 --- loss: 0.000000\n",
      "tensor([6.8052e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8989 --- loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0837e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8991 --- loss: 0.000002\n",
      "tensor([0.0030], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8994 --- loss: 0.003018\n",
      "tensor([0.0339], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8996 --- loss: 0.034449\n",
      "tensor([0.0013], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8999 --- loss: 0.001264\n",
      "tensor([0.0077], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9002 --- loss: 0.007701\n",
      "tensor([2.5808e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9004 --- loss: 0.000000\n",
      "tensor([0.0846], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9007 --- loss: 0.088379\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9009 --- loss: 0.000000\n",
      "tensor([5.5384e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9012 --- loss: 0.000001\n",
      "tensor([7.7343e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9014 --- loss: 0.000008\n",
      "tensor([6.1976e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9017 --- loss: 0.000006\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9019 --- loss: 0.000603\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9022 --- loss: 0.000545\n",
      "tensor([2.2353e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9024 --- loss: 0.000002\n",
      "tensor([1.1311e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9027 --- loss: 0.000011\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9029 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9032 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9034 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9037 --- loss: 0.000000\n",
      "tensor([2.7454e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9039 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9042 --- loss: 0.000023\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9044 --- loss: 0.000008\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9047 --- loss: 0.000001\n",
      "tensor([7.6502e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9050 --- loss: 0.000000\n",
      "tensor([1.7434e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9052 --- loss: 0.000000\n",
      "tensor([5.4294e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9055 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9057 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9060 --- loss: 0.000008\n",
      "tensor([4.8151e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9062 --- loss: 0.000048\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9065 --- loss: 0.000084\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9067 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9070 --- loss: 0.000002\n",
      "tensor([6.9691e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9072 --- loss: 0.000070\n",
      "tensor([1.4359e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9075 --- loss: 0.000000\n",
      "tensor([2.9846e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9077 --- loss: 0.000000\n",
      "tensor([3.7976e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9080 --- loss: 0.000000\n",
      "tensor([1.2869e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9082 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9085 --- loss: 0.000001\n",
      "tensor([2.0124e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9087 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9090 --- loss: 0.000114\n",
      "tensor([0.0040], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9093 --- loss: 0.003992\n",
      "tensor([1.5674e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9095 --- loss: 0.000016\n",
      "tensor([6.6640e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9098 --- loss: 0.000000\n",
      "tensor([1.4481e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9100 --- loss: 0.000000\n",
      "tensor([1.8656e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9103 --- loss: 0.000019\n",
      "tensor([0.0016], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9105 --- loss: 0.001555\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9108 --- loss: 0.000009\n",
      "tensor([3.6800e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9110 --- loss: 0.000037\n",
      "tensor([3.4774e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9113 --- loss: 0.000003\n",
      "tensor([9.6434e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9115 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9118 --- loss: 0.000023\n",
      "tensor([4.0695e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9120 --- loss: 0.000000\n",
      "tensor([9.8696e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9123 --- loss: 0.000010\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9125 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9128 --- loss: 0.000034\n",
      "tensor([7.2581e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9130 --- loss: 0.000001\n",
      "tensor([5.6495e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9133 --- loss: 0.000056\n",
      "tensor([1.5737e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9135 --- loss: 0.000000\n",
      "tensor([1.8227e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9138 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9141 --- loss: 0.000011\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9143 --- loss: 0.000021\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9146 --- loss: 0.000003\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9148 --- loss: 0.000306\n",
      "tensor([1.6971e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9151 --- loss: 0.000017\n",
      "tensor([9.1611e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9153 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9156 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9158 --- loss: 0.000011\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9161 --- loss: 0.000195\n",
      "tensor([3.8253e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9163 --- loss: 0.000000\n",
      "tensor([4.6771e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9166 --- loss: 0.000005\n",
      "tensor([1.5320e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9168 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9171 --- loss: 0.000068\n",
      "tensor([2.9364e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9173 --- loss: 0.000003\n",
      "tensor([2.8416e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9176 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9178 --- loss: 0.000005\n",
      "tensor([4.4266e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9181 --- loss: 0.000000\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9184 --- loss: 0.000415\n",
      "tensor([1.7422e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9186 --- loss: 0.000017\n",
      "tensor([3.7630e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9189 --- loss: 0.000038\n",
      "tensor([4.1240e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9191 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9194 --- loss: 0.000021\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9196 --- loss: 0.000026\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9199 --- loss: 0.000014\n",
      "tensor([1.9213e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9201 --- loss: 0.000000\n",
      "tensor([1.0298e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9204 --- loss: 0.000000\n",
      "tensor([1.7869e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9206 --- loss: 0.000000\n",
      "tensor([2.6645e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9209 --- loss: 0.000000\n",
      "tensor([1.5057e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9211 --- loss: 0.000015\n",
      "tensor([1.3655e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9214 --- loss: 0.000000\n",
      "tensor([1.2612e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9216 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9219 --- loss: 0.000103\n",
      "tensor([3.3589e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9221 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9224 --- loss: 0.000003\n",
      "tensor([9.9246e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9226 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9229 --- loss: 0.000000\n",
      "tensor([4.8138e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9232 --- loss: 0.000005\n",
      "tensor([3.9377e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9234 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9237 --- loss: 0.000041\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9239 --- loss: 0.000038\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9242 --- loss: 0.000227\n",
      "tensor([1.0974e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9244 --- loss: 0.000000\n",
      "tensor([0.0317], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9247 --- loss: 0.032176\n",
      "tensor([2.4683e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9249 --- loss: 0.000000\n",
      "tensor([4.4719e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9252 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9254 --- loss: 0.000031\n",
      "tensor([4.9794e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9257 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9259 --- loss: 0.000003\n",
      "tensor([7.9658e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9262 --- loss: 0.000001\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9264 --- loss: 0.000326\n",
      "tensor([1.0552e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9267 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9269 --- loss: 0.000010\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9272 --- loss: 0.000005\n",
      "tensor([4.1182e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9275 --- loss: 0.000004\n",
      "tensor([5.2295e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9277 --- loss: 0.000000\n",
      "tensor([2.8759e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9280 --- loss: 0.000000\n",
      "tensor([1.4685e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9282 --- loss: 0.000015\n",
      "tensor([2.1152e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9285 --- loss: 0.000021\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9287 --- loss: 0.000042\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9290 --- loss: 0.000002\n",
      "tensor([4.4005e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9292 --- loss: 0.000000\n",
      "tensor([1.9911e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9295 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9297 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9300 --- loss: 0.000015\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9302 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9305 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9307 --- loss: 0.000003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9310 --- loss: 0.000057\n",
      "tensor([3.6491e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9312 --- loss: 0.000000\n",
      "tensor([7.4219e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9315 --- loss: 0.000000\n",
      "tensor([0.0201], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9317 --- loss: 0.020263\n",
      "tensor([2.7906e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9320 --- loss: 0.000028\n",
      "tensor([3.4313e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9323 --- loss: 0.000000\n",
      "tensor([2.7215e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9325 --- loss: 0.000027\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9328 --- loss: 0.000026\n",
      "tensor([2.7072e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9330 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9333 --- loss: 0.000001\n",
      "tensor([2.7752e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9335 --- loss: 0.000000\n",
      "tensor([1.8830e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9338 --- loss: 0.000000\n",
      "tensor([2.2468e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9340 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9343 --- loss: 0.000000\n",
      "tensor([8.8040e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9345 --- loss: 0.000000\n",
      "tensor([1.3728e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9348 --- loss: 0.000000\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9350 --- loss: 0.000835\n",
      "tensor([3.9442e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9353 --- loss: 0.000000\n",
      "tensor([4.5253e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9355 --- loss: 0.000005\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9358 --- loss: 0.000311\n",
      "tensor([5.8503e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9360 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9363 --- loss: 0.000012\n",
      "tensor([2.2359e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9366 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9368 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9371 --- loss: 0.000017\n",
      "tensor([6.3923e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9373 --- loss: 0.000000\n",
      "tensor([0.2816], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9376 --- loss: 0.330747\n",
      "tensor([7.3581e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9378 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9381 --- loss: 0.000016\n",
      "tensor([5.7481e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9383 --- loss: 0.000006\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9386 --- loss: 0.000115\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9388 --- loss: 0.000015\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9391 --- loss: 0.000098\n",
      "tensor([7.3503e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9393 --- loss: 0.000000\n",
      "tensor([1.8184e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9396 --- loss: 0.000000\n",
      "tensor([1.0565e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9398 --- loss: 0.000011\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9401 --- loss: 0.000031\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9403 --- loss: 0.000083\n",
      "tensor([1.7988e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9406 --- loss: 0.000000\n",
      "tensor([1.3459e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9408 --- loss: 0.000000\n",
      "tensor([1.4376e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9411 --- loss: 0.000014\n",
      "tensor([2.8577e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9414 --- loss: 0.000003\n",
      "tensor([1.3248e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9416 --- loss: 0.000001\n",
      "tensor([2.9420e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9419 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9421 --- loss: 0.000198\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9424 --- loss: 0.000078\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9426 --- loss: 0.000032\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9429 --- loss: 0.000004\n",
      "tensor([2.7712e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9431 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9434 --- loss: 0.000001\n",
      "tensor([5.6524e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9436 --- loss: 0.000000\n",
      "tensor([2.4166e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9439 --- loss: 0.000000\n",
      "tensor([1.4977e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9441 --- loss: 0.000000\n",
      "tensor([1.2293e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9444 --- loss: 0.000012\n",
      "tensor([1.1070e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9446 --- loss: 0.000000\n",
      "tensor([7.3279e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9449 --- loss: 0.000000\n",
      "tensor([8.3764e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9451 --- loss: 0.000000\n",
      "tensor([2.1333e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9454 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9457 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9459 --- loss: 0.000192\n",
      "tensor([4.0466e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9462 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9464 --- loss: 0.000044\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9467 --- loss: 0.000011\n",
      "tensor([3.5923e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9469 --- loss: 0.000000\n",
      "tensor([3.2053e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9472 --- loss: 0.000000\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9474 --- loss: 0.001250\n",
      "tensor([0.9990], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9477 --- loss: 0.000994\n",
      "tensor([7.2546e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9479 --- loss: 0.000000\n",
      "tensor([1.4567e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9482 --- loss: 0.000015\n",
      "tensor([0.9982], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9484 --- loss: 0.001765\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9487 --- loss: 0.000039\n",
      "tensor([3.8591e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9489 --- loss: 0.000000\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9492 --- loss: 0.000935\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9494 --- loss: 0.000408\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9497 --- loss: 0.000984\n",
      "tensor([2.7093e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9499 --- loss: 0.000003\n",
      "tensor([9.2843e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9502 --- loss: 0.000093\n",
      "tensor([2.6110e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9505 --- loss: 0.000000\n",
      "tensor([8.3674e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9507 --- loss: 0.000008\n",
      "tensor([1.5528e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9510 --- loss: 0.000002\n",
      "tensor([7.3536e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9512 --- loss: 0.000001\n",
      "tensor([1.1120e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9515 --- loss: 0.000000\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9517 --- loss: 0.000941\n",
      "tensor([3.3839e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9520 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9522 --- loss: 0.000003\n",
      "tensor([3.3402e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9525 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9527 --- loss: 0.000087\n",
      "tensor([8.8893e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9530 --- loss: 0.000000\n",
      "tensor([2.9978e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9532 --- loss: 0.000000\n",
      "tensor([9.2273e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9535 --- loss: 0.000000\n",
      "tensor([9.1660e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9537 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9540 --- loss: 0.000052\n",
      "tensor([6.6171e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9542 --- loss: 0.000001\n",
      "tensor([1.2083e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9545 --- loss: 0.000000\n",
      "tensor([1.0117e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9548 --- loss: 0.000000\n",
      "tensor([1.4734e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9550 --- loss: 0.000001\n",
      "tensor([4.4272e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9553 --- loss: 0.000004\n",
      "tensor([3.5971e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9555 --- loss: 0.000004\n",
      "tensor([3.3836e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9558 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9560 --- loss: 0.000120\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9563 --- loss: 0.000088\n",
      "tensor([4.8362e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9565 --- loss: 0.000048\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9568 --- loss: 0.000001\n",
      "tensor([2.1078e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9570 --- loss: 0.000002\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9573 --- loss: 0.000121\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9575 --- loss: 0.000006\n",
      "tensor([6.9313e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9578 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9580 --- loss: 0.000009\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9583 --- loss: 0.000245\n",
      "tensor([6.9001e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9585 --- loss: 0.000007\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9588 --- loss: 0.000247\n",
      "tensor([1.5277e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9590 --- loss: 0.000015\n",
      "tensor([1.0329e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9593 --- loss: 0.000000\n",
      "tensor([1.1512e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9596 --- loss: 0.000001\n",
      "tensor([2.4468e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9598 --- loss: 0.000002\n",
      "tensor([1.4269e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9601 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9603 --- loss: 0.000025\n",
      "tensor([3.9979e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9606 --- loss: 0.000000\n",
      "tensor([5.3298e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9608 --- loss: 0.000000\n",
      "tensor([0.0076], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9611 --- loss: 0.007670\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9613 --- loss: 0.000002\n",
      "tensor([1.4959e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9616 --- loss: 0.000000\n",
      "tensor([2.8377e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9618 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9621 --- loss: 0.000056\n",
      "tensor([2.4850e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9623 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9626 --- loss: 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0969e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9628 --- loss: 0.000011\n",
      "tensor([0.9990], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9631 --- loss: 0.001002\n",
      "tensor([3.7960e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9633 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9636 --- loss: 0.000035\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9639 --- loss: 0.000122\n",
      "tensor([2.2041e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9641 --- loss: 0.000000\n",
      "tensor([1.4902e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9644 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9646 --- loss: 0.000025\n",
      "tensor([3.7517e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9649 --- loss: 0.000000\n",
      "tensor([2.4156e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9651 --- loss: 0.000000\n",
      "tensor([2.8032e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9654 --- loss: 0.000000\n",
      "tensor([7.1745e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9656 --- loss: 0.000007\n",
      "tensor([9.4861e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9659 --- loss: 0.000001\n",
      "tensor([8.5278e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9661 --- loss: 0.000000\n",
      "tensor([1.0925e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9664 --- loss: 0.000000\n",
      "tensor([1.5236e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9666 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9669 --- loss: 0.000258\n",
      "tensor([1.1963e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9671 --- loss: 0.000001\n",
      "tensor([1.0993e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9674 --- loss: 0.000011\n",
      "tensor([9.3294e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9676 --- loss: 0.000000\n",
      "tensor([1.0278e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9679 --- loss: 0.000000\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9681 --- loss: 0.000639\n",
      "tensor([2.5212e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9684 --- loss: 0.000000\n",
      "tensor([5.2316e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9687 --- loss: 0.000000\n",
      "tensor([9.2003e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9689 --- loss: 0.000000\n",
      "tensor([4.7978e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9692 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9694 --- loss: 0.000123\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9697 --- loss: 0.000065\n",
      "tensor([5.2177e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9699 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9702 --- loss: 0.000018\n",
      "tensor([6.6967e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9704 --- loss: 0.000007\n",
      "tensor([5.1932e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9707 --- loss: 0.000000\n",
      "tensor([4.2679e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9709 --- loss: 0.000000\n",
      "tensor([0.9943], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9712 --- loss: 0.005720\n",
      "tensor([0.8488], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9714 --- loss: 0.163905\n",
      "tensor([1.3150e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9717 --- loss: 0.000013\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9719 --- loss: 0.000106\n",
      "tensor([2.9786e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9722 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9724 --- loss: 0.000006\n",
      "tensor([3.7565e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9727 --- loss: 0.000000\n",
      "tensor([1.9775e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9730 --- loss: 0.000000\n",
      "tensor([1.7919e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9732 --- loss: 0.000000\n",
      "tensor([2.9202e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9735 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9737 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9740 --- loss: 0.000010\n",
      "tensor([9.6826e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9742 --- loss: 0.000097\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9745 --- loss: 0.000017\n",
      "tensor([5.0395e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9747 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9750 --- loss: 0.000024\n",
      "tensor([9.1085e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9752 --- loss: 0.000000\n",
      "tensor([2.2930e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9755 --- loss: 0.000000\n",
      "tensor([1.0822e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9757 --- loss: 0.000000\n",
      "tensor([2.1166e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9760 --- loss: 0.000000\n",
      "tensor([4.3621e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9762 --- loss: 0.000044\n",
      "tensor([1.4434e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9765 --- loss: 0.000000\n",
      "tensor([0.9990], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9767 --- loss: 0.001001\n",
      "tensor([2.7115e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9770 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9772 --- loss: 0.000037\n",
      "tensor([9.8143e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9775 --- loss: 0.000001\n",
      "tensor([6.5190e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9778 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9780 --- loss: 0.000014\n",
      "tensor([5.0061e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9783 --- loss: 0.000050\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9785 --- loss: 0.000039\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9788 --- loss: 0.000000\n",
      "tensor([2.1104e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9790 --- loss: 0.000002\n",
      "tensor([5.1125e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9793 --- loss: 0.000000\n",
      "tensor([4.7574e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9795 --- loss: 0.000000\n",
      "tensor([3.0370e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9798 --- loss: 0.000000\n",
      "tensor([2.7142e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9800 --- loss: 0.000000\n",
      "tensor([8.5696e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9803 --- loss: 0.000000\n",
      "tensor([4.1590e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9805 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9808 --- loss: 0.000015\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9810 --- loss: 0.000001\n",
      "tensor([5.3321e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9813 --- loss: 0.000053\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9815 --- loss: 0.000431\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9818 --- loss: 0.000045\n",
      "tensor([0.0019], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9821 --- loss: 0.001901\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9823 --- loss: 0.000002\n",
      "tensor([0.0747], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9826 --- loss: 0.077689\n",
      "tensor([1.7928e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9828 --- loss: 0.000018\n",
      "tensor([9.6342e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9831 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9833 --- loss: 0.000049\n",
      "tensor([1.0092e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9836 --- loss: 0.000010\n",
      "tensor([2.6976e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9838 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9841 --- loss: 0.000336\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9843 --- loss: 0.000071\n",
      "tensor([8.9203e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9846 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9848 --- loss: 0.000030\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9851 --- loss: 0.000634\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9853 --- loss: 0.000002\n",
      "tensor([2.9174e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9856 --- loss: 0.000000\n",
      "tensor([1.2997e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9858 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9861 --- loss: 0.000172\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9863 --- loss: 0.000048\n",
      "tensor([1.0121e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9866 --- loss: 0.000001\n",
      "tensor([9.6753e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9869 --- loss: 0.000010\n",
      "tensor([3.7840e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9871 --- loss: 0.000000\n",
      "tensor([2.3855e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9874 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9876 --- loss: 0.000002\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9879 --- loss: 0.000316\n",
      "tensor([2.3201e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9881 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9884 --- loss: 0.000015\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9886 --- loss: 0.000015\n",
      "tensor([1.9074e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9889 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9891 --- loss: 0.000008\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9894 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9896 --- loss: 0.000006\n",
      "tensor([5.3962e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9899 --- loss: 0.000005\n",
      "tensor([0.0060], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9901 --- loss: 0.006034\n",
      "tensor([0.0063], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9904 --- loss: 0.006339\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9906 --- loss: 0.000308\n",
      "tensor([1.8309e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9909 --- loss: 0.000002\n",
      "tensor([1.8578e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9912 --- loss: 0.000000\n",
      "tensor([2.7480e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9914 --- loss: 0.000000\n",
      "tensor([1.4521e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9917 --- loss: 0.000000\n",
      "tensor([2.6035e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9919 --- loss: 0.000003\n",
      "tensor([5.9660e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9922 --- loss: 0.000060\n",
      "tensor([9.1694e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9924 --- loss: 0.000000\n",
      "tensor([0.9886], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9927 --- loss: 0.011416\n",
      "tensor([2.6800e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9929 --- loss: 0.000027\n",
      "tensor([1.8440e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9932 --- loss: 0.000000\n",
      "tensor([8.6876e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9934 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9937 --- loss: 0.000028\n",
      "tensor([0.0035], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9939 --- loss: 0.003545\n",
      "tensor([4.7091e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9942 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9944 --- loss: 0.000131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9947 --- loss: 0.000003\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9949 --- loss: 0.000918\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9952 --- loss: 0.000014\n",
      "tensor([7.7894e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9954 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9957 --- loss: 0.000298\n",
      "tensor([5.2344e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9960 --- loss: 0.000000\n",
      "tensor([5.7669e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9962 --- loss: 0.000000\n",
      "tensor([1.3826e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9965 --- loss: 0.000000\n",
      "tensor([8.5090e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9967 --- loss: 0.000085\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9970 --- loss: 0.000044\n",
      "tensor([4.8863e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9972 --- loss: 0.000000\n",
      "tensor([7.4356e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9975 --- loss: 0.000000\n",
      "tensor([7.7569e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9977 --- loss: 0.000001\n",
      "tensor([1.1534e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9980 --- loss: 0.000000\n",
      "tensor([1.7659e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9982 --- loss: 0.000000\n",
      "tensor([1.9395e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9985 --- loss: 0.000000\n",
      "tensor([2.3622e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9987 --- loss: 0.000000\n",
      "tensor([2.8963e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9990 --- loss: 0.000000\n",
      "tensor([0.9975], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9992 --- loss: 0.002497\n",
      "tensor([2.2244e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9995 --- loss: 0.000000\n",
      "tensor([1.3292e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9997 --- loss: 0.000000\n",
      "Epoch finished ! Loss: 0.025207460581323494\n",
      "Checkpoint 1 saved !\n",
      "Starting epoch 2/2.\n",
      "tensor([1.6475e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0000 --- loss: 0.000000\n",
      "tensor([6.6923e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0003 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0005 --- loss: 0.000243\n",
      "tensor([2.3368e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0008 --- loss: 0.000023\n",
      "tensor([3.8380e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0010 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0013 --- loss: 0.000232\n",
      "tensor([7.7246e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0015 --- loss: 0.000000\n",
      "tensor([1.5087e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0018 --- loss: 0.000002\n",
      "tensor([2.0611e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0020 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0023 --- loss: 0.000018\n",
      "tensor([9.9749e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0025 --- loss: 0.000001\n",
      "tensor([5.7368e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0028 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0030 --- loss: 0.000045\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0033 --- loss: 0.000142\n",
      "tensor([1.4505e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0035 --- loss: 0.000000\n",
      "tensor([7.5999e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0038 --- loss: 0.000008\n",
      "tensor([1.8606e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0040 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0043 --- loss: 0.000147\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0046 --- loss: 0.000056\n",
      "tensor([1.2239e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0048 --- loss: 0.000012\n",
      "tensor([3.4430e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0051 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0053 --- loss: 0.000037\n",
      "tensor([1.9850e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0056 --- loss: 0.000000\n",
      "tensor([1.7900e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0058 --- loss: 0.000002\n",
      "tensor([3.8016e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0061 --- loss: 0.000000\n",
      "tensor([1.6343e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0063 --- loss: 0.000002\n",
      "tensor([7.4458e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0066 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0068 --- loss: 0.000272\n",
      "tensor([1.3402e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0071 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0073 --- loss: 0.000055\n",
      "tensor([3.1285e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0076 --- loss: 0.000000\n",
      "tensor([0.9741], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0078 --- loss: 0.026230\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0081 --- loss: 0.000192\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0083 --- loss: 0.000004\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0086 --- loss: 0.000060\n",
      "tensor([5.4638e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0088 --- loss: 0.000000\n",
      "tensor([2.0608e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0091 --- loss: 0.000002\n",
      "tensor([1.5236e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0094 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0096 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0099 --- loss: 0.000007\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0101 --- loss: 0.000010\n",
      "tensor([3.0689e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0104 --- loss: 0.000000\n",
      "tensor([1.8699e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0106 --- loss: 0.000019\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0109 --- loss: 0.000237\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0111 --- loss: 0.000001\n",
      "tensor([5.1970e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0114 --- loss: 0.000000\n",
      "tensor([4.1398e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0116 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0119 --- loss: 0.000001\n",
      "tensor([1.3923e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0121 --- loss: 0.000000\n",
      "tensor([1.3144e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0124 --- loss: 0.000000\n",
      "tensor([4.2742e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0126 --- loss: 0.000000\n",
      "tensor([3.0891e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0129 --- loss: 0.000000\n",
      "tensor([6.3313e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0131 --- loss: 0.000000\n",
      "tensor([1.5049e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0134 --- loss: 0.000000\n",
      "tensor([1.1899e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0137 --- loss: 0.000012\n",
      "tensor([4.1468e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0139 --- loss: 0.000004\n",
      "tensor([7.3557e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0142 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0144 --- loss: 0.000121\n",
      "tensor([0.9985], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0147 --- loss: 0.001485\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0149 --- loss: 0.000103\n",
      "tensor([7.3286e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0152 --- loss: 0.000001\n",
      "tensor([1.0895e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0154 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0157 --- loss: 0.000014\n",
      "tensor([4.6985e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0159 --- loss: 0.000047\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0162 --- loss: 0.000679\n",
      "tensor([9.7041e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0164 --- loss: 0.000010\n",
      "tensor([1.5383e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0167 --- loss: 0.000015\n",
      "tensor([1.6221e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0169 --- loss: 0.000000\n",
      "tensor([0.9168], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0172 --- loss: 0.086837\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0174 --- loss: 0.000823\n",
      "tensor([3.2840e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0177 --- loss: 0.000000\n",
      "tensor([7.2364e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0179 --- loss: 0.000000\n",
      "tensor([1.5318e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0182 --- loss: 0.000002\n",
      "tensor([4.5295e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0185 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0187 --- loss: 0.000013\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0190 --- loss: 0.000076\n",
      "tensor([6.9849e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0192 --- loss: 0.000000\n",
      "tensor([5.5018e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0195 --- loss: 0.000055\n",
      "tensor([2.1297e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0197 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0200 --- loss: 0.000036\n",
      "tensor([8.8196e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0202 --- loss: 0.000001\n",
      "tensor([4.0852e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0205 --- loss: 0.000000\n",
      "tensor([2.7974e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0207 --- loss: 0.000000\n",
      "tensor([2.3915e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0210 --- loss: 0.000002\n",
      "tensor([1.8405e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0212 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0215 --- loss: 0.000009\n",
      "tensor([2.5973e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0217 --- loss: 0.000000\n",
      "tensor([2.2749e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0220 --- loss: 0.000023\n",
      "tensor([2.4576e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0222 --- loss: 0.000025\n",
      "tensor([7.7065e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0225 --- loss: 0.000008\n",
      "tensor([5.1127e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0228 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0230 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0233 --- loss: 0.000014\n",
      "tensor([2.0215e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0235 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0238 --- loss: 0.000015\n",
      "tensor([7.1774e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0240 --- loss: 0.000000\n",
      "tensor([3.3225e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0243 --- loss: 0.000000\n",
      "tensor([9.3695e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0245 --- loss: 0.000000\n",
      "tensor([4.0326e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0248 --- loss: 0.000040\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0250 --- loss: 0.000068\n",
      "tensor([4.4912e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0253 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0255 --- loss: 0.000192\n",
      "tensor([1.0691e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0258 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0260 --- loss: 0.000038\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0263 --- loss: 0.000313\n",
      "tensor([2.0384e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0265 --- loss: 0.000020\n",
      "tensor([2.1641e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0268 --- loss: 0.000022\n",
      "tensor([6.0902e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0270 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0273 --- loss: 0.000130\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0276 --- loss: 0.000057\n",
      "tensor([4.0707e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0278 --- loss: 0.000000\n",
      "tensor([5.4575e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0281 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0283 --- loss: 0.000171\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0286 --- loss: 0.000289\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0288 --- loss: 0.000012\n",
      "tensor([1.2997e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0291 --- loss: 0.000000\n",
      "tensor([4.0136e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0293 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0296 --- loss: 0.000000\n",
      "tensor([3.9554e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0298 --- loss: 0.000000\n",
      "tensor([2.8932e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0301 --- loss: 0.000003\n",
      "tensor([9.9448e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0303 --- loss: 0.000099\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0306 --- loss: 0.000040\n",
      "tensor([1.9551e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0308 --- loss: 0.000020\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0311 --- loss: 0.000430\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0313 --- loss: 0.000003\n",
      "tensor([5.2492e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0316 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0319 --- loss: 0.000196\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0321 --- loss: 0.000016\n",
      "tensor([1.3610e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0324 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0326 --- loss: 0.000010\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0329 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0331 --- loss: 0.000004\n",
      "tensor([5.2172e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0334 --- loss: 0.000000\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0336 --- loss: 0.000641\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0339 --- loss: 0.000004\n",
      "tensor([2.8575e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0341 --- loss: 0.000003\n",
      "tensor([4.6032e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0344 --- loss: 0.000000\n",
      "tensor([2.2840e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0346 --- loss: 0.000023\n",
      "tensor([6.7440e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0349 --- loss: 0.000001\n",
      "tensor([1.3524e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0351 --- loss: 0.000000\n",
      "tensor([2.3208e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0354 --- loss: 0.000023\n",
      "tensor([1.7174e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0356 --- loss: 0.000000\n",
      "tensor([9.1894e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0359 --- loss: 0.000009\n",
      "tensor([8.3168e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0361 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0364 --- loss: 0.000012\n",
      "tensor([4.1104e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0367 --- loss: 0.000000\n",
      "tensor([5.3296e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0369 --- loss: 0.000000\n",
      "tensor([8.8046e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0372 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0374 --- loss: 0.000006\n",
      "tensor([1.4284e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0377 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0379 --- loss: 0.000009\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0382 --- loss: 0.000022\n",
      "tensor([6.3999e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0384 --- loss: 0.000000\n",
      "tensor([4.0331e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0387 --- loss: 0.000000\n",
      "tensor([8.9515e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0389 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0392 --- loss: 0.000047\n",
      "tensor([8.9202e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0394 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0397 --- loss: 0.000007\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0399 --- loss: 0.000282\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0402 --- loss: 0.000042\n",
      "tensor([5.8651e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0404 --- loss: 0.000000\n",
      "tensor([1.2458e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0407 --- loss: 0.000001\n",
      "tensor([9.3058e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0410 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0412 --- loss: 0.000167\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0415 --- loss: 0.000001\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0417 --- loss: 0.000431\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0420 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0422 --- loss: 0.000015\n",
      "tensor([1.9333e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0425 --- loss: 0.000000\n",
      "tensor([4.4303e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0427 --- loss: 0.000000\n",
      "tensor([4.6597e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0430 --- loss: 0.000000\n",
      "tensor([8.6943e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0432 --- loss: 0.000000\n",
      "tensor([2.8469e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0435 --- loss: 0.000028\n",
      "tensor([1.3626e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0437 --- loss: 0.000000\n",
      "tensor([1.9878e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0440 --- loss: 0.000000\n",
      "tensor([1.3782e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0442 --- loss: 0.000001\n",
      "tensor([6.4010e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0445 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0447 --- loss: 0.000007\n",
      "tensor([1.7312e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0450 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0452 --- loss: 0.000002\n",
      "tensor([2.9167e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0455 --- loss: 0.000000\n",
      "tensor([3.4825e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0458 --- loss: 0.000000\n",
      "tensor([3.0441e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0460 --- loss: 0.000000\n",
      "tensor([1.0656e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0463 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0465 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0468 --- loss: 0.000001\n",
      "tensor([9.0450e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0470 --- loss: 0.000000\n",
      "tensor([0.0009], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0473 --- loss: 0.000905\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0475 --- loss: 0.000008\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0478 --- loss: 0.000026\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0480 --- loss: 0.000029\n",
      "tensor([0.2085], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0483 --- loss: 0.233769\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0485 --- loss: 0.000099\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0488 --- loss: 0.000001\n",
      "tensor([2.4355e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0490 --- loss: 0.000000\n",
      "tensor([2.0169e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0493 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0495 --- loss: 0.000026\n",
      "tensor([3.3216e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0498 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0501 --- loss: 0.000003\n",
      "tensor([9.0750e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0503 --- loss: 0.000001\n",
      "tensor([1.0442e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0506 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0508 --- loss: 0.000257\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0511 --- loss: 0.000211\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0513 --- loss: 0.000012\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0516 --- loss: 0.000300\n",
      "tensor([4.9707e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0518 --- loss: 0.000005\n",
      "tensor([0.9536], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0521 --- loss: 0.047480\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0523 --- loss: 0.000002\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0526 --- loss: 0.000112\n",
      "tensor([1.4808e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0528 --- loss: 0.000000\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0531 --- loss: 0.000559\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0533 --- loss: 0.000020\n",
      "tensor([1.7939e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0536 --- loss: 0.000000\n",
      "tensor([6.1241e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0538 --- loss: 0.000000\n",
      "tensor([1.8591e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0541 --- loss: 0.000000\n",
      "tensor([3.8925e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0543 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0546 --- loss: 0.000211\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0549 --- loss: 0.000008\n",
      "tensor([6.7235e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0551 --- loss: 0.000000\n",
      "tensor([3.0369e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0554 --- loss: 0.000000\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0556 --- loss: 0.000284\n",
      "tensor([2.2207e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0559 --- loss: 0.000000\n",
      "tensor([2.7588e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0561 --- loss: 0.000000\n",
      "tensor([9.7344e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0564 --- loss: 0.000001\n",
      "tensor([0.9980], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0566 --- loss: 0.001985\n",
      "tensor([2.4810e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0569 --- loss: 0.000000\n",
      "tensor([7.8660e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0571 --- loss: 0.000000\n",
      "tensor([4.5456e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0574 --- loss: 0.000045\n",
      "tensor([4.1107e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0576 --- loss: 0.000004\n",
      "tensor([5.3405e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0579 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0581 --- loss: 0.000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.6723e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0584 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0586 --- loss: 0.000001\n",
      "tensor([2.4479e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0589 --- loss: 0.000000\n",
      "tensor([9.7435e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0592 --- loss: 0.000000\n",
      "tensor([2.9759e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0594 --- loss: 0.000030\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0597 --- loss: 0.000004\n",
      "tensor([8.7598e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0599 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0602 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0604 --- loss: 0.000008\n",
      "tensor([0.9911], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0607 --- loss: 0.008956\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0609 --- loss: 0.000111\n",
      "tensor([1.0465e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0612 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0614 --- loss: 0.000009\n",
      "tensor([3.1423e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0617 --- loss: 0.000000\n",
      "tensor([5.0047e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0619 --- loss: 0.000050\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0622 --- loss: 0.000168\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0624 --- loss: 0.000002\n",
      "tensor([7.9473e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0627 --- loss: 0.000008\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0629 --- loss: 0.000591\n",
      "tensor([5.1827e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0632 --- loss: 0.000000\n",
      "tensor([4.8523e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0634 --- loss: 0.000049\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0637 --- loss: 0.000026\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0640 --- loss: 0.000176\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0642 --- loss: 0.000082\n",
      "tensor([5.7143e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0645 --- loss: 0.000000\n",
      "tensor([1.4707e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0647 --- loss: 0.000000\n",
      "tensor([2.1125e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0650 --- loss: 0.000000\n",
      "tensor([5.7784e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0652 --- loss: 0.000006\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0655 --- loss: 0.001553\n",
      "tensor([5.4831e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0657 --- loss: 0.000000\n",
      "tensor([2.2858e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0660 --- loss: 0.000000\n",
      "tensor([4.8103e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0662 --- loss: 0.000005\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0665 --- loss: 0.000315\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0667 --- loss: 0.000046\n",
      "tensor([0.0267], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0670 --- loss: 0.027047\n",
      "tensor([1.5478e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0672 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0675 --- loss: 0.000003\n",
      "tensor([1.1274e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0677 --- loss: 0.000000\n",
      "tensor([3.3756e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0680 --- loss: 0.000003\n",
      "tensor([1.3503e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0683 --- loss: 0.000000\n",
      "tensor([2.6920e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0685 --- loss: 0.000000\n",
      "tensor([5.0006e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0688 --- loss: 0.000050\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0690 --- loss: 0.000134\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0693 --- loss: 0.000022\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0695 --- loss: 0.000203\n",
      "tensor([6.7019e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0698 --- loss: 0.000067\n",
      "tensor([7.4260e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0700 --- loss: 0.000001\n",
      "tensor([4.9125e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0703 --- loss: 0.000000\n",
      "tensor([4.9177e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0705 --- loss: 0.000005\n",
      "tensor([2.9529e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0708 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0710 --- loss: 0.000001\n",
      "tensor([3.5797e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0713 --- loss: 0.000004\n",
      "tensor([2.1719e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0715 --- loss: 0.000002\n",
      "tensor([0.9981], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0718 --- loss: 0.001859\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0720 --- loss: 0.000036\n",
      "tensor([0.0012], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0723 --- loss: 0.001178\n",
      "tensor([0.9964], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0725 --- loss: 0.003596\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0728 --- loss: 0.000376\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0731 --- loss: 0.000481\n",
      "tensor([1.7969e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0733 --- loss: 0.000000\n",
      "tensor([2.1866e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0736 --- loss: 0.000000\n",
      "tensor([1.9655e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0738 --- loss: 0.000020\n",
      "tensor([7.2214e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0741 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0743 --- loss: 0.000068\n",
      "tensor([3.7134e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0746 --- loss: 0.000000\n",
      "tensor([2.2239e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0748 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0751 --- loss: 0.000007\n",
      "tensor([1.9607e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0753 --- loss: 0.000000\n",
      "tensor([6.5631e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0756 --- loss: 0.000000\n",
      "tensor([1.9736e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0758 --- loss: 0.000000\n",
      "tensor([4.0921e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0761 --- loss: 0.000000\n",
      "tensor([4.2560e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0763 --- loss: 0.000000\n",
      "tensor([4.4991e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0766 --- loss: 0.000004\n",
      "tensor([5.3920e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0768 --- loss: 0.000000\n",
      "tensor([1.3110e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0771 --- loss: 0.000000\n",
      "tensor([3.7728e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0774 --- loss: 0.000000\n",
      "tensor([1.0659e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0776 --- loss: 0.000000\n",
      "tensor([1.2838e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0779 --- loss: 0.000000\n",
      "tensor([4.1519e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0781 --- loss: 0.000042\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0784 --- loss: 0.000085\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0786 --- loss: 0.000021\n",
      "tensor([4.9888e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0789 --- loss: 0.000000\n",
      "tensor([2.7510e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0791 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0794 --- loss: 0.000228\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0796 --- loss: 0.000087\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0799 --- loss: 0.000595\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0801 --- loss: 0.000473\n",
      "tensor([1.0129e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0804 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0806 --- loss: 0.000006\n",
      "tensor([7.1745e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0809 --- loss: 0.000000\n",
      "tensor([7.2407e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0811 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0814 --- loss: 0.000009\n",
      "tensor([3.8987e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0816 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0819 --- loss: 0.000083\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0822 --- loss: 0.001072\n",
      "tensor([7.0323e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0824 --- loss: 0.000000\n",
      "tensor([8.8894e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0827 --- loss: 0.000000\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0829 --- loss: 0.000531\n",
      "tensor([9.7137e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0832 --- loss: 0.000010\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0834 --- loss: 0.000178\n",
      "tensor([0.0045], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0837 --- loss: 0.004464\n",
      "tensor([8.9250e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0839 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0842 --- loss: 0.000056\n",
      "tensor([1.7228e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0844 --- loss: 0.000000\n",
      "tensor([1.0061e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0847 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0849 --- loss: 0.000027\n",
      "tensor([3.0741e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0852 --- loss: 0.000031\n",
      "tensor([5.0820e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0854 --- loss: 0.000000\n",
      "tensor([1.1456e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0857 --- loss: 0.000011\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0859 --- loss: 0.000037\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0862 --- loss: 0.000039\n",
      "tensor([6.0876e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0865 --- loss: 0.000001\n",
      "tensor([3.1067e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0867 --- loss: 0.000003\n",
      "tensor([3.3939e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0870 --- loss: 0.000000\n",
      "tensor([0.9968], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0872 --- loss: 0.003199\n",
      "tensor([7.9234e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0875 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0877 --- loss: 0.000116\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0880 --- loss: 0.000514\n",
      "tensor([1.4132e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0882 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0885 --- loss: 0.000007\n",
      "tensor([0.0021], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0887 --- loss: 0.002078\n",
      "tensor([3.1254e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0890 --- loss: 0.000000\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0892 --- loss: 0.001123\n",
      "tensor([6.3942e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0895 --- loss: 0.000000\n",
      "tensor([7.2579e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0897 --- loss: 0.000000\n",
      "tensor([4.3067e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0900 --- loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.6963e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0902 --- loss: 0.000001\n",
      "tensor([5.8240e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0905 --- loss: 0.000000\n",
      "tensor([9.6309e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0907 --- loss: 0.000000\n",
      "tensor([1.0669e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0910 --- loss: 0.000000\n",
      "tensor([0.9982], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0913 --- loss: 0.001771\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0915 --- loss: 0.000004\n",
      "tensor([4.7678e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0918 --- loss: 0.000000\n",
      "tensor([4.6224e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0920 --- loss: 0.000000\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0923 --- loss: 0.000512\n",
      "tensor([8.9771e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0925 --- loss: 0.000090\n",
      "tensor([1.4397e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0928 --- loss: 0.000014\n",
      "tensor([7.9500e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0930 --- loss: 0.000080\n",
      "tensor([4.2677e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0933 --- loss: 0.000043\n",
      "tensor([6.5996e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0935 --- loss: 0.000001\n",
      "tensor([8.2229e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0938 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0940 --- loss: 0.000004\n",
      "tensor([1.2363e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0943 --- loss: 0.000001\n",
      "tensor([9.9969e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0945 --- loss: 0.000000\n",
      "tensor([2.8839e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0948 --- loss: 0.000003\n",
      "tensor([2.5100e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0950 --- loss: 0.000000\n",
      "tensor([6.7444e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0953 --- loss: 0.000000\n",
      "tensor([3.4229e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0956 --- loss: 0.000000\n",
      "tensor([7.0126e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0958 --- loss: 0.000000\n",
      "tensor([7.1873e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0961 --- loss: 0.000000\n",
      "tensor([1.0133e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0963 --- loss: 0.000000\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0966 --- loss: 0.000474\n",
      "tensor([3.6457e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0968 --- loss: 0.000000\n",
      "tensor([2.3022e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0971 --- loss: 0.000000\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0973 --- loss: 0.000393\n",
      "tensor([7.9967e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0976 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0978 --- loss: 0.000003\n",
      "tensor([1.1451e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0981 --- loss: 0.000011\n",
      "tensor([1.2457e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0983 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0986 --- loss: 0.000110\n",
      "tensor([9.9645e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0988 --- loss: 0.000100\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0991 --- loss: 0.000145\n",
      "tensor([5.0796e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0993 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.0996 --- loss: 0.000027\n",
      "tensor([1.1392e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.0998 --- loss: 0.000000\n",
      "tensor([8.9144e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1001 --- loss: 0.000000\n",
      "tensor([3.2443e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1004 --- loss: 0.000000\n",
      "tensor([2.2761e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1006 --- loss: 0.000000\n",
      "tensor([4.6403e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1009 --- loss: 0.000000\n",
      "tensor([0.9966], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1011 --- loss: 0.003396\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1014 --- loss: 0.000001\n",
      "tensor([2.2682e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1016 --- loss: 0.000000\n",
      "tensor([9.8907e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1019 --- loss: 0.000001\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1021 --- loss: 0.000291\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1024 --- loss: 0.000025\n",
      "tensor([1.7297e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1026 --- loss: 0.000000\n",
      "tensor([5.6048e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1029 --- loss: 0.000000\n",
      "tensor([2.0736e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1031 --- loss: 0.000000\n",
      "tensor([5.9062e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1034 --- loss: 0.000000\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1036 --- loss: 0.000279\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1039 --- loss: 0.000871\n",
      "tensor([2.4178e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1041 --- loss: 0.000002\n",
      "tensor([4.4707e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1044 --- loss: 0.000000\n",
      "tensor([5.1379e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1047 --- loss: 0.000000\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1049 --- loss: 0.000748\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1052 --- loss: 0.000007\n",
      "tensor([1.0455e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1054 --- loss: 0.000000\n",
      "tensor([4.9569e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1057 --- loss: 0.000000\n",
      "tensor([8.8229e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1059 --- loss: 0.000009\n",
      "tensor([3.1469e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1062 --- loss: 0.000000\n",
      "tensor([1.2676e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1064 --- loss: 0.000000\n",
      "tensor([8.7893e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1067 --- loss: 0.000000\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1069 --- loss: 0.000372\n",
      "tensor([1.0500e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1072 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1074 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1077 --- loss: 0.000049\n",
      "tensor([4.9540e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1079 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1082 --- loss: 0.000020\n",
      "tensor([4.7983e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1084 --- loss: 0.000000\n",
      "tensor([1.9822e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1087 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1089 --- loss: 0.000024\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1092 --- loss: 0.000007\n",
      "tensor([1.8072e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1095 --- loss: 0.000000\n",
      "tensor([2.5537e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1097 --- loss: 0.000000\n",
      "tensor([3.2646e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1100 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1102 --- loss: 0.000106\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1105 --- loss: 0.000036\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1107 --- loss: 0.000001\n",
      "tensor([1.3387e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1110 --- loss: 0.000000\n",
      "tensor([2.7848e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1112 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1115 --- loss: 0.000247\n",
      "tensor([2.4328e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1117 --- loss: 0.000000\n",
      "tensor([3.5413e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1120 --- loss: 0.000004\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1122 --- loss: 0.000229\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1125 --- loss: 0.000788\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1127 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1130 --- loss: 0.000027\n",
      "tensor([3.8868e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1132 --- loss: 0.000000\n",
      "tensor([2.9323e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1135 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1138 --- loss: 0.000018\n",
      "tensor([0.0009], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1140 --- loss: 0.000851\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1143 --- loss: 0.000104\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1145 --- loss: 0.000077\n",
      "tensor([7.8399e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1148 --- loss: 0.000078\n",
      "tensor([1.3034e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1150 --- loss: 0.000000\n",
      "tensor([6.0815e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1153 --- loss: 0.000001\n",
      "tensor([1.3263e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1155 --- loss: 0.000000\n",
      "tensor([1.5188e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1158 --- loss: 0.000000\n",
      "tensor([1.6844e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1160 --- loss: 0.000000\n",
      "tensor([2.5072e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1163 --- loss: 0.000003\n",
      "tensor([2.3847e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1165 --- loss: 0.000000\n",
      "tensor([9.9026e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1168 --- loss: 0.000010\n",
      "tensor([9.1041e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1170 --- loss: 0.000000\n",
      "tensor([2.7169e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1173 --- loss: 0.000000\n",
      "tensor([1.3413e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1175 --- loss: 0.000000\n",
      "tensor([1.4486e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1178 --- loss: 0.000000\n",
      "tensor([8.3703e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1180 --- loss: 0.000001\n",
      "tensor([0.0090], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1183 --- loss: 0.009047\n",
      "tensor([2.1875e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1186 --- loss: 0.000000\n",
      "tensor([2.1412e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1188 --- loss: 0.000000\n",
      "tensor([0.9963], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1191 --- loss: 0.003716\n",
      "tensor([1.7553e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1193 --- loss: 0.000000\n",
      "tensor([3.8735e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1196 --- loss: 0.000000\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1198 --- loss: 0.000810\n",
      "tensor([6.1937e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1201 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1203 --- loss: 0.000002\n",
      "tensor([2.1697e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1206 --- loss: 0.000000\n",
      "tensor([3.2778e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1208 --- loss: 0.000000\n",
      "tensor([9.8815e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1211 --- loss: 0.000000\n",
      "tensor([1.5051e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1213 --- loss: 0.000000\n",
      "tensor([1.1686e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1216 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1218 --- loss: 0.000163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1221 --- loss: 0.000146\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1223 --- loss: 0.000004\n",
      "tensor([4.3949e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1226 --- loss: 0.000000\n",
      "tensor([7.8077e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1229 --- loss: 0.000000\n",
      "tensor([6.0438e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1231 --- loss: 0.000000\n",
      "tensor([3.7207e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1234 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1236 --- loss: 0.000002\n",
      "tensor([5.1266e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1239 --- loss: 0.000001\n",
      "tensor([2.4074e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1241 --- loss: 0.000002\n",
      "tensor([0.9990], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1244 --- loss: 0.001011\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1246 --- loss: 0.000001\n",
      "tensor([2.3965e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1249 --- loss: 0.000000\n",
      "tensor([1.1429e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1251 --- loss: 0.000000\n",
      "tensor([3.8436e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1254 --- loss: 0.000000\n",
      "tensor([1.8886e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1256 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1259 --- loss: 0.000036\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1261 --- loss: 0.000009\n",
      "tensor([2.1988e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1264 --- loss: 0.000000\n",
      "tensor([9.2956e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1266 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1269 --- loss: 0.000004\n",
      "tensor([2.8842e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1271 --- loss: 0.000000\n",
      "tensor([2.1326e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1274 --- loss: 0.000000\n",
      "tensor([0.9955], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1277 --- loss: 0.004499\n",
      "tensor([4.2984e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1279 --- loss: 0.000000\n",
      "tensor([2.8883e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1282 --- loss: 0.000003\n",
      "tensor([7.3019e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1284 --- loss: 0.000000\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1287 --- loss: 0.000301\n",
      "tensor([5.8410e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1289 --- loss: 0.000000\n",
      "tensor([6.0767e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1292 --- loss: 0.000006\n",
      "tensor([7.1347e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1294 --- loss: 0.000000\n",
      "tensor([1.5398e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1297 --- loss: 0.000000\n",
      "tensor([6.0693e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1299 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1302 --- loss: 0.000025\n",
      "tensor([5.4509e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1304 --- loss: 0.000000\n",
      "tensor([1.9676e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1307 --- loss: 0.000020\n",
      "tensor([3.4117e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1309 --- loss: 0.000000\n",
      "tensor([7.9600e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1312 --- loss: 0.000000\n",
      "tensor([3.1343e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1314 --- loss: 0.000000\n",
      "tensor([8.3899e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1317 --- loss: 0.000008\n",
      "tensor([4.7219e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1320 --- loss: 0.000005\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1322 --- loss: 0.000605\n",
      "tensor([1.4803e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1325 --- loss: 0.000000\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1327 --- loss: 0.000775\n",
      "tensor([2.9277e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1330 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1332 --- loss: 0.000027\n",
      "tensor([1.8580e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1335 --- loss: 0.000000\n",
      "tensor([4.5585e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1337 --- loss: 0.000000\n",
      "tensor([1.6391e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1340 --- loss: 0.000000\n",
      "tensor([1.9948e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1342 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1345 --- loss: 0.000006\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1347 --- loss: 0.000090\n",
      "tensor([1.5314e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1350 --- loss: 0.000002\n",
      "tensor([4.9713e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1352 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1355 --- loss: 0.000229\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1357 --- loss: 0.000062\n",
      "tensor([6.3819e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1360 --- loss: 0.000064\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1362 --- loss: 0.001201\n",
      "tensor([5.4101e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1365 --- loss: 0.000000\n",
      "tensor([3.5610e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1368 --- loss: 0.000000\n",
      "tensor([6.3955e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1370 --- loss: 0.000000\n",
      "tensor([3.8202e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1373 --- loss: 0.000000\n",
      "tensor([2.3425e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1375 --- loss: 0.000000\n",
      "tensor([2.2245e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1378 --- loss: 0.000002\n",
      "tensor([5.6272e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1380 --- loss: 0.000000\n",
      "tensor([2.2303e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1383 --- loss: 0.000000\n",
      "tensor([1.5337e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1385 --- loss: 0.000015\n",
      "tensor([8.0538e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1388 --- loss: 0.000000\n",
      "tensor([4.7645e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1390 --- loss: 0.000000\n",
      "tensor([4.1733e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1393 --- loss: 0.000000\n",
      "tensor([6.1600e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1395 --- loss: 0.000001\n",
      "tensor([4.0466e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1398 --- loss: 0.000040\n",
      "tensor([0.0014], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1400 --- loss: 0.001404\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1403 --- loss: 0.000677\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1405 --- loss: 0.000004\n",
      "tensor([3.2288e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1408 --- loss: 0.000000\n",
      "tensor([1.7393e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1411 --- loss: 0.000000\n",
      "tensor([7.8242e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1413 --- loss: 0.000000\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1416 --- loss: 0.000387\n",
      "tensor([5.4614e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1418 --- loss: 0.000000\n",
      "tensor([8.3941e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1421 --- loss: 0.000008\n",
      "tensor([2.4324e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1423 --- loss: 0.000000\n",
      "tensor([5.8649e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1426 --- loss: 0.000059\n",
      "tensor([3.2625e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1428 --- loss: 0.000000\n",
      "tensor([2.7038e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1431 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1433 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1436 --- loss: 0.000109\n",
      "tensor([2.8774e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1438 --- loss: 0.000029\n",
      "tensor([2.6334e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1441 --- loss: 0.000000\n",
      "tensor([3.3514e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1443 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1446 --- loss: 0.000069\n",
      "tensor([7.2190e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1448 --- loss: 0.000000\n",
      "tensor([1.2314e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1451 --- loss: 0.000012\n",
      "tensor([1.7314e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1453 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1456 --- loss: 0.000138\n",
      "tensor([6.7691e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1459 --- loss: 0.000000\n",
      "tensor([3.2426e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1461 --- loss: 0.000000\n",
      "tensor([2.6784e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1464 --- loss: 0.000000\n",
      "tensor([1.8323e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1466 --- loss: 0.000000\n",
      "tensor([1.8127e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1469 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1471 --- loss: 0.000054\n",
      "tensor([3.5406e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1474 --- loss: 0.000000\n",
      "tensor([1.8319e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1476 --- loss: 0.000000\n",
      "tensor([0.9864], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1479 --- loss: 0.013705\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1481 --- loss: 0.000084\n",
      "tensor([1.4798e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1484 --- loss: 0.000001\n",
      "tensor([1.6556e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1486 --- loss: 0.000000\n",
      "tensor([5.3561e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1489 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1491 --- loss: 0.000260\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1494 --- loss: 0.000104\n",
      "tensor([0.9982], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1496 --- loss: 0.001771\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1499 --- loss: 0.000002\n",
      "tensor([3.3328e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1502 --- loss: 0.000000\n",
      "tensor([2.3203e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1504 --- loss: 0.000023\n",
      "tensor([9.6432e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1507 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1509 --- loss: 0.000251\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1512 --- loss: 0.000073\n",
      "tensor([0.9975], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1514 --- loss: 0.002488\n",
      "tensor([4.9237e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1517 --- loss: 0.000000\n",
      "tensor([7.9727e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1519 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1522 --- loss: 0.000013\n",
      "tensor([3.4329e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1524 --- loss: 0.000000\n",
      "tensor([1.8122e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1527 --- loss: 0.000018\n",
      "tensor([3.3997e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1529 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1532 --- loss: 0.000042\n",
      "tensor([2.7881e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1534 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1537 --- loss: 0.000308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.7014e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1539 --- loss: 0.000001\n",
      "tensor([4.0727e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1542 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1544 --- loss: 0.000001\n",
      "tensor([2.7102e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1547 --- loss: 0.000000\n",
      "tensor([6.9346e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1550 --- loss: 0.000000\n",
      "tensor([1.4872e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1552 --- loss: 0.000000\n",
      "tensor([2.5378e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1555 --- loss: 0.000000\n",
      "tensor([9.4484e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1557 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1560 --- loss: 0.000034\n",
      "tensor([2.4853e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1562 --- loss: 0.000000\n",
      "tensor([1.5357e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1565 --- loss: 0.000015\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1567 --- loss: 0.000013\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1570 --- loss: 0.000003\n",
      "tensor([0.9948], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1572 --- loss: 0.005240\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1575 --- loss: 0.000080\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1577 --- loss: 0.000005\n",
      "tensor([1.0583e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1580 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1582 --- loss: 0.000012\n",
      "tensor([7.5637e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1585 --- loss: 0.000008\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1587 --- loss: 0.000012\n",
      "tensor([0.7543], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1590 --- loss: 0.282020\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1593 --- loss: 0.000322\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1595 --- loss: 0.000425\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1598 --- loss: 0.000001\n",
      "tensor([1.5848e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1600 --- loss: 0.000016\n",
      "tensor([2.3772e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1603 --- loss: 0.000000\n",
      "tensor([1.3562e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1605 --- loss: 0.000001\n",
      "tensor([3.4279e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1608 --- loss: 0.000000\n",
      "tensor([4.5916e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1610 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1613 --- loss: 0.000005\n",
      "tensor([4.1849e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1615 --- loss: 0.000004\n",
      "tensor([1.6217e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1618 --- loss: 0.000016\n",
      "tensor([9.1360e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1620 --- loss: 0.000000\n",
      "tensor([3.2828e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1623 --- loss: 0.000000\n",
      "tensor([7.6832e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1625 --- loss: 0.000001\n",
      "tensor([2.8396e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1628 --- loss: 0.000028\n",
      "tensor([2.1046e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1630 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1633 --- loss: 0.000043\n",
      "tensor([0.9939], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1635 --- loss: 0.006133\n",
      "tensor([0.0130], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1638 --- loss: 0.013119\n",
      "tensor([3.0558e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1641 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1643 --- loss: 0.000008\n",
      "tensor([1.0289e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1646 --- loss: 0.000000\n",
      "tensor([8.5580e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1648 --- loss: 0.000086\n",
      "tensor([2.5200e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1651 --- loss: 0.000025\n",
      "tensor([3.0581e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1653 --- loss: 0.000000\n",
      "tensor([8.9841e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1656 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1658 --- loss: 0.000101\n",
      "tensor([1.6666e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1661 --- loss: 0.000000\n",
      "tensor([4.5283e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1663 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1666 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1668 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1671 --- loss: 0.000003\n",
      "tensor([0.0160], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1673 --- loss: 0.016105\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1676 --- loss: 0.000823\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1678 --- loss: 0.000002\n",
      "tensor([4.9736e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1681 --- loss: 0.000050\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1684 --- loss: 0.000000\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1686 --- loss: 0.000272\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1689 --- loss: 0.000003\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1691 --- loss: 0.000177\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1694 --- loss: 0.000111\n",
      "tensor([3.9608e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1696 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1699 --- loss: 0.000000\n",
      "tensor([2.1928e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1701 --- loss: 0.000000\n",
      "tensor([3.3189e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1704 --- loss: 0.000033\n",
      "tensor([3.5566e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1706 --- loss: 0.000000\n",
      "tensor([6.0175e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1709 --- loss: 0.000060\n",
      "tensor([2.4287e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1711 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1714 --- loss: 0.000227\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1716 --- loss: 0.000105\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1719 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1721 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1724 --- loss: 0.000000\n",
      "tensor([6.9614e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1726 --- loss: 0.000070\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1729 --- loss: 0.000000\n",
      "tensor([4.5885e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1732 --- loss: 0.000005\n",
      "tensor([4.9953e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1734 --- loss: 0.000000\n",
      "tensor([2.2053e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1737 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1739 --- loss: 0.000150\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1742 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1744 --- loss: 0.000015\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1747 --- loss: 0.000001\n",
      "tensor([1.6875e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1749 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1752 --- loss: 0.000048\n",
      "tensor([2.8566e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1754 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1757 --- loss: 0.000007\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1759 --- loss: 0.000002\n",
      "tensor([5.0982e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1762 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1764 --- loss: 0.000001\n",
      "tensor([6.3866e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1767 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1769 --- loss: 0.000001\n",
      "tensor([8.9605e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1772 --- loss: 0.000009\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1775 --- loss: 0.000593\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1777 --- loss: 0.000004\n",
      "tensor([2.5352e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1780 --- loss: 0.000000\n",
      "tensor([7.7417e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1782 --- loss: 0.000000\n",
      "tensor([3.9845e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1785 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1787 --- loss: 0.000027\n",
      "tensor([2.9331e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1790 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1792 --- loss: 0.000010\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1795 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1797 --- loss: 0.000003\n",
      "tensor([7.6030e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1800 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1802 --- loss: 0.000000\n",
      "tensor([7.6615e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1805 --- loss: 0.000000\n",
      "tensor([8.8474e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1807 --- loss: 0.000000\n",
      "tensor([1.7160e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1810 --- loss: 0.000000\n",
      "tensor([3.0954e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1812 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1815 --- loss: 0.000001\n",
      "tensor([5.2812e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1817 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1820 --- loss: 0.000113\n",
      "tensor([1.8056e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1823 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1825 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1828 --- loss: 0.000001\n",
      "tensor([5.9033e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1830 --- loss: 0.000001\n",
      "tensor([9.4126e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1833 --- loss: 0.000009\n",
      "tensor([1.5155e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1835 --- loss: 0.000000\n",
      "tensor([3.1528e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1838 --- loss: 0.000000\n",
      "tensor([2.4923e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1840 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1843 --- loss: 0.000107\n",
      "tensor([0.0062], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1845 --- loss: 0.006170\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1848 --- loss: 0.000208\n",
      "tensor([1.2132e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1850 --- loss: 0.000012\n",
      "tensor([8.7835e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1853 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1855 --- loss: 0.000219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0139e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1858 --- loss: 0.000010\n",
      "tensor([1.0545e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1860 --- loss: 0.000000\n",
      "tensor([2.0413e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1863 --- loss: 0.000020\n",
      "tensor([4.5946e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1866 --- loss: 0.000000\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1868 --- loss: 0.000250\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1871 --- loss: 0.000002\n",
      "tensor([7.5117e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1873 --- loss: 0.000075\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1876 --- loss: 0.000005\n",
      "tensor([4.6011e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1878 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1881 --- loss: 0.000002\n",
      "tensor([2.8731e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1883 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1886 --- loss: 0.000002\n",
      "tensor([8.5789e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1888 --- loss: 0.000086\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1891 --- loss: 0.000001\n",
      "tensor([3.9743e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1893 --- loss: 0.000000\n",
      "tensor([2.2962e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1896 --- loss: 0.000002\n",
      "tensor([0.0053], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1898 --- loss: 0.005310\n",
      "tensor([4.5376e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1901 --- loss: 0.000045\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1903 --- loss: 0.000238\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1906 --- loss: 0.000001\n",
      "tensor([8.4551e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1908 --- loss: 0.000085\n",
      "tensor([4.1614e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1911 --- loss: 0.000000\n",
      "tensor([1.5028e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1914 --- loss: 0.000015\n",
      "tensor([0.0307], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1916 --- loss: 0.031197\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1919 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1921 --- loss: 0.000000\n",
      "tensor([4.3208e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1924 --- loss: 0.000000\n",
      "tensor([2.7377e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1926 --- loss: 0.000027\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1929 --- loss: 0.000004\n",
      "tensor([1.9358e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1931 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1934 --- loss: 0.000002\n",
      "tensor([0.0068], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1936 --- loss: 0.006868\n",
      "tensor([5.1000e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1939 --- loss: 0.000000\n",
      "tensor([7.7155e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1941 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1944 --- loss: 0.000003\n",
      "tensor([2.2663e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1946 --- loss: 0.000000\n",
      "tensor([9.5527e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1949 --- loss: 0.000000\n",
      "tensor([5.0862e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1951 --- loss: 0.000000\n",
      "tensor([8.0591e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1954 --- loss: 0.000081\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1957 --- loss: 0.000002\n",
      "tensor([4.8359e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1959 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1962 --- loss: 0.000009\n",
      "tensor([7.2259e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1964 --- loss: 0.000000\n",
      "tensor([9.7816e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1967 --- loss: 0.000098\n",
      "tensor([1.4311e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1969 --- loss: 0.000000\n",
      "tensor([3.8780e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1972 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1974 --- loss: 0.000135\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1977 --- loss: 0.000127\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1979 --- loss: 0.000001\n",
      "tensor([6.3495e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1982 --- loss: 0.000000\n",
      "tensor([5.5196e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1984 --- loss: 0.000001\n",
      "tensor([2.3792e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1987 --- loss: 0.000024\n",
      "tensor([4.3249e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.1989 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1992 --- loss: 0.000009\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1994 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1997 --- loss: 0.000021\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.1999 --- loss: 0.000007\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2002 --- loss: 0.000084\n",
      "tensor([8.6172e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2005 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2007 --- loss: 0.000002\n",
      "tensor([1.2986e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2010 --- loss: 0.000013\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2012 --- loss: 0.000000\n",
      "tensor([4.0312e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2015 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2017 --- loss: 0.000000\n",
      "tensor([2.4451e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2020 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2022 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2025 --- loss: 0.000000\n",
      "tensor([3.4585e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2027 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2030 --- loss: 0.000012\n",
      "tensor([3.1682e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2032 --- loss: 0.000000\n",
      "tensor([1.7106e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2035 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2037 --- loss: 0.000001\n",
      "tensor([3.6610e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2040 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2042 --- loss: 0.000000\n",
      "tensor([0.0021], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2045 --- loss: 0.002112\n",
      "tensor([4.0244e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2048 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2050 --- loss: 0.000119\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2053 --- loss: 0.000010\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2055 --- loss: 0.000016\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2058 --- loss: 0.000011\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2060 --- loss: 0.000797\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2063 --- loss: 0.000000\n",
      "tensor([1.4927e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2065 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2068 --- loss: 0.000160\n",
      "tensor([1.3061e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2070 --- loss: 0.000013\n",
      "tensor([3.7849e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2073 --- loss: 0.000000\n",
      "tensor([1.2481e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2075 --- loss: 0.000000\n",
      "tensor([5.3465e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2078 --- loss: 0.000053\n",
      "tensor([9.5907e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2080 --- loss: 0.000000\n",
      "tensor([1.3396e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2083 --- loss: 0.000000\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2085 --- loss: 0.000638\n",
      "tensor([1.7366e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2088 --- loss: 0.000017\n",
      "tensor([0.6097], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2090 --- loss: 0.940731\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2093 --- loss: 0.000020\n",
      "tensor([5.5255e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2096 --- loss: 0.000006\n",
      "tensor([2.1971e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2098 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2101 --- loss: 0.000027\n",
      "tensor([8.9269e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2103 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2106 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2108 --- loss: 0.000242\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2111 --- loss: 0.000005\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2113 --- loss: 0.000192\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2116 --- loss: 0.000008\n",
      "tensor([4.3524e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2118 --- loss: 0.000000\n",
      "tensor([5.9600e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2121 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2123 --- loss: 0.000012\n",
      "tensor([1.2277e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2126 --- loss: 0.000000\n",
      "tensor([0.9962], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2128 --- loss: 0.003817\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2131 --- loss: 0.000106\n",
      "tensor([6.2638e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2133 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2136 --- loss: 0.000010\n",
      "tensor([1.3008e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2139 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2141 --- loss: 0.000140\n",
      "tensor([8.2580e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2144 --- loss: 0.000000\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2146 --- loss: 0.000486\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2149 --- loss: 0.000078\n",
      "tensor([4.6327e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2151 --- loss: 0.000005\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2154 --- loss: 0.000092\n",
      "tensor([0.9970], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2156 --- loss: 0.002967\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2159 --- loss: 0.000190\n",
      "tensor([4.3246e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2161 --- loss: 0.000000\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2164 --- loss: 0.000857\n",
      "tensor([2.2568e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2166 --- loss: 0.000000\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2169 --- loss: 0.000711\n",
      "tensor([2.7032e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2171 --- loss: 0.000000\n",
      "tensor([0.9904], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2174 --- loss: 0.009622\n",
      "tensor([9.3578e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2176 --- loss: 0.000000\n",
      "tensor([2.4915e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2179 --- loss: 0.000002\n",
      "tensor([1.9070e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2181 --- loss: 0.000000\n",
      "tensor([0.9979], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2184 --- loss: 0.002056\n",
      "tensor([8.1740e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2187 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2189 --- loss: 0.000014\n",
      "tensor([1.1397e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2192 --- loss: 0.000000\n",
      "tensor([1.8142e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2194 --- loss: 0.000000\n",
      "tensor([2.3517e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2197 --- loss: 0.000002\n",
      "tensor([0.9860], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2199 --- loss: 0.014101\n",
      "tensor([5.0540e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2202 --- loss: 0.000000\n",
      "tensor([1.0686e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2204 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2207 --- loss: 0.000060\n",
      "tensor([1.8959e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2209 --- loss: 0.000002\n",
      "tensor([1.4537e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2212 --- loss: 0.000000\n",
      "tensor([7.0658e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2214 --- loss: 0.000000\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2217 --- loss: 0.001160\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2219 --- loss: 0.001084\n",
      "tensor([0.9910], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2222 --- loss: 0.008994\n",
      "tensor([1.4350e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2224 --- loss: 0.000001\n",
      "tensor([4.5082e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2227 --- loss: 0.000000\n",
      "tensor([4.2028e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2230 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2232 --- loss: 0.000297\n",
      "tensor([3.4780e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2235 --- loss: 0.000000\n",
      "tensor([4.7963e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2237 --- loss: 0.000000\n",
      "tensor([1.6201e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2240 --- loss: 0.000000\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2242 --- loss: 0.000478\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2245 --- loss: 0.000103\n",
      "tensor([1.5519e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2247 --- loss: 0.000000\n",
      "tensor([5.6969e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2250 --- loss: 0.000000\n",
      "tensor([4.0711e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2252 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2255 --- loss: 0.000013\n",
      "tensor([1.1185e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2257 --- loss: 0.000000\n",
      "tensor([9.7652e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2260 --- loss: 0.000000\n",
      "tensor([0.9678], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2262 --- loss: 0.032706\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2265 --- loss: 0.000126\n",
      "tensor([1.1903e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2267 --- loss: 0.000012\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2270 --- loss: 0.000055\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2272 --- loss: 0.000106\n",
      "tensor([3.1984e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2275 --- loss: 0.000000\n",
      "tensor([0.9963], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2278 --- loss: 0.003675\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2280 --- loss: 0.001064\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2283 --- loss: 0.001592\n",
      "tensor([7.4428e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2285 --- loss: 0.000000\n",
      "tensor([7.4613e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2288 --- loss: 0.000000\n",
      "tensor([2.5680e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2290 --- loss: 0.000000\n",
      "tensor([1.0565e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2293 --- loss: 0.000000\n",
      "tensor([1.4600e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2295 --- loss: 0.000000\n",
      "tensor([3.0362e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2298 --- loss: 0.000000\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2300 --- loss: 0.000398\n",
      "tensor([3.4158e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2303 --- loss: 0.000034\n",
      "tensor([1.4281e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2305 --- loss: 0.000000\n",
      "tensor([4.8261e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2308 --- loss: 0.000000\n",
      "tensor([2.5669e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2310 --- loss: 0.000000\n",
      "tensor([4.4352e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2313 --- loss: 0.000000\n",
      "tensor([1.4944e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2315 --- loss: 0.000000\n",
      "tensor([4.1275e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2318 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2321 --- loss: 0.000094\n",
      "tensor([3.4251e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2323 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2326 --- loss: 0.000053\n",
      "tensor([1.8782e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2328 --- loss: 0.000019\n",
      "tensor([0.9964], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2331 --- loss: 0.003570\n",
      "tensor([1.2869e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2333 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2336 --- loss: 0.000054\n",
      "tensor([5.9752e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2338 --- loss: 0.000001\n",
      "tensor([0.9985], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2341 --- loss: 0.001482\n",
      "tensor([9.1684e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2343 --- loss: 0.000092\n",
      "tensor([1.5046e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2346 --- loss: 0.000000\n",
      "tensor([6.2947e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2348 --- loss: 0.000000\n",
      "tensor([6.9707e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2351 --- loss: 0.000000\n",
      "tensor([3.9532e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2353 --- loss: 0.000000\n",
      "tensor([1.8745e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2356 --- loss: 0.000002\n",
      "tensor([2.6248e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2358 --- loss: 0.000000\n",
      "tensor([0.9975], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2361 --- loss: 0.002477\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2363 --- loss: 0.000030\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2366 --- loss: 0.000279\n",
      "tensor([0.9979], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2369 --- loss: 0.002072\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2371 --- loss: 0.000455\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2374 --- loss: 0.000003\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2376 --- loss: 0.000187\n",
      "tensor([5.8055e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2379 --- loss: 0.000000\n",
      "tensor([3.4031e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2381 --- loss: 0.000000\n",
      "tensor([5.3953e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2384 --- loss: 0.000000\n",
      "tensor([0.9796], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2386 --- loss: 0.020586\n",
      "tensor([2.6835e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2389 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2391 --- loss: 0.000006\n",
      "tensor([5.1293e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2394 --- loss: 0.000001\n",
      "tensor([5.4123e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2396 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2399 --- loss: 0.000013\n",
      "tensor([1.1369e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2401 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2404 --- loss: 0.000015\n",
      "tensor([2.2220e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2406 --- loss: 0.000000\n",
      "tensor([0.9986], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2409 --- loss: 0.001369\n",
      "tensor([1.3922e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2412 --- loss: 0.000000\n",
      "tensor([0.9927], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2414 --- loss: 0.007289\n",
      "tensor([1.0287e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2417 --- loss: 0.000000\n",
      "tensor([2.8227e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2419 --- loss: 0.000000\n",
      "tensor([2.5685e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2422 --- loss: 0.000003\n",
      "tensor([5.6858e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2424 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2427 --- loss: 0.000003\n",
      "tensor([3.7265e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2429 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2432 --- loss: 0.000004\n",
      "tensor([2.9816e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2434 --- loss: 0.000000\n",
      "tensor([1.0467e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2437 --- loss: 0.000000\n",
      "tensor([2.0749e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2439 --- loss: 0.000000\n",
      "tensor([1.2445e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2442 --- loss: 0.000000\n",
      "tensor([0.9990], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2444 --- loss: 0.001010\n",
      "tensor([9.9225e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2447 --- loss: 0.000001\n",
      "tensor([0.9970], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2449 --- loss: 0.003032\n",
      "tensor([3.7519e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2452 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2454 --- loss: 0.000002\n",
      "tensor([0.9402], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2457 --- loss: 0.061616\n",
      "tensor([0.9986], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2460 --- loss: 0.001396\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2462 --- loss: 0.000031\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2465 --- loss: 0.000265\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2467 --- loss: 0.000666\n",
      "tensor([6.2361e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2470 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2472 --- loss: 0.000027\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2475 --- loss: 0.000008\n",
      "tensor([8.1976e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2477 --- loss: 0.000000\n",
      "tensor([4.1280e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2480 --- loss: 0.000000\n",
      "tensor([2.8234e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2482 --- loss: 0.000000\n",
      "tensor([1.5881e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2485 --- loss: 0.000000\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2487 --- loss: 0.000625\n",
      "tensor([4.6932e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2490 --- loss: 0.000005\n",
      "tensor([1.5672e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2492 --- loss: 0.000000\n",
      "tensor([1.4640e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2495 --- loss: 0.000000\n",
      "tensor([6.7916e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2497 --- loss: 0.000001\n",
      "tensor([1.0876e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2500 --- loss: 0.000000\n",
      "tensor([1.2482e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2503 --- loss: 0.000000\n",
      "tensor([0.9873], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2505 --- loss: 0.012777\n",
      "tensor([2.7874e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2508 --- loss: 0.000028\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2510 --- loss: 0.000003\n",
      "tensor([2.2296e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2513 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2515 --- loss: 0.000048\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2518 --- loss: 0.000012\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2520 --- loss: 0.001173\n",
      "tensor([6.2718e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2523 --- loss: 0.000000\n",
      "tensor([2.6044e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2525 --- loss: 0.000000\n",
      "tensor([9.3294e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2528 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2530 --- loss: 0.000106\n",
      "tensor([2.2110e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2533 --- loss: 0.000002\n",
      "tensor([3.1006e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2535 --- loss: 0.000000\n",
      "tensor([1.5203e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2538 --- loss: 0.000015\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2540 --- loss: 0.000010\n",
      "tensor([1.8083e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2543 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2546 --- loss: 0.000009\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2548 --- loss: 0.000106\n",
      "tensor([2.5187e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2551 --- loss: 0.000000\n",
      "tensor([5.0942e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2553 --- loss: 0.000000\n",
      "tensor([4.7570e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2556 --- loss: 0.000000\n",
      "tensor([2.1294e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2558 --- loss: 0.000000\n",
      "tensor([1.4242e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2561 --- loss: 0.000000\n",
      "tensor([1.0817e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2563 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2566 --- loss: 0.000124\n",
      "tensor([5.7249e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2568 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2571 --- loss: 0.000007\n",
      "tensor([3.9197e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2573 --- loss: 0.000000\n",
      "tensor([0.9979], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2576 --- loss: 0.002123\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2578 --- loss: 0.000509\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2581 --- loss: 0.000037\n",
      "tensor([2.7536e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2583 --- loss: 0.000000\n",
      "tensor([7.5464e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2586 --- loss: 0.000008\n",
      "tensor([2.2267e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2588 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2591 --- loss: 0.000319\n",
      "tensor([2.6675e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2594 --- loss: 0.000003\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2596 --- loss: 0.000633\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2599 --- loss: 0.000083\n",
      "tensor([3.3414e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2601 --- loss: 0.000000\n",
      "tensor([1.5542e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2604 --- loss: 0.000000\n",
      "tensor([7.7819e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2606 --- loss: 0.000000\n",
      "tensor([1.3463e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2609 --- loss: 0.000013\n",
      "tensor([2.1072e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2611 --- loss: 0.000000\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2614 --- loss: 0.000423\n",
      "tensor([0.8848], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2616 --- loss: 0.122446\n",
      "tensor([2.8328e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2619 --- loss: 0.000000\n",
      "tensor([2.7485e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2621 --- loss: 0.000000\n",
      "tensor([2.2140e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2624 --- loss: 0.000000\n",
      "tensor([8.0363e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2626 --- loss: 0.000008\n",
      "tensor([0.0018], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2629 --- loss: 0.001835\n",
      "tensor([1.6565e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2631 --- loss: 0.000017\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2634 --- loss: 0.000003\n",
      "tensor([0.9808], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2637 --- loss: 0.019358\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2639 --- loss: 0.000019\n",
      "tensor([1.2559e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2642 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2644 --- loss: 0.000016\n",
      "tensor([3.3146e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2647 --- loss: 0.000000\n",
      "tensor([7.0108e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2649 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2652 --- loss: 0.000004\n",
      "tensor([1.9583e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2654 --- loss: 0.000000\n",
      "tensor([2.6150e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2657 --- loss: 0.000000\n",
      "tensor([3.4611e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2659 --- loss: 0.000000\n",
      "tensor([1.7249e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2662 --- loss: 0.000000\n",
      "tensor([7.7795e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2664 --- loss: 0.000000\n",
      "tensor([1.3659e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2667 --- loss: 0.000000\n",
      "tensor([2.1467e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2669 --- loss: 0.000000\n",
      "tensor([1.6918e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2672 --- loss: 0.000000\n",
      "tensor([2.1982e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2674 --- loss: 0.000002\n",
      "tensor([9.0861e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2677 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2679 --- loss: 0.000025\n",
      "tensor([1.2915e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2682 --- loss: 0.000000\n",
      "tensor([1.3572e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2685 --- loss: 0.000014\n",
      "tensor([1.1921e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2687 --- loss: 0.000012\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2690 --- loss: 0.000001\n",
      "tensor([1.2472e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2692 --- loss: 0.000012\n",
      "tensor([1.8827e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2695 --- loss: 0.000000\n",
      "tensor([1.0360e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2697 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2700 --- loss: 0.000001\n",
      "tensor([4.9762e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2702 --- loss: 0.000005\n",
      "tensor([2.2198e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2705 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2707 --- loss: 0.000138\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2710 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2712 --- loss: 0.000021\n",
      "tensor([3.2384e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2715 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2717 --- loss: 0.000020\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2720 --- loss: 0.000224\n",
      "tensor([5.6964e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2722 --- loss: 0.000006\n",
      "tensor([5.9523e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2725 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2728 --- loss: 0.000069\n",
      "tensor([7.6777e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2730 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2733 --- loss: 0.000020\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2735 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2738 --- loss: 0.000001\n",
      "tensor([2.9534e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2740 --- loss: 0.000000\n",
      "tensor([6.7028e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2743 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2745 --- loss: 0.000006\n",
      "tensor([6.9430e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2748 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2750 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2753 --- loss: 0.000036\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2755 --- loss: 0.000053\n",
      "tensor([2.1734e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2758 --- loss: 0.000002\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2760 --- loss: 0.000316\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2763 --- loss: 0.000001\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2765 --- loss: 0.000220\n",
      "tensor([4.2174e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2768 --- loss: 0.000004\n",
      "tensor([1.4816e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2770 --- loss: 0.000000\n",
      "tensor([4.6956e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2773 --- loss: 0.000000\n",
      "tensor([2.5783e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2776 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2778 --- loss: 0.000031\n",
      "tensor([1.2819e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2781 --- loss: 0.000013\n",
      "tensor([2.2298e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2783 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2786 --- loss: 0.000006\n",
      "tensor([1.5981e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2788 --- loss: 0.000002\n",
      "tensor([2.1507e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2791 --- loss: 0.000000\n",
      "tensor([7.5682e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2793 --- loss: 0.000000\n",
      "tensor([4.6260e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2796 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2798 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2801 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2803 --- loss: 0.000015\n",
      "tensor([2.2735e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2806 --- loss: 0.000023\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2808 --- loss: 0.000023\n",
      "tensor([1.3073e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2811 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2813 --- loss: 0.000022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.1900e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2816 --- loss: 0.000008\n",
      "tensor([2.0125e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2819 --- loss: 0.000000\n",
      "tensor([2.1135e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2821 --- loss: 0.000002\n",
      "tensor([7.7746e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2824 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2826 --- loss: 0.000013\n",
      "tensor([3.9802e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2829 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2831 --- loss: 0.000024\n",
      "tensor([1.3422e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2834 --- loss: 0.000000\n",
      "tensor([3.9113e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2836 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2839 --- loss: 0.000012\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2841 --- loss: 0.000142\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2844 --- loss: 0.000019\n",
      "tensor([9.5528e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2846 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2849 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2851 --- loss: 0.000007\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2854 --- loss: 0.000079\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2856 --- loss: 0.000787\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2859 --- loss: 0.000082\n",
      "tensor([2.1176e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2861 --- loss: 0.000002\n",
      "tensor([1.0511e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2864 --- loss: 0.000000\n",
      "tensor([5.4555e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2867 --- loss: 0.000055\n",
      "tensor([1.5138e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2869 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2872 --- loss: 0.000005\n",
      "tensor([1.0185e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2874 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2877 --- loss: 0.000012\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2879 --- loss: 0.000081\n",
      "tensor([7.4856e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2882 --- loss: 0.000000\n",
      "tensor([1.7148e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2884 --- loss: 0.000000\n",
      "tensor([4.0143e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2887 --- loss: 0.000004\n",
      "tensor([1.9084e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2889 --- loss: 0.000000\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2892 --- loss: 0.000695\n",
      "tensor([0.9903], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2894 --- loss: 0.009701\n",
      "tensor([6.7993e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2897 --- loss: 0.000007\n",
      "tensor([1.7137e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2899 --- loss: 0.000017\n",
      "tensor([1.7600e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2902 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2904 --- loss: 0.000008\n",
      "tensor([1.0474e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2907 --- loss: 0.000000\n",
      "tensor([4.0615e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2910 --- loss: 0.000000\n",
      "tensor([3.4782e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2912 --- loss: 0.000000\n",
      "tensor([9.9818e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2915 --- loss: 0.000000\n",
      "tensor([2.1644e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2917 --- loss: 0.000000\n",
      "tensor([2.9348e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2920 --- loss: 0.000000\n",
      "tensor([6.0154e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2922 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2925 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2927 --- loss: 0.000106\n",
      "tensor([7.7567e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2930 --- loss: 0.000000\n",
      "tensor([4.5432e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2932 --- loss: 0.000000\n",
      "tensor([1.0491e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2935 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2937 --- loss: 0.000002\n",
      "tensor([3.4634e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2940 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2942 --- loss: 0.000005\n",
      "tensor([1.4895e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2945 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2947 --- loss: 0.000028\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2950 --- loss: 0.000008\n",
      "tensor([1.6805e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2952 --- loss: 0.000000\n",
      "tensor([1.7854e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2955 --- loss: 0.000000\n",
      "tensor([2.4954e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2958 --- loss: 0.000000\n",
      "tensor([3.0331e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2960 --- loss: 0.000000\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2963 --- loss: 0.000345\n",
      "tensor([1.2241e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2965 --- loss: 0.000000\n",
      "tensor([1.0029e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2968 --- loss: 0.000001\n",
      "tensor([6.7288e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2970 --- loss: 0.000000\n",
      "tensor([5.5214e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2973 --- loss: 0.000000\n",
      "tensor([5.3627e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2975 --- loss: 0.000001\n",
      "tensor([4.0181e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2978 --- loss: 0.000000\n",
      "tensor([6.9018e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2980 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.2983 --- loss: 0.000002\n",
      "tensor([4.6532e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2985 --- loss: 0.000047\n",
      "tensor([2.0959e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2988 --- loss: 0.000000\n",
      "tensor([1.0764e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2990 --- loss: 0.000000\n",
      "tensor([5.2482e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2993 --- loss: 0.000005\n",
      "tensor([2.7186e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2995 --- loss: 0.000003\n",
      "tensor([3.4004e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.2998 --- loss: 0.000000\n",
      "tensor([1.2671e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3001 --- loss: 0.000000\n",
      "tensor([1.5410e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3003 --- loss: 0.000002\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3006 --- loss: 0.000109\n",
      "tensor([4.9834e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3008 --- loss: 0.000050\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3011 --- loss: 0.000002\n",
      "tensor([5.0399e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3013 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3016 --- loss: 0.000039\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3018 --- loss: 0.000003\n",
      "tensor([1.9852e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3021 --- loss: 0.000002\n",
      "tensor([6.4077e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3023 --- loss: 0.000064\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3026 --- loss: 0.000092\n",
      "tensor([8.3393e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3028 --- loss: 0.000083\n",
      "tensor([2.6523e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3031 --- loss: 0.000027\n",
      "tensor([2.6990e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3033 --- loss: 0.000000\n",
      "tensor([3.4771e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3036 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3038 --- loss: 0.000018\n",
      "tensor([5.6531e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3041 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3043 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3046 --- loss: 0.000000\n",
      "tensor([0.9962], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3049 --- loss: 0.003762\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3051 --- loss: 0.000029\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3054 --- loss: 0.000000\n",
      "tensor([5.5469e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3056 --- loss: 0.000006\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3059 --- loss: 0.000307\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3061 --- loss: 0.000033\n",
      "tensor([2.3813e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3064 --- loss: 0.000002\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3066 --- loss: 0.001198\n",
      "tensor([6.9050e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3069 --- loss: 0.000007\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3071 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3074 --- loss: 0.000021\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3076 --- loss: 0.000003\n",
      "tensor([4.4031e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3079 --- loss: 0.000044\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3081 --- loss: 0.000001\n",
      "tensor([2.3512e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3084 --- loss: 0.000000\n",
      "tensor([5.3271e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3086 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3089 --- loss: 0.000185\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3092 --- loss: 0.000006\n",
      "tensor([2.0677e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3094 --- loss: 0.000000\n",
      "tensor([7.3469e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3097 --- loss: 0.000073\n",
      "tensor([1.6966e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3099 --- loss: 0.000000\n",
      "tensor([6.7012e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3102 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3104 --- loss: 0.000051\n",
      "tensor([2.3404e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3107 --- loss: 0.000000\n",
      "tensor([1.4896e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3109 --- loss: 0.000000\n",
      "tensor([1.0812e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3112 --- loss: 0.000000\n",
      "tensor([9.8730e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3114 --- loss: 0.000001\n",
      "tensor([1.2013e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3117 --- loss: 0.000012\n",
      "tensor([1.0400e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3119 --- loss: 0.000010\n",
      "tensor([2.6489e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3122 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3124 --- loss: 0.000001\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3127 --- loss: 0.000100\n",
      "tensor([0.0012], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3129 --- loss: 0.001193\n",
      "tensor([2.9248e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3132 --- loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.8215e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3134 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3137 --- loss: 0.000013\n",
      "tensor([2.3409e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3140 --- loss: 0.000000\n",
      "tensor([1.5921e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3142 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3145 --- loss: 0.000032\n",
      "tensor([1.2175e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3147 --- loss: 0.000012\n",
      "tensor([6.6452e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3150 --- loss: 0.000000\n",
      "tensor([3.5722e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3152 --- loss: 0.000000\n",
      "tensor([1.2875e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3155 --- loss: 0.000013\n",
      "tensor([6.1656e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3157 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3160 --- loss: 0.000060\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3162 --- loss: 0.000207\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3165 --- loss: 0.000006\n",
      "tensor([3.6085e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3167 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3170 --- loss: 0.000006\n",
      "tensor([7.9129e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3172 --- loss: 0.000000\n",
      "tensor([9.2214e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3175 --- loss: 0.000000\n",
      "tensor([7.3232e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3177 --- loss: 0.000000\n",
      "tensor([2.3813e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3180 --- loss: 0.000000\n",
      "tensor([4.4409e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3183 --- loss: 0.000000\n",
      "tensor([4.5988e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3185 --- loss: 0.000000\n",
      "tensor([5.5966e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3188 --- loss: 0.000000\n",
      "tensor([4.4955e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3190 --- loss: 0.000000\n",
      "tensor([1.8662e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3193 --- loss: 0.000019\n",
      "tensor([1.2817e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3195 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3198 --- loss: 0.000070\n",
      "tensor([9.6780e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3200 --- loss: 0.000000\n",
      "tensor([1.4540e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3203 --- loss: 0.000000\n",
      "tensor([7.2841e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3205 --- loss: 0.000000\n",
      "tensor([2.0920e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3208 --- loss: 0.000000\n",
      "tensor([1.4921e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3210 --- loss: 0.000000\n",
      "tensor([3.9250e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3213 --- loss: 0.000000\n",
      "tensor([2.6282e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3215 --- loss: 0.000000\n",
      "tensor([1.2888e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3218 --- loss: 0.000000\n",
      "tensor([4.9645e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3220 --- loss: 0.000000\n",
      "tensor([3.6112e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3223 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3225 --- loss: 0.000005\n",
      "tensor([4.4694e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3228 --- loss: 0.000000\n",
      "tensor([1.3968e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3231 --- loss: 0.000000\n",
      "tensor([3.7984e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3233 --- loss: 0.000004\n",
      "tensor([6.9433e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3236 --- loss: 0.000000\n",
      "tensor([5.1436e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3238 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3241 --- loss: 0.000017\n",
      "tensor([2.6108e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3243 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3246 --- loss: 0.000001\n",
      "tensor([9.9929e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3248 --- loss: 0.000010\n",
      "tensor([3.5092e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3251 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3253 --- loss: 0.000000\n",
      "tensor([3.3590e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3256 --- loss: 0.000000\n",
      "tensor([3.4594e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3258 --- loss: 0.000000\n",
      "tensor([1.8675e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3261 --- loss: 0.000019\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3263 --- loss: 0.000112\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3266 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3268 --- loss: 0.000006\n",
      "tensor([4.5902e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3271 --- loss: 0.000046\n",
      "tensor([3.5972e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3274 --- loss: 0.000000\n",
      "tensor([1.1990e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3276 --- loss: 0.000000\n",
      "tensor([1.9884e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3279 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3281 --- loss: 0.000001\n",
      "tensor([5.2177e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3284 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3286 --- loss: 0.000002\n",
      "tensor([3.1583e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3289 --- loss: 0.000000\n",
      "tensor([2.0296e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3291 --- loss: 0.000000\n",
      "tensor([1.1191e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3294 --- loss: 0.000000\n",
      "tensor([2.4022e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3296 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3299 --- loss: 0.000007\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3301 --- loss: 0.000239\n",
      "tensor([5.8150e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3304 --- loss: 0.000000\n",
      "tensor([1.5936e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3306 --- loss: 0.000000\n",
      "tensor([1.6800e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3309 --- loss: 0.000000\n",
      "tensor([6.8146e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3311 --- loss: 0.000000\n",
      "tensor([3.8197e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3314 --- loss: 0.000000\n",
      "tensor([9.1858e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3316 --- loss: 0.000000\n",
      "tensor([1.5142e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3319 --- loss: 0.000000\n",
      "tensor([1.5118e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3322 --- loss: 0.000000\n",
      "tensor([5.6467e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3324 --- loss: 0.000000\n",
      "tensor([4.1547e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3327 --- loss: 0.000000\n",
      "tensor([8.3433e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3329 --- loss: 0.000000\n",
      "tensor([8.1478e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3332 --- loss: 0.000000\n",
      "tensor([7.6475e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3334 --- loss: 0.000001\n",
      "tensor([7.5314e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3337 --- loss: 0.000000\n",
      "tensor([5.4930e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3339 --- loss: 0.000000\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3342 --- loss: 0.000491\n",
      "tensor([1.4350e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3344 --- loss: 0.000000\n",
      "tensor([2.4951e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3347 --- loss: 0.000000\n",
      "tensor([3.0029e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3349 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3352 --- loss: 0.000001\n",
      "tensor([2.1154e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3354 --- loss: 0.000002\n",
      "tensor([3.5616e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3357 --- loss: 0.000000\n",
      "tensor([2.4218e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3359 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3362 --- loss: 0.000002\n",
      "tensor([7.2852e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3365 --- loss: 0.000073\n",
      "tensor([0.0088], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3367 --- loss: 0.008868\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3370 --- loss: 0.000004\n",
      "tensor([1.2875e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3372 --- loss: 0.000000\n",
      "tensor([8.5394e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3375 --- loss: 0.000000\n",
      "tensor([1.1517e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3377 --- loss: 0.000012\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3380 --- loss: 0.000322\n",
      "tensor([4.1527e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3382 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3385 --- loss: 0.000049\n",
      "tensor([6.5564e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3387 --- loss: 0.000007\n",
      "tensor([2.9623e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3390 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3392 --- loss: 0.000048\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3395 --- loss: 0.000003\n",
      "tensor([5.5695e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3397 --- loss: 0.000000\n",
      "tensor([7.8968e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3400 --- loss: 0.000001\n",
      "tensor([3.8767e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3402 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3405 --- loss: 0.000023\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3407 --- loss: 0.000022\n",
      "tensor([0.0126], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3410 --- loss: 0.012646\n",
      "tensor([1.8361e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3413 --- loss: 0.000000\n",
      "tensor([4.6628e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3415 --- loss: 0.000000\n",
      "tensor([2.1109e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3418 --- loss: 0.000000\n",
      "tensor([1.1146e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3420 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3423 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3425 --- loss: 0.000000\n",
      "tensor([5.9117e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3428 --- loss: 0.000000\n",
      "tensor([5.2623e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3430 --- loss: 0.000053\n",
      "tensor([0.9981], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3433 --- loss: 0.001891\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3435 --- loss: 0.000329\n",
      "tensor([3.1205e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3438 --- loss: 0.000000\n",
      "tensor([1.6506e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3440 --- loss: 0.000000\n",
      "tensor([7.1721e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3443 --- loss: 0.000001\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3445 --- loss: 0.000153\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3448 --- loss: 0.000050\n",
      "tensor([2.3465e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3450 --- loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2505e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3453 --- loss: 0.000000\n",
      "tensor([6.3165e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3456 --- loss: 0.000000\n",
      "tensor([2.1769e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3458 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3461 --- loss: 0.000119\n",
      "tensor([6.8744e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3463 --- loss: 0.000000\n",
      "tensor([1.5345e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3466 --- loss: 0.000015\n",
      "tensor([1.5678e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3468 --- loss: 0.000000\n",
      "tensor([4.0407e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3471 --- loss: 0.000000\n",
      "tensor([7.4577e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3473 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3476 --- loss: 0.000026\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3478 --- loss: 0.000335\n",
      "tensor([0.0009], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3481 --- loss: 0.000891\n",
      "tensor([1.8554e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3483 --- loss: 0.000000\n",
      "tensor([5.9153e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3486 --- loss: 0.000001\n",
      "tensor([5.7874e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3488 --- loss: 0.000000\n",
      "tensor([6.8073e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3491 --- loss: 0.000007\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3493 --- loss: 0.000118\n",
      "tensor([1.1208e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3496 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3498 --- loss: 0.000001\n",
      "tensor([3.1628e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3501 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3504 --- loss: 0.000003\n",
      "tensor([8.2409e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3506 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3509 --- loss: 0.000078\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3511 --- loss: 0.000015\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3514 --- loss: 0.000207\n",
      "tensor([4.0683e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3516 --- loss: 0.000000\n",
      "tensor([1.9592e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3519 --- loss: 0.000000\n",
      "tensor([5.4279e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3521 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3524 --- loss: 0.000018\n",
      "tensor([1.0026e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3526 --- loss: 0.000000\n",
      "tensor([3.2787e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3529 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3531 --- loss: 0.000012\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3534 --- loss: 0.000001\n",
      "tensor([4.2556e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3536 --- loss: 0.000000\n",
      "tensor([1.0151e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3539 --- loss: 0.000000\n",
      "tensor([8.3284e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3541 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3544 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3547 --- loss: 0.000002\n",
      "tensor([4.5852e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3549 --- loss: 0.000046\n",
      "tensor([1.4481e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3552 --- loss: 0.000000\n",
      "tensor([2.4317e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3554 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3557 --- loss: 0.000218\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3559 --- loss: 0.000001\n",
      "tensor([1.6371e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3562 --- loss: 0.000000\n",
      "tensor([1.7213e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3564 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3567 --- loss: 0.000007\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3569 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3572 --- loss: 0.000008\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3574 --- loss: 0.000020\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3577 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3579 --- loss: 0.000014\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3582 --- loss: 0.000170\n",
      "tensor([1.2918e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3584 --- loss: 0.000000\n",
      "tensor([2.7316e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3587 --- loss: 0.000000\n",
      "tensor([4.4689e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3589 --- loss: 0.000000\n",
      "tensor([1.1835e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3592 --- loss: 0.000000\n",
      "tensor([4.0600e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3595 --- loss: 0.000000\n",
      "tensor([1.9846e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3597 --- loss: 0.000002\n",
      "tensor([1.4533e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3600 --- loss: 0.000000\n",
      "tensor([2.2524e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3602 --- loss: 0.000000\n",
      "tensor([3.5787e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3605 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3607 --- loss: 0.000012\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3610 --- loss: 0.000007\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3612 --- loss: 0.000002\n",
      "tensor([1.2515e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3615 --- loss: 0.000000\n",
      "tensor([1.9797e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3617 --- loss: 0.000000\n",
      "tensor([3.8359e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3620 --- loss: 0.000000\n",
      "tensor([4.6944e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3622 --- loss: 0.000047\n",
      "tensor([5.1294e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3625 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3627 --- loss: 0.000029\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3630 --- loss: 0.000050\n",
      "tensor([1.0866e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3632 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3635 --- loss: 0.000055\n",
      "tensor([5.4787e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3638 --- loss: 0.000000\n",
      "tensor([1.0956e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3640 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3643 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3645 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3648 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3650 --- loss: 0.000003\n",
      "tensor([1.4223e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3653 --- loss: 0.000000\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3655 --- loss: 0.000284\n",
      "tensor([7.5609e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3658 --- loss: 0.000008\n",
      "tensor([6.5781e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3660 --- loss: 0.000000\n",
      "tensor([5.7804e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3663 --- loss: 0.000000\n",
      "tensor([2.9757e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3665 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3668 --- loss: 0.000297\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3670 --- loss: 0.000026\n",
      "tensor([4.9399e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3673 --- loss: 0.000005\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3675 --- loss: 0.000121\n",
      "tensor([1.0462e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3678 --- loss: 0.000010\n",
      "tensor([1.4901e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3680 --- loss: 0.000000\n",
      "tensor([5.0527e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3683 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3686 --- loss: 0.000008\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3688 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3691 --- loss: 0.000022\n",
      "tensor([8.1060e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3693 --- loss: 0.000008\n",
      "tensor([1.6236e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3696 --- loss: 0.000016\n",
      "tensor([5.0786e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3698 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3701 --- loss: 0.000030\n",
      "tensor([1.3944e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3703 --- loss: 0.000000\n",
      "tensor([7.7769e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3706 --- loss: 0.000001\n",
      "tensor([0.0034], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3708 --- loss: 0.003366\n",
      "tensor([1.6097e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3711 --- loss: 0.000000\n",
      "tensor([2.6871e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3713 --- loss: 0.000000\n",
      "tensor([2.2276e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3716 --- loss: 0.000000\n",
      "tensor([8.4387e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3718 --- loss: 0.000001\n",
      "tensor([9.5245e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3721 --- loss: 0.000000\n",
      "tensor([9.7662e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3723 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3726 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3729 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3731 --- loss: 0.000002\n",
      "tensor([3.2695e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3734 --- loss: 0.000000\n",
      "tensor([8.7691e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3736 --- loss: 0.000000\n",
      "tensor([3.1888e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3739 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3741 --- loss: 0.000073\n",
      "tensor([1.1122e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3744 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3746 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3749 --- loss: 0.000013\n",
      "tensor([4.5129e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3751 --- loss: 0.000000\n",
      "tensor([2.0627e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3754 --- loss: 0.000000\n",
      "tensor([4.6563e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3756 --- loss: 0.000047\n",
      "tensor([8.7757e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3759 --- loss: 0.000000\n",
      "tensor([4.9796e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3761 --- loss: 0.000005\n",
      "tensor([1.4723e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3764 --- loss: 0.000000\n",
      "tensor([4.1884e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3766 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3769 --- loss: 0.000004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3771 --- loss: 0.000011\n",
      "tensor([1.0366e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3774 --- loss: 0.000000\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3777 --- loss: 0.000456\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3779 --- loss: 0.000002\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3782 --- loss: 0.000412\n",
      "tensor([1.9695e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3784 --- loss: 0.000020\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3787 --- loss: 0.000064\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3789 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3792 --- loss: 0.000017\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3794 --- loss: 0.000128\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3797 --- loss: 0.000005\n",
      "tensor([2.2774e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3799 --- loss: 0.000000\n",
      "tensor([1.2962e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3802 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3804 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3807 --- loss: 0.000034\n",
      "tensor([1.1702e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3809 --- loss: 0.000012\n",
      "tensor([2.0148e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3812 --- loss: 0.000000\n",
      "tensor([3.6398e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3814 --- loss: 0.000036\n",
      "tensor([7.8656e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3817 --- loss: 0.000000\n",
      "tensor([5.1637e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3820 --- loss: 0.000052\n",
      "tensor([1.8004e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3822 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3825 --- loss: 0.000002\n",
      "tensor([2.2806e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3827 --- loss: 0.000000\n",
      "tensor([1.2022e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3830 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3832 --- loss: 0.000006\n",
      "tensor([1.0995e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3835 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3837 --- loss: 0.000023\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3840 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3842 --- loss: 0.000001\n",
      "tensor([1.2732e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3845 --- loss: 0.000000\n",
      "tensor([8.9987e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3847 --- loss: 0.000000\n",
      "tensor([1.9805e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3850 --- loss: 0.000020\n",
      "tensor([3.3225e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3852 --- loss: 0.000000\n",
      "tensor([6.5455e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3855 --- loss: 0.000001\n",
      "tensor([2.3289e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3857 --- loss: 0.000023\n",
      "tensor([1.3692e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3860 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3862 --- loss: 0.000050\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3865 --- loss: 0.000000\n",
      "tensor([1.3899e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3868 --- loss: 0.000000\n",
      "tensor([9.5577e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3870 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3873 --- loss: 0.000004\n",
      "tensor([2.2343e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3875 --- loss: 0.000022\n",
      "tensor([8.1004e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3878 --- loss: 0.000000\n",
      "tensor([2.8100e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3880 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3883 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3885 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3888 --- loss: 0.000004\n",
      "tensor([1.3233e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3890 --- loss: 0.000013\n",
      "tensor([7.6888e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3893 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3895 --- loss: 0.000029\n",
      "tensor([4.2515e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3898 --- loss: 0.000000\n",
      "tensor([0.0013], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3900 --- loss: 0.001283\n",
      "tensor([2.7852e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3903 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3905 --- loss: 0.000028\n",
      "tensor([3.9803e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3908 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3911 --- loss: 0.000024\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3913 --- loss: 0.000231\n",
      "tensor([6.7702e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3916 --- loss: 0.000000\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3918 --- loss: 0.000522\n",
      "tensor([4.5775e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3921 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3923 --- loss: 0.000016\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3926 --- loss: 0.000034\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3928 --- loss: 0.000010\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3931 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3933 --- loss: 0.000041\n",
      "tensor([1.1139e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3936 --- loss: 0.000001\n",
      "tensor([8.5118e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3938 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3941 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3943 --- loss: 0.000003\n",
      "tensor([3.5039e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3946 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3948 --- loss: 0.000004\n",
      "tensor([1.5612e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3951 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3953 --- loss: 0.000002\n",
      "tensor([4.8561e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3956 --- loss: 0.000000\n",
      "tensor([0.0202], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3959 --- loss: 0.020381\n",
      "tensor([1.3652e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3961 --- loss: 0.000000\n",
      "tensor([3.0287e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3964 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3966 --- loss: 0.000000\n",
      "tensor([9.4836e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3969 --- loss: 0.000000\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3971 --- loss: 0.000323\n",
      "tensor([4.1978e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3974 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3976 --- loss: 0.000001\n",
      "tensor([2.3140e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3979 --- loss: 0.000000\n",
      "tensor([3.9311e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3981 --- loss: 0.000000\n",
      "tensor([3.7981e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3984 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3986 --- loss: 0.000009\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3989 --- loss: 0.000002\n",
      "tensor([1.1726e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3991 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.3994 --- loss: 0.000017\n",
      "tensor([9.3538e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3996 --- loss: 0.000000\n",
      "tensor([4.5075e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.3999 --- loss: 0.000000\n",
      "tensor([7.4902e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4002 --- loss: 0.000007\n",
      "tensor([5.0823e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4004 --- loss: 0.000000\n",
      "tensor([1.9034e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4007 --- loss: 0.000019\n",
      "tensor([5.3504e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4009 --- loss: 0.000000\n",
      "tensor([9.1979e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4012 --- loss: 0.000009\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4014 --- loss: 0.000003\n",
      "tensor([1.1157e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4017 --- loss: 0.000011\n",
      "tensor([1.5246e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4019 --- loss: 0.000000\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4022 --- loss: 0.000900\n",
      "tensor([8.2825e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4024 --- loss: 0.000000\n",
      "tensor([1.1070e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4027 --- loss: 0.000000\n",
      "tensor([3.5020e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4029 --- loss: 0.000000\n",
      "tensor([0.0016], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4032 --- loss: 0.001576\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4034 --- loss: 0.000140\n",
      "tensor([4.8905e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4037 --- loss: 0.000049\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4039 --- loss: 0.000131\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4042 --- loss: 0.000011\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4044 --- loss: 0.000038\n",
      "tensor([6.3645e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4047 --- loss: 0.000006\n",
      "tensor([2.1545e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4050 --- loss: 0.000002\n",
      "tensor([6.2704e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4052 --- loss: 0.000001\n",
      "tensor([1.2604e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4055 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4057 --- loss: 0.000201\n",
      "tensor([2.0160e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4060 --- loss: 0.000020\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4062 --- loss: 0.000134\n",
      "tensor([7.2900e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4065 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4067 --- loss: 0.000063\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4070 --- loss: 0.000165\n",
      "tensor([1.3210e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4072 --- loss: 0.000000\n",
      "tensor([3.0538e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4075 --- loss: 0.000000\n",
      "tensor([0.0131], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4077 --- loss: 0.013210\n",
      "tensor([1.7925e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4080 --- loss: 0.000000\n",
      "tensor([5.8052e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4082 --- loss: 0.000000\n",
      "tensor([7.3887e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4085 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4087 --- loss: 0.000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.3387e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4090 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4093 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4095 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4098 --- loss: 0.000029\n",
      "tensor([9.4659e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4100 --- loss: 0.000000\n",
      "tensor([8.9554e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4103 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4105 --- loss: 0.000007\n",
      "tensor([7.4187e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4108 --- loss: 0.000007\n",
      "tensor([8.2560e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4110 --- loss: 0.000000\n",
      "tensor([2.9377e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4113 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4115 --- loss: 0.000045\n",
      "tensor([2.4098e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4118 --- loss: 0.000000\n",
      "tensor([2.0796e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4120 --- loss: 0.000000\n",
      "tensor([9.9049e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4123 --- loss: 0.000099\n",
      "tensor([3.1950e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4125 --- loss: 0.000003\n",
      "tensor([2.4889e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4128 --- loss: 0.000000\n",
      "tensor([2.5947e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4130 --- loss: 0.000026\n",
      "tensor([6.9432e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4133 --- loss: 0.000007\n",
      "tensor([1.5408e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4135 --- loss: 0.000002\n",
      "tensor([1.9458e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4138 --- loss: 0.000000\n",
      "tensor([1.4361e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4141 --- loss: 0.000001\n",
      "tensor([2.7183e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4143 --- loss: 0.000000\n",
      "tensor([1.8328e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4146 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4148 --- loss: 0.000004\n",
      "tensor([1.2300e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4151 --- loss: 0.000000\n",
      "tensor([1.3737e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4153 --- loss: 0.000000\n",
      "tensor([2.6148e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4156 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4158 --- loss: 0.000011\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4161 --- loss: 0.000183\n",
      "tensor([1.4093e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4163 --- loss: 0.000014\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4166 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4168 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4171 --- loss: 0.000005\n",
      "tensor([1.4284e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4173 --- loss: 0.000000\n",
      "tensor([3.5973e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4176 --- loss: 0.000000\n",
      "tensor([5.1057e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4178 --- loss: 0.000000\n",
      "tensor([2.9979e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4181 --- loss: 0.000000\n",
      "tensor([3.1614e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4184 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4186 --- loss: 0.000000\n",
      "tensor([2.3236e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4189 --- loss: 0.000000\n",
      "tensor([1.9405e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4191 --- loss: 0.000000\n",
      "tensor([2.5699e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4194 --- loss: 0.000003\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4196 --- loss: 0.000284\n",
      "tensor([2.9036e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4199 --- loss: 0.000000\n",
      "tensor([0.0030], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4201 --- loss: 0.003018\n",
      "tensor([1.9893e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4204 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4206 --- loss: 0.000002\n",
      "tensor([2.1060e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4209 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4211 --- loss: 0.000024\n",
      "tensor([4.3916e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4214 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4216 --- loss: 0.000107\n",
      "tensor([0.0102], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4219 --- loss: 0.010277\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4221 --- loss: 0.000129\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4224 --- loss: 0.000111\n",
      "tensor([2.6143e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4226 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4229 --- loss: 0.000001\n",
      "tensor([2.5611e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4232 --- loss: 0.000000\n",
      "tensor([1.7191e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4234 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4237 --- loss: 0.000006\n",
      "tensor([2.4463e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4239 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4242 --- loss: 0.000006\n",
      "tensor([2.3750e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4244 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4247 --- loss: 0.000001\n",
      "tensor([9.3551e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4249 --- loss: 0.000000\n",
      "tensor([3.2559e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4252 --- loss: 0.000033\n",
      "tensor([5.5165e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4254 --- loss: 0.000055\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4257 --- loss: 0.000002\n",
      "tensor([8.8943e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4259 --- loss: 0.000000\n",
      "tensor([3.6099e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4262 --- loss: 0.000036\n",
      "tensor([3.0057e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4264 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4267 --- loss: 0.000001\n",
      "tensor([0.9981], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4269 --- loss: 0.001930\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4272 --- loss: 0.000055\n",
      "tensor([1.0713e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4275 --- loss: 0.000000\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4277 --- loss: 0.000423\n",
      "tensor([7.0252e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4280 --- loss: 0.000000\n",
      "tensor([8.5983e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4282 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4285 --- loss: 0.000082\n",
      "tensor([4.0774e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4287 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4290 --- loss: 0.000268\n",
      "tensor([6.3747e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4292 --- loss: 0.000000\n",
      "tensor([1.0501e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4295 --- loss: 0.000000\n",
      "tensor([6.6379e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4297 --- loss: 0.000001\n",
      "tensor([0.0020], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4300 --- loss: 0.001963\n",
      "tensor([3.4685e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4302 --- loss: 0.000035\n",
      "tensor([3.7072e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4305 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4307 --- loss: 0.000007\n",
      "tensor([3.6244e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4310 --- loss: 0.000000\n",
      "tensor([3.5609e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4312 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4315 --- loss: 0.000001\n",
      "tensor([5.6887e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4317 --- loss: 0.000000\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4320 --- loss: 0.000482\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4323 --- loss: 0.000027\n",
      "tensor([8.5242e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4325 --- loss: 0.000000\n",
      "tensor([3.5768e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4328 --- loss: 0.000000\n",
      "tensor([9.9370e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4330 --- loss: 0.000001\n",
      "tensor([1.9938e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4333 --- loss: 0.000000\n",
      "tensor([3.4197e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4335 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4338 --- loss: 0.000117\n",
      "tensor([9.8901e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4340 --- loss: 0.000000\n",
      "tensor([9.0288e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4343 --- loss: 0.000001\n",
      "tensor([5.9074e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4345 --- loss: 0.000000\n",
      "tensor([3.7164e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4348 --- loss: 0.000000\n",
      "tensor([1.1074e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4350 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4353 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4355 --- loss: 0.000003\n",
      "tensor([3.8488e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4358 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4360 --- loss: 0.000023\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4363 --- loss: 0.000001\n",
      "tensor([1.4408e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4366 --- loss: 0.000014\n",
      "tensor([9.1570e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4368 --- loss: 0.000009\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4371 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4373 --- loss: 0.000011\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4376 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4378 --- loss: 0.000067\n",
      "tensor([0.0053], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4381 --- loss: 0.005280\n",
      "tensor([2.3753e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4383 --- loss: 0.000000\n",
      "tensor([8.4022e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4386 --- loss: 0.000000\n",
      "tensor([2.5749e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4388 --- loss: 0.000003\n",
      "tensor([1.5922e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4391 --- loss: 0.000000\n",
      "tensor([8.2497e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4393 --- loss: 0.000000\n",
      "tensor([4.4530e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4396 --- loss: 0.000004\n",
      "tensor([1.9301e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4398 --- loss: 0.000019\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4401 --- loss: 0.000038\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4403 --- loss: 0.000003\n",
      "tensor([4.1016e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4406 --- loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4408 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4411 --- loss: 0.000162\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4414 --- loss: 0.000056\n",
      "tensor([5.5978e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4416 --- loss: 0.000056\n",
      "tensor([2.1270e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4419 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4421 --- loss: 0.000004\n",
      "tensor([2.7565e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4424 --- loss: 0.000003\n",
      "tensor([3.6722e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4426 --- loss: 0.000000\n",
      "tensor([1.2420e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4429 --- loss: 0.000012\n",
      "tensor([3.4005e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4431 --- loss: 0.000000\n",
      "tensor([0.9909], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4434 --- loss: 0.009178\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4436 --- loss: 0.000031\n",
      "tensor([5.7767e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4439 --- loss: 0.000000\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4441 --- loss: 0.000827\n",
      "tensor([8.6788e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4444 --- loss: 0.000000\n",
      "tensor([5.0272e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4446 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4449 --- loss: 0.000030\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4451 --- loss: 0.000002\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4454 --- loss: 0.000200\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4457 --- loss: 0.000370\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4459 --- loss: 0.000073\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4462 --- loss: 0.000002\n",
      "tensor([2.7507e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4464 --- loss: 0.000000\n",
      "tensor([3.4307e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4467 --- loss: 0.000000\n",
      "tensor([1.1547e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4469 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4472 --- loss: 0.000012\n",
      "tensor([6.5433e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4474 --- loss: 0.000000\n",
      "tensor([4.4638e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4477 --- loss: 0.000004\n",
      "tensor([1.1446e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4479 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4482 --- loss: 0.000202\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4484 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4487 --- loss: 0.000004\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4489 --- loss: 0.000070\n",
      "tensor([2.7896e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4492 --- loss: 0.000028\n",
      "tensor([2.3053e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4494 --- loss: 0.000000\n",
      "tensor([3.6671e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4497 --- loss: 0.000004\n",
      "tensor([2.6100e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4499 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4502 --- loss: 0.000023\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4505 --- loss: 0.000012\n",
      "tensor([1.5278e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4507 --- loss: 0.000015\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4510 --- loss: 0.000029\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4512 --- loss: 0.000115\n",
      "tensor([4.3531e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4515 --- loss: 0.000004\n",
      "tensor([9.7913e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4517 --- loss: 0.000000\n",
      "tensor([2.1553e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4520 --- loss: 0.000000\n",
      "tensor([2.5479e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4522 --- loss: 0.000000\n",
      "tensor([4.7662e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4525 --- loss: 0.000000\n",
      "tensor([4.8769e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4527 --- loss: 0.000000\n",
      "tensor([7.6668e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4530 --- loss: 0.000000\n",
      "tensor([2.0695e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4532 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4535 --- loss: 0.000180\n",
      "tensor([2.3239e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4537 --- loss: 0.000023\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4540 --- loss: 0.000073\n",
      "tensor([1.8455e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4542 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4545 --- loss: 0.000019\n",
      "tensor([2.7508e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4548 --- loss: 0.000000\n",
      "tensor([1.8608e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4550 --- loss: 0.000000\n",
      "tensor([1.4397e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4553 --- loss: 0.000000\n",
      "tensor([3.9474e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4555 --- loss: 0.000000\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4558 --- loss: 0.000364\n",
      "tensor([1.0479e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4560 --- loss: 0.000000\n",
      "tensor([1.1506e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4563 --- loss: 0.000000\n",
      "tensor([5.8818e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4565 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4568 --- loss: 0.000000\n",
      "tensor([4.6241e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4570 --- loss: 0.000000\n",
      "tensor([1.1366e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4573 --- loss: 0.000000\n",
      "tensor([5.9424e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4575 --- loss: 0.000000\n",
      "tensor([5.5711e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4578 --- loss: 0.000056\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4580 --- loss: 0.000708\n",
      "tensor([5.1461e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4583 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4585 --- loss: 0.000050\n",
      "tensor([3.4663e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4588 --- loss: 0.000000\n",
      "tensor([1.2923e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4590 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4593 --- loss: 0.000001\n",
      "tensor([8.2885e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4596 --- loss: 0.000001\n",
      "tensor([4.6365e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4598 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4601 --- loss: 0.000026\n",
      "tensor([3.7786e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4603 --- loss: 0.000000\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4606 --- loss: 0.000314\n",
      "tensor([3.0616e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4608 --- loss: 0.000000\n",
      "tensor([1.9850e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4611 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4613 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4616 --- loss: 0.000002\n",
      "tensor([7.9977e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4618 --- loss: 0.000000\n",
      "tensor([4.5464e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4621 --- loss: 0.000000\n",
      "tensor([0.5911], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4623 --- loss: 0.894367\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4626 --- loss: 0.000200\n",
      "tensor([1.7763e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4628 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4631 --- loss: 0.000032\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4633 --- loss: 0.000505\n",
      "tensor([5.5271e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4636 --- loss: 0.000000\n",
      "tensor([1.6258e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4639 --- loss: 0.000000\n",
      "tensor([1.1682e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4641 --- loss: 0.000000\n",
      "tensor([0.9978], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4644 --- loss: 0.002208\n",
      "tensor([2.4452e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4646 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4649 --- loss: 0.000038\n",
      "tensor([1.1094e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4651 --- loss: 0.000000\n",
      "tensor([7.8678e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4654 --- loss: 0.000000\n",
      "tensor([8.0167e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4656 --- loss: 0.000000\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4659 --- loss: 0.000905\n",
      "tensor([4.0184e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4661 --- loss: 0.000000\n",
      "tensor([2.4760e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4664 --- loss: 0.000000\n",
      "tensor([4.8836e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4666 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4669 --- loss: 0.000163\n",
      "tensor([1.3017e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4671 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4674 --- loss: 0.000056\n",
      "tensor([1.1704e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4676 --- loss: 0.000000\n",
      "tensor([3.9333e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4679 --- loss: 0.000000\n",
      "tensor([1.8302e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4681 --- loss: 0.000000\n",
      "tensor([0.9716], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4684 --- loss: 0.028833\n",
      "tensor([1.1183e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4687 --- loss: 0.000000\n",
      "tensor([8.4066e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4689 --- loss: 0.000000\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4692 --- loss: 0.000504\n",
      "tensor([2.5633e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4694 --- loss: 0.000000\n",
      "tensor([3.7758e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4697 --- loss: 0.000000\n",
      "tensor([8.2718e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4699 --- loss: 0.000000\n",
      "tensor([2.5824e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4702 --- loss: 0.000003\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4704 --- loss: 0.000153\n",
      "tensor([0.9966], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4707 --- loss: 0.003394\n",
      "tensor([1.2200e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4709 --- loss: 0.000000\n",
      "tensor([9.1718e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4712 --- loss: 0.000000\n",
      "tensor([1.5949e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4714 --- loss: 0.000000\n",
      "tensor([9.3836e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4717 --- loss: 0.000000\n",
      "tensor([5.2339e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4719 --- loss: 0.000000\n",
      "tensor([2.8103e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4722 --- loss: 0.000003\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4724 --- loss: 0.000183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.9216e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4727 --- loss: 0.000000\n",
      "tensor([6.6846e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4730 --- loss: 0.000001\n",
      "tensor([9.8427e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4732 --- loss: 0.000000\n",
      "tensor([0.9977], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4735 --- loss: 0.002269\n",
      "tensor([5.2998e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4737 --- loss: 0.000000\n",
      "tensor([0.9980], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4740 --- loss: 0.001954\n",
      "tensor([2.8123e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4742 --- loss: 0.000000\n",
      "tensor([5.5110e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4745 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4747 --- loss: 0.000010\n",
      "tensor([3.5867e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4750 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4752 --- loss: 0.000041\n",
      "tensor([1.3990e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4755 --- loss: 0.000000\n",
      "tensor([5.7752e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4757 --- loss: 0.000000\n",
      "tensor([1.0609e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4760 --- loss: 0.000000\n",
      "tensor([0.9973], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4762 --- loss: 0.002703\n",
      "tensor([0.9284], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4765 --- loss: 0.074317\n",
      "tensor([2.9691e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4767 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4770 --- loss: 0.000027\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4772 --- loss: 0.000246\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4775 --- loss: 0.000804\n",
      "tensor([7.4798e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4778 --- loss: 0.000001\n",
      "tensor([3.1068e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4780 --- loss: 0.000000\n",
      "tensor([0.9473], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4783 --- loss: 0.054126\n",
      "tensor([2.9574e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4785 --- loss: 0.000000\n",
      "tensor([1.3039e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4788 --- loss: 0.000001\n",
      "tensor([2.6222e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4790 --- loss: 0.000026\n",
      "tensor([0.9558], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4793 --- loss: 0.045206\n",
      "tensor([3.0033e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4795 --- loss: 0.000000\n",
      "tensor([2.9061e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4798 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4800 --- loss: 0.000026\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4803 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4805 --- loss: 0.000009\n",
      "tensor([5.6755e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4808 --- loss: 0.000000\n",
      "tensor([3.7175e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4810 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4813 --- loss: 0.000152\n",
      "tensor([8.0608e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4815 --- loss: 0.000000\n",
      "tensor([2.3012e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4818 --- loss: 0.000000\n",
      "tensor([1.8673e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4821 --- loss: 0.000000\n",
      "tensor([1.3347e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4823 --- loss: 0.000001\n",
      "tensor([8.2726e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4826 --- loss: 0.000000\n",
      "tensor([0.9944], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4828 --- loss: 0.005632\n",
      "tensor([0.9987], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4831 --- loss: 0.001262\n",
      "tensor([0.9990], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4833 --- loss: 0.000993\n",
      "tensor([7.8165e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4836 --- loss: 0.000001\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4838 --- loss: 0.000234\n",
      "tensor([1.1866e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4841 --- loss: 0.000001\n",
      "tensor([5.7712e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4843 --- loss: 0.000000\n",
      "tensor([2.0185e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4846 --- loss: 0.000000\n",
      "tensor([2.5437e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4848 --- loss: 0.000003\n",
      "tensor([4.0157e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4851 --- loss: 0.000000\n",
      "tensor([4.7065e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4853 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4856 --- loss: 0.000240\n",
      "tensor([1.4988e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4858 --- loss: 0.000000\n",
      "tensor([8.4650e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4861 --- loss: 0.000000\n",
      "tensor([4.4529e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4863 --- loss: 0.000000\n",
      "tensor([0.9818], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4866 --- loss: 0.018345\n",
      "tensor([7.7008e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4869 --- loss: 0.000000\n",
      "tensor([1.3268e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4871 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4874 --- loss: 0.000001\n",
      "tensor([5.5637e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4876 --- loss: 0.000000\n",
      "tensor([1.0453e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4879 --- loss: 0.000000\n",
      "tensor([7.7795e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4881 --- loss: 0.000000\n",
      "tensor([1.1025e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4884 --- loss: 0.000000\n",
      "tensor([3.2670e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4886 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4889 --- loss: 0.000032\n",
      "tensor([1.6353e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4891 --- loss: 0.000000\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4894 --- loss: 0.000878\n",
      "tensor([1.6983e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4896 --- loss: 0.000000\n",
      "tensor([2.9604e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4899 --- loss: 0.000030\n",
      "tensor([4.4172e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4901 --- loss: 0.000000\n",
      "tensor([1.6489e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4904 --- loss: 0.000000\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4906 --- loss: 0.001616\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4909 --- loss: 0.000050\n",
      "tensor([1.2662e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4912 --- loss: 0.000013\n",
      "tensor([1.0141e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4914 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4917 --- loss: 0.000039\n",
      "tensor([8.8188e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4919 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4922 --- loss: 0.000241\n",
      "tensor([1.1566e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4924 --- loss: 0.000000\n",
      "tensor([2.0908e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4927 --- loss: 0.000002\n",
      "tensor([1.0040e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4929 --- loss: 0.000010\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4932 --- loss: 0.000045\n",
      "tensor([1.5377e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4934 --- loss: 0.000000\n",
      "tensor([6.5575e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4937 --- loss: 0.000000\n",
      "tensor([8.1372e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4939 --- loss: 0.000000\n",
      "tensor([1.2170e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4942 --- loss: 0.000000\n",
      "tensor([8.8781e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4944 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4947 --- loss: 0.000084\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4949 --- loss: 0.000091\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4952 --- loss: 0.000104\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4954 --- loss: 0.000102\n",
      "tensor([9.5699e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4957 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4960 --- loss: 0.000333\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4962 --- loss: 0.000087\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4965 --- loss: 0.000053\n",
      "tensor([1.9250e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4967 --- loss: 0.000000\n",
      "tensor([1.2966e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4970 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4972 --- loss: 0.000082\n",
      "tensor([2.8024e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4975 --- loss: 0.000000\n",
      "tensor([3.6534e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4977 --- loss: 0.000000\n",
      "tensor([8.4951e-16], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4980 --- loss: 0.000000\n",
      "tensor([4.1955e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4982 --- loss: 0.000000\n",
      "tensor([8.0088e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4985 --- loss: 0.000000\n",
      "tensor([6.1152e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4987 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4990 --- loss: 0.000060\n",
      "tensor([5.8700e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4992 --- loss: 0.000000\n",
      "tensor([1.4958e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.4995 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.4997 --- loss: 0.000009\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5000 --- loss: 0.000152\n",
      "tensor([3.6150e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5003 --- loss: 0.000000\n",
      "tensor([8.0142e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5005 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5008 --- loss: 0.000234\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5010 --- loss: 0.000026\n",
      "tensor([1.9619e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5013 --- loss: 0.000000\n",
      "tensor([1.9967e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5015 --- loss: 0.000000\n",
      "tensor([3.2926e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5018 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5020 --- loss: 0.000190\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5023 --- loss: 0.000225\n",
      "tensor([1.7721e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5025 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5028 --- loss: 0.000298\n",
      "tensor([2.2439e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5030 --- loss: 0.000000\n",
      "tensor([0.9926], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5033 --- loss: 0.007398\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5035 --- loss: 0.000037\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5038 --- loss: 0.000190\n",
      "tensor([1.8847e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5040 --- loss: 0.000000\n",
      "tensor([2.5849e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5043 --- loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7734e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5046 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5048 --- loss: 0.000003\n",
      "tensor([1.8179e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5051 --- loss: 0.000000\n",
      "tensor([1.0113e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5053 --- loss: 0.000000\n",
      "tensor([0.9951], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5056 --- loss: 0.004922\n",
      "tensor([6.0068e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5058 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5061 --- loss: 0.000003\n",
      "tensor([1.8622e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5063 --- loss: 0.000000\n",
      "tensor([5.7479e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5066 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5068 --- loss: 0.000008\n",
      "tensor([9.4327e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5071 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5073 --- loss: 0.000005\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5076 --- loss: 0.000050\n",
      "tensor([7.3341e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5078 --- loss: 0.000000\n",
      "tensor([1.5868e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5081 --- loss: 0.000002\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5083 --- loss: 0.000129\n",
      "tensor([2.4468e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5086 --- loss: 0.000000\n",
      "tensor([6.1193e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5088 --- loss: 0.000000\n",
      "tensor([2.9296e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5091 --- loss: 0.000000\n",
      "tensor([1.4743e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5094 --- loss: 0.000000\n",
      "tensor([1.1318e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5096 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5099 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5101 --- loss: 0.000000\n",
      "tensor([9.6356e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5104 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5106 --- loss: 0.000029\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5109 --- loss: 0.000087\n",
      "tensor([1.9292e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5111 --- loss: 0.000002\n",
      "tensor([2.7337e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5114 --- loss: 0.000003\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5116 --- loss: 0.000405\n",
      "tensor([1.5729e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5119 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5121 --- loss: 0.000126\n",
      "tensor([9.9872e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5124 --- loss: 0.000000\n",
      "tensor([0.9939], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5126 --- loss: 0.006155\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5129 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5131 --- loss: 0.000029\n",
      "tensor([2.8815e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5134 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5137 --- loss: 0.000010\n",
      "tensor([7.1688e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5139 --- loss: 0.000000\n",
      "tensor([2.8662e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5142 --- loss: 0.000000\n",
      "tensor([6.7502e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5144 --- loss: 0.000000\n",
      "tensor([1.9111e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5147 --- loss: 0.000000\n",
      "tensor([5.7274e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5149 --- loss: 0.000001\n",
      "tensor([1.6133e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5152 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5154 --- loss: 0.000004\n",
      "tensor([5.8618e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5157 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5159 --- loss: 0.000099\n",
      "tensor([4.2863e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5162 --- loss: 0.000000\n",
      "tensor([9.7361e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5164 --- loss: 0.000000\n",
      "tensor([5.3688e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5167 --- loss: 0.000005\n",
      "tensor([3.1137e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5169 --- loss: 0.000000\n",
      "tensor([4.9737e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5172 --- loss: 0.000000\n",
      "tensor([4.3710e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5174 --- loss: 0.000004\n",
      "tensor([2.1753e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5177 --- loss: 0.000000\n",
      "tensor([8.1550e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5179 --- loss: 0.000000\n",
      "tensor([3.9275e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5182 --- loss: 0.000000\n",
      "tensor([1.1674e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5185 --- loss: 0.000000\n",
      "tensor([8.8218e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5187 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5190 --- loss: 0.000109\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5192 --- loss: 0.001083\n",
      "tensor([5.8281e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5195 --- loss: 0.000006\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5197 --- loss: 0.000053\n",
      "tensor([3.6135e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5200 --- loss: 0.000000\n",
      "tensor([0.9871], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5202 --- loss: 0.012980\n",
      "tensor([1.6875e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5205 --- loss: 0.000000\n",
      "tensor([1.3397e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5207 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5210 --- loss: 0.000216\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5212 --- loss: 0.000007\n",
      "tensor([9.8110e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5215 --- loss: 0.000098\n",
      "tensor([1.6953e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5217 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5220 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5222 --- loss: 0.000006\n",
      "tensor([1.3117e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5225 --- loss: 0.000000\n",
      "tensor([2.0918e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5228 --- loss: 0.000000\n",
      "tensor([2.4293e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5230 --- loss: 0.000000\n",
      "tensor([0.9959], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5233 --- loss: 0.004077\n",
      "tensor([8.0333e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5235 --- loss: 0.000000\n",
      "tensor([1.8594e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5238 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5240 --- loss: 0.000119\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5243 --- loss: 0.000011\n",
      "tensor([2.4087e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5245 --- loss: 0.000000\n",
      "tensor([1.3669e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5248 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5250 --- loss: 0.000151\n",
      "tensor([1.7624e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5253 --- loss: 0.000000\n",
      "tensor([4.3516e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5255 --- loss: 0.000000\n",
      "tensor([4.6888e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5258 --- loss: 0.000000\n",
      "tensor([2.2075e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5260 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5263 --- loss: 0.000104\n",
      "tensor([1.5268e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5265 --- loss: 0.000000\n",
      "tensor([2.6283e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5268 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5270 --- loss: 0.000002\n",
      "tensor([2.7839e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5273 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5276 --- loss: 0.000013\n",
      "tensor([4.8139e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5278 --- loss: 0.000000\n",
      "tensor([2.6131e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5281 --- loss: 0.000000\n",
      "tensor([0.9970], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5283 --- loss: 0.003022\n",
      "tensor([2.1960e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5286 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5288 --- loss: 0.000000\n",
      "tensor([2.2070e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5291 --- loss: 0.000000\n",
      "tensor([7.8786e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5293 --- loss: 0.000001\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5296 --- loss: 0.000261\n",
      "tensor([2.1258e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5298 --- loss: 0.000021\n",
      "tensor([0.9552], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5301 --- loss: 0.045814\n",
      "tensor([1.7100e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5303 --- loss: 0.000000\n",
      "tensor([4.5552e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5306 --- loss: 0.000000\n",
      "tensor([1.9525e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5308 --- loss: 0.000000\n",
      "tensor([0.9986], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5311 --- loss: 0.001356\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5313 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5316 --- loss: 0.000016\n",
      "tensor([3.0026e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5319 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5321 --- loss: 0.000004\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5324 --- loss: 0.000109\n",
      "tensor([0.9970], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5326 --- loss: 0.003043\n",
      "tensor([9.8883e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5329 --- loss: 0.000010\n",
      "tensor([5.7795e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5331 --- loss: 0.000000\n",
      "tensor([0.9940], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5334 --- loss: 0.006001\n",
      "tensor([2.0724e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5336 --- loss: 0.000000\n",
      "tensor([3.8351e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5339 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5341 --- loss: 0.000157\n",
      "tensor([4.3341e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5344 --- loss: 0.000000\n",
      "tensor([7.0892e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5346 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5349 --- loss: 0.000125\n",
      "tensor([1.4232e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5351 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5354 --- loss: 0.000048\n",
      "tensor([3.3112e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5356 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5359 --- loss: 0.000001\n",
      "tensor([0.0054], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5361 --- loss: 0.005425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1287e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5364 --- loss: 0.000000\n",
      "tensor([4.1182e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5367 --- loss: 0.000000\n",
      "tensor([6.3657e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5369 --- loss: 0.000000\n",
      "tensor([2.0481e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5372 --- loss: 0.000000\n",
      "tensor([2.8593e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5374 --- loss: 0.000000\n",
      "tensor([0.9946], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5377 --- loss: 0.005366\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5379 --- loss: 0.000002\n",
      "tensor([1.5602e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5382 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5384 --- loss: 0.000101\n",
      "tensor([2.4819e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5387 --- loss: 0.000000\n",
      "tensor([5.0007e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5389 --- loss: 0.000000\n",
      "tensor([0.9969], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5392 --- loss: 0.003078\n",
      "tensor([3.9262e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5394 --- loss: 0.000000\n",
      "tensor([1.6864e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5397 --- loss: 0.000000\n",
      "tensor([6.4550e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5399 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5402 --- loss: 0.000319\n",
      "tensor([4.3253e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5404 --- loss: 0.000000\n",
      "tensor([2.8046e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5407 --- loss: 0.000028\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5410 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5412 --- loss: 0.000001\n",
      "tensor([5.4267e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5415 --- loss: 0.000001\n",
      "tensor([3.0226e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5417 --- loss: 0.000003\n",
      "tensor([1.5142e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5420 --- loss: 0.000000\n",
      "tensor([9.3569e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5422 --- loss: 0.000000\n",
      "tensor([5.2555e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5425 --- loss: 0.000000\n",
      "tensor([2.1545e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5427 --- loss: 0.000002\n",
      "tensor([1.8194e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5430 --- loss: 0.000002\n",
      "tensor([1.4695e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5432 --- loss: 0.000000\n",
      "tensor([1.5903e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5435 --- loss: 0.000016\n",
      "tensor([6.7639e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5437 --- loss: 0.000000\n",
      "tensor([8.2990e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5440 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5442 --- loss: 0.000034\n",
      "tensor([1.4641e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5445 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5447 --- loss: 0.000029\n",
      "tensor([3.1733e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5450 --- loss: 0.000000\n",
      "tensor([3.9047e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5452 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5455 --- loss: 0.000001\n",
      "tensor([6.6286e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5458 --- loss: 0.000000\n",
      "tensor([1.2810e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5460 --- loss: 0.000000\n",
      "tensor([2.5971e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5463 --- loss: 0.000000\n",
      "tensor([1.3038e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5465 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5468 --- loss: 0.000112\n",
      "tensor([3.3241e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5470 --- loss: 0.000000\n",
      "tensor([1.9726e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5473 --- loss: 0.000000\n",
      "tensor([3.9578e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5475 --- loss: 0.000000\n",
      "tensor([3.4524e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5478 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5480 --- loss: 0.000265\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5483 --- loss: 0.000086\n",
      "tensor([1.3184e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5485 --- loss: 0.000000\n",
      "tensor([3.5223e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5488 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5490 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5493 --- loss: 0.000045\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5495 --- loss: 0.000027\n",
      "tensor([4.1181e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5498 --- loss: 0.000000\n",
      "tensor([4.1202e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5501 --- loss: 0.000041\n",
      "tensor([0.0109], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5503 --- loss: 0.010973\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5506 --- loss: 0.000001\n",
      "tensor([7.9159e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5508 --- loss: 0.000000\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5511 --- loss: 0.000640\n",
      "tensor([3.9275e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5513 --- loss: 0.000000\n",
      "tensor([1.8658e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5516 --- loss: 0.000002\n",
      "tensor([6.3580e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5518 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5521 --- loss: 0.000021\n",
      "tensor([2.2125e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5523 --- loss: 0.000002\n",
      "tensor([8.8766e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5526 --- loss: 0.000000\n",
      "tensor([1.0275e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5528 --- loss: 0.000000\n",
      "tensor([4.6738e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5531 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5533 --- loss: 0.000137\n",
      "tensor([3.0317e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5536 --- loss: 0.000000\n",
      "tensor([3.3116e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5538 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5541 --- loss: 0.000004\n",
      "tensor([4.7686e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5543 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5546 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5549 --- loss: 0.000020\n",
      "tensor([0.9945], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5551 --- loss: 0.005497\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5554 --- loss: 0.000003\n",
      "tensor([8.9158e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5556 --- loss: 0.000000\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5559 --- loss: 0.000664\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5561 --- loss: 0.000110\n",
      "tensor([1.4184e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5564 --- loss: 0.000014\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5566 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5569 --- loss: 0.000006\n",
      "tensor([1.1700e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5571 --- loss: 0.000000\n",
      "tensor([1.5862e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5574 --- loss: 0.000000\n",
      "tensor([2.6199e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5576 --- loss: 0.000000\n",
      "tensor([2.9504e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5579 --- loss: 0.000030\n",
      "tensor([1.0609e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5581 --- loss: 0.000000\n",
      "tensor([3.0732e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5584 --- loss: 0.000000\n",
      "tensor([5.3578e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5586 --- loss: 0.000054\n",
      "tensor([2.9910e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5589 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5592 --- loss: 0.000214\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5594 --- loss: 0.000002\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5597 --- loss: 0.000449\n",
      "tensor([6.9521e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5599 --- loss: 0.000007\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5602 --- loss: 0.000001\n",
      "tensor([1.0729e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5604 --- loss: 0.000011\n",
      "tensor([3.3276e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5607 --- loss: 0.000000\n",
      "tensor([9.8942e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5609 --- loss: 0.000000\n",
      "tensor([3.1066e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5612 --- loss: 0.000000\n",
      "tensor([1.4744e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5614 --- loss: 0.000000\n",
      "tensor([2.8173e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5617 --- loss: 0.000003\n",
      "tensor([5.2767e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5619 --- loss: 0.000000\n",
      "tensor([4.7521e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5622 --- loss: 0.000000\n",
      "tensor([1.7518e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5624 --- loss: 0.000000\n",
      "tensor([2.3414e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5627 --- loss: 0.000000\n",
      "tensor([1.0643e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5629 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5632 --- loss: 0.000001\n",
      "tensor([2.3925e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5634 --- loss: 0.000002\n",
      "tensor([2.5293e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5637 --- loss: 0.000000\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5640 --- loss: 0.000781\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5642 --- loss: 0.000025\n",
      "tensor([5.6917e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5645 --- loss: 0.000000\n",
      "tensor([4.7203e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5647 --- loss: 0.000000\n",
      "tensor([8.5213e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5650 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5652 --- loss: 0.000065\n",
      "tensor([7.2358e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5655 --- loss: 0.000000\n",
      "tensor([3.6277e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5657 --- loss: 0.000000\n",
      "tensor([3.5339e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5660 --- loss: 0.000000\n",
      "tensor([3.5443e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5662 --- loss: 0.000000\n",
      "tensor([7.5508e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5665 --- loss: 0.000008\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5667 --- loss: 0.000057\n",
      "tensor([5.3112e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5670 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5672 --- loss: 0.000113\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5675 --- loss: 0.000019\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5677 --- loss: 0.000023\n",
      "tensor([3.6623e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5680 --- loss: 0.000037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.1146e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5683 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5685 --- loss: 0.000004\n",
      "tensor([4.0486e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5688 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5690 --- loss: 0.000000\n",
      "tensor([5.3472e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5693 --- loss: 0.000000\n",
      "tensor([5.3114e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5695 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5698 --- loss: 0.000345\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5700 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5703 --- loss: 0.000028\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5705 --- loss: 0.000005\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5708 --- loss: 0.000064\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5710 --- loss: 0.000553\n",
      "tensor([7.2238e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5713 --- loss: 0.000000\n",
      "tensor([3.1327e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5715 --- loss: 0.000000\n",
      "tensor([4.4627e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5718 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5720 --- loss: 0.000029\n",
      "tensor([1.1277e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5723 --- loss: 0.000000\n",
      "tensor([1.2144e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5725 --- loss: 0.000000\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5728 --- loss: 0.000492\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5731 --- loss: 0.000774\n",
      "tensor([4.9620e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5733 --- loss: 0.000000\n",
      "tensor([5.8117e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5736 --- loss: 0.000000\n",
      "tensor([3.1443e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5738 --- loss: 0.000000\n",
      "tensor([4.3113e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5741 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5743 --- loss: 0.000005\n",
      "tensor([1.5555e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5746 --- loss: 0.000000\n",
      "tensor([1.5802e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5748 --- loss: 0.000000\n",
      "tensor([0.0343], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5751 --- loss: 0.034886\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5753 --- loss: 0.000061\n",
      "tensor([1.0330e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5756 --- loss: 0.000000\n",
      "tensor([7.9646e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5758 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5761 --- loss: 0.000086\n",
      "tensor([9.5385e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5763 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5766 --- loss: 0.000007\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5768 --- loss: 0.000001\n",
      "tensor([2.1316e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5771 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5774 --- loss: 0.000004\n",
      "tensor([9.2091e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5776 --- loss: 0.000000\n",
      "tensor([8.5398e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5779 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5781 --- loss: 0.000002\n",
      "tensor([8.1427e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5784 --- loss: 0.000000\n",
      "tensor([3.3860e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5786 --- loss: 0.000003\n",
      "tensor([4.2463e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5789 --- loss: 0.000000\n",
      "tensor([1.2962e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5791 --- loss: 0.000000\n",
      "tensor([1.3074e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5794 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5796 --- loss: 0.000077\n",
      "tensor([3.6660e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5799 --- loss: 0.000000\n",
      "tensor([3.9867e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5801 --- loss: 0.000040\n",
      "tensor([9.9285e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5804 --- loss: 0.000000\n",
      "tensor([3.2236e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5806 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5809 --- loss: 0.000031\n",
      "tensor([0.9642], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5811 --- loss: 0.036471\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5814 --- loss: 0.000007\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5816 --- loss: 0.000097\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5819 --- loss: 0.000338\n",
      "tensor([1.2312e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5822 --- loss: 0.000000\n",
      "tensor([1.2653e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5824 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5827 --- loss: 0.000125\n",
      "tensor([2.8719e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5829 --- loss: 0.000003\n",
      "tensor([6.9835e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5832 --- loss: 0.000001\n",
      "tensor([4.7713e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5834 --- loss: 0.000048\n",
      "tensor([5.4695e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5837 --- loss: 0.000000\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5839 --- loss: 0.000839\n",
      "tensor([3.3036e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5842 --- loss: 0.000003\n",
      "tensor([2.8884e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5844 --- loss: 0.000000\n",
      "tensor([3.3630e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5847 --- loss: 0.000000\n",
      "tensor([0.9795], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5849 --- loss: 0.020746\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5852 --- loss: 0.000014\n",
      "tensor([9.4140e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5854 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5857 --- loss: 0.000000\n",
      "tensor([8.1833e-16], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5859 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5862 --- loss: 0.000056\n",
      "tensor([1.6225e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5865 --- loss: 0.000016\n",
      "tensor([1.1324e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5867 --- loss: 0.000011\n",
      "tensor([1.1759e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5870 --- loss: 0.000000\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5872 --- loss: 0.001155\n",
      "tensor([5.0950e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5875 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5877 --- loss: 0.000189\n",
      "tensor([1.3459e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5880 --- loss: 0.000000\n",
      "tensor([3.4762e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5882 --- loss: 0.000035\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5885 --- loss: 0.000651\n",
      "tensor([5.3944e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5887 --- loss: 0.000054\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5890 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5892 --- loss: 0.000001\n",
      "tensor([3.5294e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5895 --- loss: 0.000000\n",
      "tensor([7.8704e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5897 --- loss: 0.000000\n",
      "tensor([4.3279e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5900 --- loss: 0.000000\n",
      "tensor([5.4620e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5902 --- loss: 0.000000\n",
      "tensor([0.9957], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5905 --- loss: 0.004331\n",
      "tensor([1.7790e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5907 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5910 --- loss: 0.000112\n",
      "tensor([5.6608e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5913 --- loss: 0.000000\n",
      "tensor([2.2246e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5915 --- loss: 0.000000\n",
      "tensor([4.6403e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5918 --- loss: 0.000000\n",
      "tensor([1.3292e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5920 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5923 --- loss: 0.000272\n",
      "tensor([6.1199e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5925 --- loss: 0.000000\n",
      "tensor([2.4406e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5928 --- loss: 0.000000\n",
      "tensor([3.3257e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5930 --- loss: 0.000000\n",
      "tensor([3.8787e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5933 --- loss: 0.000000\n",
      "tensor([7.9321e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5935 --- loss: 0.000000\n",
      "tensor([0.9963], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5938 --- loss: 0.003726\n",
      "tensor([1.2722e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5940 --- loss: 0.000000\n",
      "tensor([1.8000e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5943 --- loss: 0.000018\n",
      "tensor([6.7998e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5945 --- loss: 0.000000\n",
      "tensor([2.2680e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5948 --- loss: 0.000000\n",
      "tensor([1.8535e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5950 --- loss: 0.000000\n",
      "tensor([2.1681e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5953 --- loss: 0.000000\n",
      "tensor([2.7186e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5956 --- loss: 0.000027\n",
      "tensor([1.8649e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5958 --- loss: 0.000000\n",
      "tensor([1.6535e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5961 --- loss: 0.000000\n",
      "tensor([2.3259e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5963 --- loss: 0.000000\n",
      "tensor([0.9833], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5966 --- loss: 0.016887\n",
      "tensor([2.0393e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5968 --- loss: 0.000000\n",
      "tensor([2.1270e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5971 --- loss: 0.000002\n",
      "tensor([2.9525e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5973 --- loss: 0.000000\n",
      "tensor([5.1571e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5976 --- loss: 0.000000\n",
      "tensor([6.7794e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5978 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.5981 --- loss: 0.000168\n",
      "tensor([1.5495e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5983 --- loss: 0.000002\n",
      "tensor([5.4485e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5986 --- loss: 0.000000\n",
      "tensor([1.9091e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5988 --- loss: 0.000000\n",
      "tensor([1.4441e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5991 --- loss: 0.000000\n",
      "tensor([3.2578e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5993 --- loss: 0.000003\n",
      "tensor([2.0681e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5996 --- loss: 0.000000\n",
      "tensor([4.7201e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.5998 --- loss: 0.000005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.3499e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6001 --- loss: 0.000000\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6004 --- loss: 0.000884\n",
      "tensor([9.9808e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6006 --- loss: 0.000000\n",
      "tensor([7.4929e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6009 --- loss: 0.000000\n",
      "tensor([7.1466e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6011 --- loss: 0.000000\n",
      "tensor([0.9976], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6014 --- loss: 0.002371\n",
      "tensor([6.2396e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6016 --- loss: 0.000000\n",
      "tensor([1.0457e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6019 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6021 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6024 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6026 --- loss: 0.000048\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6029 --- loss: 0.000001\n",
      "tensor([5.0998e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6031 --- loss: 0.000000\n",
      "tensor([4.4945e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6034 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6036 --- loss: 0.000004\n",
      "tensor([6.2604e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6039 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6041 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6044 --- loss: 0.000006\n",
      "tensor([1.5514e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6047 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6049 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6052 --- loss: 0.000013\n",
      "tensor([2.6510e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6054 --- loss: 0.000000\n",
      "tensor([1.4366e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6057 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6059 --- loss: 0.000162\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6062 --- loss: 0.000131\n",
      "tensor([3.5026e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6064 --- loss: 0.000000\n",
      "tensor([6.3753e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6067 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6069 --- loss: 0.000009\n",
      "tensor([8.9156e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6072 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6074 --- loss: 0.000165\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6077 --- loss: 0.000034\n",
      "tensor([3.3248e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6079 --- loss: 0.000000\n",
      "tensor([3.5378e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6082 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6084 --- loss: 0.000039\n",
      "tensor([1.8329e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6087 --- loss: 0.000000\n",
      "tensor([2.7354e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6089 --- loss: 0.000000\n",
      "tensor([0.9974], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6092 --- loss: 0.002640\n",
      "tensor([4.6991e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6095 --- loss: 0.000000\n",
      "tensor([5.9888e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6097 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6100 --- loss: 0.000076\n",
      "tensor([1.2680e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6102 --- loss: 0.000000\n",
      "tensor([0.9965], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6105 --- loss: 0.003500\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6107 --- loss: 0.001114\n",
      "tensor([4.1117e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6110 --- loss: 0.000000\n",
      "tensor([1.0857e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6112 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6115 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6117 --- loss: 0.000159\n",
      "tensor([2.4754e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6120 --- loss: 0.000002\n",
      "tensor([9.5088e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6122 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6125 --- loss: 0.000007\n",
      "tensor([2.7353e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6127 --- loss: 0.000000\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6130 --- loss: 0.000749\n",
      "tensor([2.8560e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6132 --- loss: 0.000000\n",
      "tensor([9.5700e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6135 --- loss: 0.000000\n",
      "tensor([2.1413e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6138 --- loss: 0.000000\n",
      "tensor([3.2995e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6140 --- loss: 0.000000\n",
      "tensor([3.9492e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6143 --- loss: 0.000000\n",
      "tensor([2.0829e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6145 --- loss: 0.000000\n",
      "tensor([1.1554e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6148 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6150 --- loss: 0.000004\n",
      "tensor([7.5008e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6153 --- loss: 0.000000\n",
      "tensor([1.5230e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6155 --- loss: 0.000000\n",
      "tensor([4.2252e-16], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6158 --- loss: 0.000000\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6160 --- loss: 0.000583\n",
      "tensor([2.8508e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6163 --- loss: 0.000000\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6165 --- loss: 0.000607\n",
      "tensor([2.7618e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6168 --- loss: 0.000000\n",
      "tensor([8.6066e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6170 --- loss: 0.000000\n",
      "tensor([5.7230e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6173 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6175 --- loss: 0.000002\n",
      "tensor([5.6859e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6178 --- loss: 0.000000\n",
      "tensor([4.0630e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6180 --- loss: 0.000041\n",
      "tensor([1.2723e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6183 --- loss: 0.000000\n",
      "tensor([1.1950e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6186 --- loss: 0.000012\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6188 --- loss: 0.000002\n",
      "tensor([4.3751e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6191 --- loss: 0.000000\n",
      "tensor([2.3760e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6193 --- loss: 0.000000\n",
      "tensor([9.6404e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6196 --- loss: 0.000000\n",
      "tensor([3.8678e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6198 --- loss: 0.000000\n",
      "tensor([3.7587e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6201 --- loss: 0.000004\n",
      "tensor([2.5943e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6203 --- loss: 0.000000\n",
      "tensor([6.4252e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6206 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6208 --- loss: 0.000044\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6211 --- loss: 0.000000\n",
      "tensor([0.9989], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6213 --- loss: 0.001108\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6216 --- loss: 0.000645\n",
      "tensor([4.1307e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6218 --- loss: 0.000041\n",
      "tensor([3.1375e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6221 --- loss: 0.000000\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6223 --- loss: 0.000515\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6226 --- loss: 0.000084\n",
      "tensor([2.4165e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6229 --- loss: 0.000000\n",
      "tensor([1.0796e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6231 --- loss: 0.000000\n",
      "tensor([6.1909e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6234 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6236 --- loss: 0.000030\n",
      "tensor([1.7872e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6239 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6241 --- loss: 0.000070\n",
      "tensor([1.1953e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6244 --- loss: 0.000000\n",
      "tensor([8.9736e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6246 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6249 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6251 --- loss: 0.000001\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6254 --- loss: 0.000103\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6256 --- loss: 0.000015\n",
      "tensor([1.9887e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6259 --- loss: 0.000000\n",
      "tensor([7.8832e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6261 --- loss: 0.000000\n",
      "tensor([2.7810e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6264 --- loss: 0.000000\n",
      "tensor([2.1363e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6266 --- loss: 0.000002\n",
      "tensor([2.0059e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6269 --- loss: 0.000002\n",
      "tensor([7.3555e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6271 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6274 --- loss: 0.000009\n",
      "tensor([5.1095e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6277 --- loss: 0.000000\n",
      "tensor([1.8747e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6279 --- loss: 0.000000\n",
      "tensor([2.3588e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6282 --- loss: 0.000000\n",
      "tensor([5.0818e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6284 --- loss: 0.000051\n",
      "tensor([1.2926e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6287 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6289 --- loss: 0.000000\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6292 --- loss: 0.000543\n",
      "tensor([1.4586e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6294 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6297 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6299 --- loss: 0.000019\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6302 --- loss: 0.000155\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6304 --- loss: 0.000388\n",
      "tensor([8.7842e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6307 --- loss: 0.000001\n",
      "tensor([1.4579e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6309 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6312 --- loss: 0.000004\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6314 --- loss: 0.000100\n",
      "tensor([2.7889e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6317 --- loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6320 --- loss: 0.000000\n",
      "tensor([9.6812e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6322 --- loss: 0.000000\n",
      "tensor([5.0179e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6325 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6327 --- loss: 0.000056\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6330 --- loss: 0.000099\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6332 --- loss: 0.000314\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6335 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6337 --- loss: 0.000211\n",
      "tensor([6.0260e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6340 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6342 --- loss: 0.000000\n",
      "tensor([2.2019e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6345 --- loss: 0.000022\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6347 --- loss: 0.000966\n",
      "tensor([5.8696e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6350 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6352 --- loss: 0.000021\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6355 --- loss: 0.000526\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6357 --- loss: 0.000005\n",
      "tensor([1.0752e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6360 --- loss: 0.000000\n",
      "tensor([8.3953e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6362 --- loss: 0.000008\n",
      "tensor([1.1158e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6365 --- loss: 0.000001\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6368 --- loss: 0.000115\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6370 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6373 --- loss: 0.000000\n",
      "tensor([1.1275e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6375 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6378 --- loss: 0.000020\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6380 --- loss: 0.000405\n",
      "tensor([2.6849e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6383 --- loss: 0.000000\n",
      "tensor([9.7282e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6385 --- loss: 0.000001\n",
      "tensor([1.2579e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6388 --- loss: 0.000000\n",
      "tensor([1.5854e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6390 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6393 --- loss: 0.000282\n",
      "tensor([5.6873e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6395 --- loss: 0.000000\n",
      "tensor([1.1265e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6398 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6400 --- loss: 0.000314\n",
      "tensor([3.3092e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6403 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6405 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6408 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6411 --- loss: 0.000041\n",
      "tensor([1.3099e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6413 --- loss: 0.000000\n",
      "tensor([2.7450e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6416 --- loss: 0.000000\n",
      "tensor([1.5351e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6418 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6421 --- loss: 0.000008\n",
      "tensor([2.2401e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6423 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6426 --- loss: 0.000002\n",
      "tensor([0.9965], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6428 --- loss: 0.003530\n",
      "tensor([1.6211e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6431 --- loss: 0.000000\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6433 --- loss: 0.000692\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6436 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6438 --- loss: 0.000022\n",
      "tensor([4.0281e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6441 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6443 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6446 --- loss: 0.000014\n",
      "tensor([2.6794e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6448 --- loss: 0.000003\n",
      "tensor([6.3970e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6451 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6453 --- loss: 0.000000\n",
      "tensor([1.0178e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6456 --- loss: 0.000001\n",
      "tensor([9.3586e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6459 --- loss: 0.000000\n",
      "tensor([8.3826e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6461 --- loss: 0.000000\n",
      "tensor([2.8084e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6464 --- loss: 0.000000\n",
      "tensor([2.7158e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6466 --- loss: 0.000000\n",
      "tensor([4.7924e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6469 --- loss: 0.000000\n",
      "tensor([1.3694e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6471 --- loss: 0.000000\n",
      "tensor([3.9850e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6474 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6476 --- loss: 0.000127\n",
      "tensor([9.0044e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6479 --- loss: 0.000009\n",
      "tensor([7.1543e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6481 --- loss: 0.000000\n",
      "tensor([7.0376e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6484 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6486 --- loss: 0.000082\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6489 --- loss: 0.000253\n",
      "tensor([1.6785e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6491 --- loss: 0.000000\n",
      "tensor([1.7580e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6494 --- loss: 0.000000\n",
      "tensor([1.4844e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6496 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6499 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6502 --- loss: 0.000006\n",
      "tensor([4.0072e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6504 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6507 --- loss: 0.000043\n",
      "tensor([4.1736e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6509 --- loss: 0.000000\n",
      "tensor([0.9922], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6512 --- loss: 0.007844\n",
      "tensor([4.2560e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6514 --- loss: 0.000000\n",
      "tensor([6.0477e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6517 --- loss: 0.000000\n",
      "tensor([0.9991], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6519 --- loss: 0.000921\n",
      "tensor([4.4518e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6522 --- loss: 0.000004\n",
      "tensor([0.0006], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6524 --- loss: 0.000615\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6527 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6529 --- loss: 0.000000\n",
      "tensor([1.7132e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6532 --- loss: 0.000002\n",
      "tensor([4.6700e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6534 --- loss: 0.000000\n",
      "tensor([2.8050e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6537 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6539 --- loss: 0.000003\n",
      "tensor([7.2351e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6542 --- loss: 0.000000\n",
      "tensor([2.4322e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6544 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6547 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6550 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6552 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6555 --- loss: 0.000020\n",
      "tensor([1.0897e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6557 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6560 --- loss: 0.000002\n",
      "tensor([8.9891e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6562 --- loss: 0.000000\n",
      "tensor([9.0802e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6565 --- loss: 0.000009\n",
      "tensor([4.6559e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6567 --- loss: 0.000000\n",
      "tensor([5.1843e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6570 --- loss: 0.000001\n",
      "tensor([7.8979e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6572 --- loss: 0.000008\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6575 --- loss: 0.000000\n",
      "tensor([9.3525e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6577 --- loss: 0.000000\n",
      "tensor([3.2218e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6580 --- loss: 0.000000\n",
      "tensor([9.9426e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6582 --- loss: 0.000000\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6585 --- loss: 0.000786\n",
      "tensor([2.3044e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6587 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6590 --- loss: 0.000164\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6593 --- loss: 0.000006\n",
      "tensor([2.2536e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6595 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6598 --- loss: 0.000005\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6600 --- loss: 0.000160\n",
      "tensor([1.9494e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6603 --- loss: 0.000000\n",
      "tensor([2.9388e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6605 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6608 --- loss: 0.000003\n",
      "tensor([8.5495e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6610 --- loss: 0.000000\n",
      "tensor([4.2804e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6613 --- loss: 0.000000\n",
      "tensor([8.6018e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6615 --- loss: 0.000009\n",
      "tensor([2.3136e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6618 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6620 --- loss: 0.000001\n",
      "tensor([5.4662e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6623 --- loss: 0.000000\n",
      "tensor([2.2502e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6625 --- loss: 0.000002\n",
      "tensor([4.8332e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6628 --- loss: 0.000000\n",
      "tensor([3.4873e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6630 --- loss: 0.000000\n",
      "tensor([3.6749e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6633 --- loss: 0.000000\n",
      "tensor([2.8715e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6635 --- loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6638 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6641 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6643 --- loss: 0.000000\n",
      "tensor([1.7145e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6646 --- loss: 0.000017\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6648 --- loss: 0.000000\n",
      "tensor([1.8476e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6651 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6653 --- loss: 0.000002\n",
      "tensor([3.5932e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6656 --- loss: 0.000036\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6658 --- loss: 0.000011\n",
      "tensor([9.7877e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6661 --- loss: 0.000010\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6663 --- loss: 0.000007\n",
      "tensor([2.9724e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6666 --- loss: 0.000000\n",
      "tensor([5.6518e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6668 --- loss: 0.000006\n",
      "tensor([1.2719e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6671 --- loss: 0.000000\n",
      "tensor([1.4569e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6673 --- loss: 0.000000\n",
      "tensor([2.0423e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6676 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6678 --- loss: 0.000065\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6681 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6684 --- loss: 0.000116\n",
      "tensor([1.5610e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6686 --- loss: 0.000002\n",
      "tensor([2.2303e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6689 --- loss: 0.000000\n",
      "tensor([1.1619e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6691 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6694 --- loss: 0.000165\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6696 --- loss: 0.000010\n",
      "tensor([1.7319e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6699 --- loss: 0.000017\n",
      "tensor([1.3460e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6701 --- loss: 0.000000\n",
      "tensor([1.1173e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6704 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6706 --- loss: 0.000007\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6709 --- loss: 0.000073\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6711 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6714 --- loss: 0.000043\n",
      "tensor([7.1018e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6716 --- loss: 0.000000\n",
      "tensor([1.0562e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6719 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6721 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6724 --- loss: 0.000017\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6726 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6729 --- loss: 0.000003\n",
      "tensor([3.5272e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6732 --- loss: 0.000000\n",
      "tensor([4.3549e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6734 --- loss: 0.000000\n",
      "tensor([3.1713e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6737 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6739 --- loss: 0.000113\n",
      "tensor([1.9552e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6742 --- loss: 0.000000\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6744 --- loss: 0.000418\n",
      "tensor([4.5597e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6747 --- loss: 0.000000\n",
      "tensor([7.5899e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6749 --- loss: 0.000000\n",
      "tensor([7.5045e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6752 --- loss: 0.000000\n",
      "tensor([4.2972e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6754 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6757 --- loss: 0.000082\n",
      "tensor([1.6270e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6759 --- loss: 0.000016\n",
      "tensor([4.9768e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6762 --- loss: 0.000005\n",
      "tensor([1.6273e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6764 --- loss: 0.000000\n",
      "tensor([4.4706e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6767 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6769 --- loss: 0.000163\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6772 --- loss: 0.000036\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6775 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6777 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6780 --- loss: 0.000081\n",
      "tensor([1.2085e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6782 --- loss: 0.000000\n",
      "tensor([2.7619e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6785 --- loss: 0.000000\n",
      "tensor([6.1821e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6787 --- loss: 0.000000\n",
      "tensor([2.5421e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6790 --- loss: 0.000003\n",
      "tensor([4.0113e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6792 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6795 --- loss: 0.000000\n",
      "tensor([0.9988], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6797 --- loss: 0.001200\n",
      "tensor([6.1094e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6800 --- loss: 0.000000\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6802 --- loss: 0.000260\n",
      "tensor([1.3433e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6805 --- loss: 0.000000\n",
      "tensor([1.4150e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6807 --- loss: 0.000000\n",
      "tensor([6.0662e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6810 --- loss: 0.000000\n",
      "tensor([3.2235e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6812 --- loss: 0.000003\n",
      "tensor([3.1154e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6815 --- loss: 0.000000\n",
      "tensor([5.9548e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6817 --- loss: 0.000000\n",
      "tensor([8.7025e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6820 --- loss: 0.000000\n",
      "tensor([0.9981], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6823 --- loss: 0.001922\n",
      "tensor([8.5119e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6825 --- loss: 0.000000\n",
      "tensor([1.8323e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6828 --- loss: 0.000000\n",
      "tensor([1.9740e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6830 --- loss: 0.000002\n",
      "tensor([6.5670e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6833 --- loss: 0.000000\n",
      "tensor([3.7342e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6835 --- loss: 0.000000\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6838 --- loss: 0.000473\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6840 --- loss: 0.000085\n",
      "tensor([1.4353e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6843 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6845 --- loss: 0.000048\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6848 --- loss: 0.000020\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6850 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6853 --- loss: 0.000030\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6855 --- loss: 0.000045\n",
      "tensor([2.4534e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6858 --- loss: 0.000000\n",
      "tensor([6.3531e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6860 --- loss: 0.000064\n",
      "tensor([1.7057e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6863 --- loss: 0.000000\n",
      "tensor([2.7605e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6866 --- loss: 0.000000\n",
      "tensor([6.3741e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6868 --- loss: 0.000000\n",
      "tensor([1.0887e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6871 --- loss: 0.000000\n",
      "tensor([9.2734e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6873 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6876 --- loss: 0.000012\n",
      "tensor([2.2266e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6878 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6881 --- loss: 0.000009\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6883 --- loss: 0.000019\n",
      "tensor([3.9699e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6886 --- loss: 0.000000\n",
      "tensor([8.7043e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6888 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6891 --- loss: 0.000015\n",
      "tensor([2.6413e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6893 --- loss: 0.000000\n",
      "tensor([4.0440e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6896 --- loss: 0.000000\n",
      "tensor([8.6452e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6898 --- loss: 0.000000\n",
      "tensor([3.0203e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6901 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6903 --- loss: 0.000017\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6906 --- loss: 0.000031\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6908 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6911 --- loss: 0.000019\n",
      "tensor([5.3552e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6914 --- loss: 0.000005\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6916 --- loss: 0.000059\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6919 --- loss: 0.000001\n",
      "tensor([2.7291e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6921 --- loss: 0.000000\n",
      "tensor([1.8955e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6924 --- loss: 0.000000\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6926 --- loss: 0.000371\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6929 --- loss: 0.000004\n",
      "tensor([1.0245e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6931 --- loss: 0.000001\n",
      "tensor([1.7695e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6934 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6936 --- loss: 0.000015\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6939 --- loss: 0.000110\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6941 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6944 --- loss: 0.000021\n",
      "tensor([5.5437e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6946 --- loss: 0.000001\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6949 --- loss: 0.000840\n",
      "tensor([2.6143e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6951 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6954 --- loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.3434e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6957 --- loss: 0.000000\n",
      "tensor([1.3794e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6959 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6962 --- loss: 0.000000\n",
      "tensor([3.9730e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6964 --- loss: 0.000000\n",
      "tensor([1.3362e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6967 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6969 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6972 --- loss: 0.000017\n",
      "tensor([1.9348e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6974 --- loss: 0.000000\n",
      "tensor([1.5553e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6977 --- loss: 0.000016\n",
      "tensor([3.1586e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6979 --- loss: 0.000000\n",
      "tensor([8.0998e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6982 --- loss: 0.000000\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6984 --- loss: 0.000403\n",
      "tensor([9.7098e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6987 --- loss: 0.000000\n",
      "tensor([2.6444e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6989 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6992 --- loss: 0.000001\n",
      "tensor([1.0269e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6994 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.6997 --- loss: 0.000000\n",
      "tensor([1.0267e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.6999 --- loss: 0.000000\n",
      "tensor([9.4494e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7002 --- loss: 0.000000\n",
      "tensor([1.0122e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7005 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7007 --- loss: 0.000095\n",
      "tensor([6.4096e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7010 --- loss: 0.000000\n",
      "tensor([5.2505e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7012 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7015 --- loss: 0.000000\n",
      "tensor([7.6800e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7017 --- loss: 0.000000\n",
      "tensor([1.0336e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7020 --- loss: 0.000000\n",
      "tensor([8.2380e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7022 --- loss: 0.000000\n",
      "tensor([9.6551e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7025 --- loss: 0.000001\n",
      "tensor([4.6047e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7027 --- loss: 0.000000\n",
      "tensor([4.2107e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7030 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7032 --- loss: 0.000000\n",
      "tensor([2.8833e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7035 --- loss: 0.000000\n",
      "tensor([4.7134e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7037 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7040 --- loss: 0.000220\n",
      "tensor([2.9655e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7042 --- loss: 0.000000\n",
      "tensor([2.9705e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7045 --- loss: 0.000003\n",
      "tensor([1.0630e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7048 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7050 --- loss: 0.000000\n",
      "tensor([2.3767e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7053 --- loss: 0.000000\n",
      "tensor([1.3151e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7055 --- loss: 0.000000\n",
      "tensor([2.9814e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7058 --- loss: 0.000000\n",
      "tensor([3.2533e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7060 --- loss: 0.000000\n",
      "tensor([4.4611e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7063 --- loss: 0.000004\n",
      "tensor([1.0079e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7065 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7068 --- loss: 0.000009\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7070 --- loss: 0.000001\n",
      "tensor([4.8958e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7073 --- loss: 0.000000\n",
      "tensor([3.2309e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7075 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7078 --- loss: 0.000014\n",
      "tensor([1.2197e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7080 --- loss: 0.000000\n",
      "tensor([5.4088e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7083 --- loss: 0.000000\n",
      "tensor([9.4801e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7085 --- loss: 0.000095\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7088 --- loss: 0.000234\n",
      "tensor([2.5554e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7090 --- loss: 0.000000\n",
      "tensor([9.9411e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7093 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7096 --- loss: 0.000001\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7098 --- loss: 0.000425\n",
      "tensor([4.5103e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7101 --- loss: 0.000000\n",
      "tensor([9.9872e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7103 --- loss: 0.000000\n",
      "tensor([4.0932e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7106 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7108 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7111 --- loss: 0.000077\n",
      "tensor([1.6859e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7113 --- loss: 0.000000\n",
      "tensor([1.3428e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7116 --- loss: 0.000000\n",
      "tensor([1.5967e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7118 --- loss: 0.000002\n",
      "tensor([2.1467e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7121 --- loss: 0.000000\n",
      "tensor([1.5578e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7123 --- loss: 0.000000\n",
      "tensor([1.9551e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7126 --- loss: 0.000002\n",
      "tensor([7.1921e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7128 --- loss: 0.000001\n",
      "tensor([3.7868e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7131 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7133 --- loss: 0.000003\n",
      "tensor([0.0036], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7136 --- loss: 0.003579\n",
      "tensor([7.9536e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7139 --- loss: 0.000001\n",
      "tensor([2.3487e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7141 --- loss: 0.000023\n",
      "tensor([4.9134e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7144 --- loss: 0.000005\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7146 --- loss: 0.000100\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7149 --- loss: 0.000002\n",
      "tensor([2.4243e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7151 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7154 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7156 --- loss: 0.000008\n",
      "tensor([4.6532e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7159 --- loss: 0.000000\n",
      "tensor([2.3409e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7161 --- loss: 0.000002\n",
      "tensor([1.8458e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7164 --- loss: 0.000000\n",
      "tensor([7.3082e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7166 --- loss: 0.000007\n",
      "tensor([1.1145e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7169 --- loss: 0.000000\n",
      "tensor([4.3015e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7171 --- loss: 0.000000\n",
      "tensor([3.0567e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7174 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7176 --- loss: 0.000000\n",
      "tensor([5.7764e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7179 --- loss: 0.000000\n",
      "tensor([5.1054e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7181 --- loss: 0.000000\n",
      "tensor([1.3928e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7184 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7187 --- loss: 0.000214\n",
      "tensor([7.6885e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7189 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7192 --- loss: 0.000012\n",
      "tensor([2.7321e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7194 --- loss: 0.000000\n",
      "tensor([3.6643e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7197 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7199 --- loss: 0.000133\n",
      "tensor([1.3129e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7202 --- loss: 0.000013\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7204 --- loss: 0.000001\n",
      "tensor([1.2464e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7207 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7209 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7212 --- loss: 0.000093\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7214 --- loss: 0.000309\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7217 --- loss: 0.000003\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7219 --- loss: 0.000118\n",
      "tensor([3.5424e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7222 --- loss: 0.000000\n",
      "tensor([1.3928e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7224 --- loss: 0.000000\n",
      "tensor([8.7722e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7227 --- loss: 0.000000\n",
      "tensor([4.4380e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7230 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7232 --- loss: 0.000177\n",
      "tensor([8.1911e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7235 --- loss: 0.000001\n",
      "tensor([8.7785e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7237 --- loss: 0.000000\n",
      "tensor([6.0100e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7240 --- loss: 0.000060\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7242 --- loss: 0.000001\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7245 --- loss: 0.000138\n",
      "tensor([1.4382e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7247 --- loss: 0.000000\n",
      "tensor([4.0457e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7250 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7252 --- loss: 0.000001\n",
      "tensor([1.4186e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7255 --- loss: 0.000000\n",
      "tensor([3.3138e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7257 --- loss: 0.000000\n",
      "tensor([7.9338e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7260 --- loss: 0.000000\n",
      "tensor([8.0581e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7262 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7265 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7267 --- loss: 0.000001\n",
      "tensor([6.9991e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7270 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7272 --- loss: 0.000191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.6093e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7275 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7278 --- loss: 0.000001\n",
      "tensor([1.7141e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7280 --- loss: 0.000000\n",
      "tensor([4.6218e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7283 --- loss: 0.000000\n",
      "tensor([8.2117e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7285 --- loss: 0.000008\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7288 --- loss: 0.000001\n",
      "tensor([1.3725e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7290 --- loss: 0.000000\n",
      "tensor([8.2013e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7293 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7295 --- loss: 0.000000\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7298 --- loss: 0.000582\n",
      "tensor([1.7734e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7300 --- loss: 0.000002\n",
      "tensor([1.8152e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7303 --- loss: 0.000000\n",
      "tensor([1.6877e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7305 --- loss: 0.000000\n",
      "tensor([3.2359e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7308 --- loss: 0.000000\n",
      "tensor([0.9963], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7310 --- loss: 0.003672\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7313 --- loss: 0.000048\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7315 --- loss: 0.000001\n",
      "tensor([5.4989e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7318 --- loss: 0.000005\n",
      "tensor([1.9011e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7321 --- loss: 0.000019\n",
      "tensor([3.7066e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7323 --- loss: 0.000000\n",
      "tensor([1.0916e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7326 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7328 --- loss: 0.000005\n",
      "tensor([2.1566e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7331 --- loss: 0.000000\n",
      "tensor([4.0389e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7333 --- loss: 0.000000\n",
      "tensor([6.9437e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7336 --- loss: 0.000000\n",
      "tensor([1.8707e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7338 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7341 --- loss: 0.000009\n",
      "tensor([1.1503e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7343 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7346 --- loss: 0.000006\n",
      "tensor([1.2125e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7348 --- loss: 0.000000\n",
      "tensor([3.8255e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7351 --- loss: 0.000000\n",
      "tensor([4.5558e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7353 --- loss: 0.000046\n",
      "tensor([2.7634e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7356 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7358 --- loss: 0.000119\n",
      "tensor([0.9919], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7361 --- loss: 0.008084\n",
      "tensor([6.2130e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7363 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7366 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7369 --- loss: 0.000014\n",
      "tensor([5.6125e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7371 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7374 --- loss: 0.000062\n",
      "tensor([1.1703e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7376 --- loss: 0.000000\n",
      "tensor([3.1445e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7379 --- loss: 0.000000\n",
      "tensor([3.0356e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7381 --- loss: 0.000000\n",
      "tensor([5.5234e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7384 --- loss: 0.000001\n",
      "tensor([1.5428e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7386 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7389 --- loss: 0.000013\n",
      "tensor([7.9337e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7391 --- loss: 0.000079\n",
      "tensor([9.0870e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7394 --- loss: 0.000000\n",
      "tensor([2.0301e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7396 --- loss: 0.000000\n",
      "tensor([1.5533e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7399 --- loss: 0.000016\n",
      "tensor([3.8861e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7401 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7404 --- loss: 0.000000\n",
      "tensor([7.3191e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7406 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7409 --- loss: 0.000009\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7412 --- loss: 0.000003\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7414 --- loss: 0.000405\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7417 --- loss: 0.000016\n",
      "tensor([0.9954], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7419 --- loss: 0.004585\n",
      "tensor([1.4454e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7422 --- loss: 0.000000\n",
      "tensor([5.8718e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7424 --- loss: 0.000006\n",
      "tensor([1.3235e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7427 --- loss: 0.000001\n",
      "tensor([1.0584e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7429 --- loss: 0.000000\n",
      "tensor([3.6316e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7432 --- loss: 0.000000\n",
      "tensor([2.0657e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7434 --- loss: 0.000021\n",
      "tensor([1.2346e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7437 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7439 --- loss: 0.000001\n",
      "tensor([1.3878e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7442 --- loss: 0.000000\n",
      "tensor([4.8711e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7444 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7447 --- loss: 0.000010\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7449 --- loss: 0.000004\n",
      "tensor([3.2581e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7452 --- loss: 0.000000\n",
      "tensor([8.8176e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7454 --- loss: 0.000000\n",
      "tensor([3.4545e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7457 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7460 --- loss: 0.000148\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7462 --- loss: 0.000152\n",
      "tensor([3.2203e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7465 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7467 --- loss: 0.000259\n",
      "tensor([3.6403e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7470 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7472 --- loss: 0.000000\n",
      "tensor([5.5961e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7475 --- loss: 0.000000\n",
      "tensor([1.1520e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7477 --- loss: 0.000000\n",
      "tensor([2.1152e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7480 --- loss: 0.000000\n",
      "tensor([1.6063e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7482 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7485 --- loss: 0.000001\n",
      "tensor([2.9188e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7487 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7490 --- loss: 0.000006\n",
      "tensor([1.3517e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7492 --- loss: 0.000000\n",
      "tensor([1.3207e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7495 --- loss: 0.000000\n",
      "tensor([2.5815e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7497 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7500 --- loss: 0.000026\n",
      "tensor([1.0916e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7503 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7505 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7508 --- loss: 0.000005\n",
      "tensor([2.2674e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7510 --- loss: 0.000000\n",
      "tensor([4.7968e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7513 --- loss: 0.000000\n",
      "tensor([1.9692e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7515 --- loss: 0.000000\n",
      "tensor([8.3077e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7518 --- loss: 0.000000\n",
      "tensor([5.8331e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7520 --- loss: 0.000000\n",
      "tensor([2.5872e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7523 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7525 --- loss: 0.000000\n",
      "tensor([2.6658e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7528 --- loss: 0.000003\n",
      "tensor([2.8538e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7530 --- loss: 0.000000\n",
      "tensor([2.7362e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7533 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7535 --- loss: 0.000021\n",
      "tensor([0.0106], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7538 --- loss: 0.010690\n",
      "tensor([1.1444e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7540 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7543 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7546 --- loss: 0.000017\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7548 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7551 --- loss: 0.000100\n",
      "tensor([6.4922e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7553 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7556 --- loss: 0.000013\n",
      "tensor([9.5926e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7558 --- loss: 0.000000\n",
      "tensor([2.9006e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7561 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7563 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7566 --- loss: 0.000003\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7568 --- loss: 0.000263\n",
      "tensor([3.9774e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7571 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7573 --- loss: 0.000004\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7576 --- loss: 0.000154\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7578 --- loss: 0.000346\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7581 --- loss: 0.000253\n",
      "tensor([1.1736e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7583 --- loss: 0.000012\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7586 --- loss: 0.000182\n",
      "tensor([8.8223e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7588 --- loss: 0.000000\n",
      "tensor([7.4687e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7591 --- loss: 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7594 --- loss: 0.000008\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7596 --- loss: 0.000072\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7599 --- loss: 0.000950\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7601 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7604 --- loss: 0.000210\n",
      "tensor([6.5058e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7606 --- loss: 0.000000\n",
      "tensor([1.8535e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7609 --- loss: 0.000000\n",
      "tensor([5.1871e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7611 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7614 --- loss: 0.000092\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7616 --- loss: 0.000027\n",
      "tensor([3.1763e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7619 --- loss: 0.000000\n",
      "tensor([4.7039e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7621 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7624 --- loss: 0.000099\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7626 --- loss: 0.000019\n",
      "tensor([8.8891e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7629 --- loss: 0.000000\n",
      "tensor([4.4906e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7631 --- loss: 0.000004\n",
      "tensor([2.0317e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7634 --- loss: 0.000000\n",
      "tensor([2.6866e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7637 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7639 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7642 --- loss: 0.000007\n",
      "tensor([9.0043e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7644 --- loss: 0.000090\n",
      "tensor([3.0874e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7647 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7649 --- loss: 0.000002\n",
      "tensor([6.0957e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7652 --- loss: 0.000000\n",
      "tensor([4.7244e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7654 --- loss: 0.000000\n",
      "tensor([1.5490e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7657 --- loss: 0.000000\n",
      "tensor([0.9975], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7659 --- loss: 0.002541\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7662 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7664 --- loss: 0.000002\n",
      "tensor([1.2719e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7667 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7669 --- loss: 0.000019\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7672 --- loss: 0.000000\n",
      "tensor([3.0416e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7674 --- loss: 0.000000\n",
      "tensor([9.5603e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7677 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7679 --- loss: 0.000096\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7682 --- loss: 0.000070\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7685 --- loss: 0.000152\n",
      "tensor([7.5637e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7687 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7690 --- loss: 0.000000\n",
      "tensor([4.8045e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7692 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7695 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7697 --- loss: 0.000196\n",
      "tensor([1.1677e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7700 --- loss: 0.000000\n",
      "tensor([4.0138e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7702 --- loss: 0.000000\n",
      "tensor([7.5080e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7705 --- loss: 0.000075\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7707 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7710 --- loss: 0.000016\n",
      "tensor([3.3399e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7712 --- loss: 0.000000\n",
      "tensor([1.1838e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7715 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7717 --- loss: 0.000328\n",
      "tensor([8.5605e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7720 --- loss: 0.000000\n",
      "tensor([2.1962e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7722 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7725 --- loss: 0.000047\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7728 --- loss: 0.000088\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7730 --- loss: 0.000003\n",
      "tensor([2.3085e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7733 --- loss: 0.000000\n",
      "tensor([3.2841e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7735 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7738 --- loss: 0.000000\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7740 --- loss: 0.000383\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7743 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7745 --- loss: 0.000009\n",
      "tensor([5.5488e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7748 --- loss: 0.000000\n",
      "tensor([1.9700e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7750 --- loss: 0.000000\n",
      "tensor([4.2186e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7753 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7755 --- loss: 0.000176\n",
      "tensor([1.0724e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7758 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7760 --- loss: 0.000003\n",
      "tensor([2.5626e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7763 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7765 --- loss: 0.000002\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7768 --- loss: 0.000169\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7770 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7773 --- loss: 0.000013\n",
      "tensor([8.4823e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7776 --- loss: 0.000000\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7778 --- loss: 0.000542\n",
      "tensor([0.0007], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7781 --- loss: 0.000735\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7783 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7786 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7788 --- loss: 0.000004\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7791 --- loss: 0.000109\n",
      "tensor([7.7826e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7793 --- loss: 0.000008\n",
      "tensor([8.9580e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7796 --- loss: 0.000000\n",
      "tensor([2.2089e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7798 --- loss: 0.000000\n",
      "tensor([3.2670e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7801 --- loss: 0.000000\n",
      "tensor([3.4127e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7803 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7806 --- loss: 0.000014\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7808 --- loss: 0.000009\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7811 --- loss: 0.000036\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7813 --- loss: 0.000002\n",
      "tensor([4.9208e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7816 --- loss: 0.000000\n",
      "tensor([2.0497e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7819 --- loss: 0.000000\n",
      "tensor([1.3881e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7821 --- loss: 0.000000\n",
      "tensor([6.0031e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7824 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7826 --- loss: 0.000025\n",
      "tensor([7.8516e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7829 --- loss: 0.000000\n",
      "tensor([2.2274e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7831 --- loss: 0.000000\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7834 --- loss: 0.001627\n",
      "tensor([3.3920e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7836 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7839 --- loss: 0.000225\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7841 --- loss: 0.000006\n",
      "tensor([3.5629e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7844 --- loss: 0.000000\n",
      "tensor([3.5677e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7846 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7849 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7851 --- loss: 0.000000\n",
      "tensor([6.5259e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7854 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7856 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7859 --- loss: 0.000002\n",
      "tensor([1.0637e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7861 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7864 --- loss: 0.000064\n",
      "tensor([2.6994e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7867 --- loss: 0.000000\n",
      "tensor([0.0027], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7869 --- loss: 0.002722\n",
      "tensor([7.5829e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7872 --- loss: 0.000000\n",
      "tensor([3.9771e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7874 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7877 --- loss: 0.000000\n",
      "tensor([1.7354e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7879 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7882 --- loss: 0.000010\n",
      "tensor([9.2861e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7884 --- loss: 0.000001\n",
      "tensor([4.6220e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7887 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7889 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7892 --- loss: 0.000005\n",
      "tensor([7.8563e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7894 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7897 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7899 --- loss: 0.000000\n",
      "tensor([3.6572e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7902 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7904 --- loss: 0.000001\n",
      "tensor([1.2732e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7907 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7910 --- loss: 0.000021\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7912 --- loss: 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7915 --- loss: 0.000003\n",
      "tensor([1.1968e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7917 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7920 --- loss: 0.000105\n",
      "tensor([2.8863e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7922 --- loss: 0.000000\n",
      "tensor([1.7893e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7925 --- loss: 0.000018\n",
      "tensor([1.3555e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7927 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7930 --- loss: 0.000237\n",
      "tensor([2.1853e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7932 --- loss: 0.000002\n",
      "tensor([3.0109e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7935 --- loss: 0.000000\n",
      "tensor([0.0012], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7937 --- loss: 0.001249\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7940 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7942 --- loss: 0.000022\n",
      "tensor([6.2653e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7945 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7947 --- loss: 0.000001\n",
      "tensor([1.4294e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7950 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7952 --- loss: 0.000313\n",
      "tensor([7.9715e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7955 --- loss: 0.000001\n",
      "tensor([1.3062e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7958 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7960 --- loss: 0.000319\n",
      "tensor([3.1599e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7963 --- loss: 0.000032\n",
      "tensor([4.7155e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7965 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7968 --- loss: 0.000054\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7970 --- loss: 0.000002\n",
      "tensor([1.0504e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7973 --- loss: 0.000000\n",
      "tensor([5.8306e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7975 --- loss: 0.000006\n",
      "tensor([0.9879], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7978 --- loss: 0.012207\n",
      "tensor([8.0692e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7980 --- loss: 0.000008\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7983 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.7985 --- loss: 0.000000\n",
      "tensor([8.1469e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7988 --- loss: 0.000000\n",
      "tensor([0.0073], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7990 --- loss: 0.007304\n",
      "tensor([4.5955e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7993 --- loss: 0.000000\n",
      "tensor([6.6054e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7995 --- loss: 0.000001\n",
      "tensor([1.6831e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.7998 --- loss: 0.000017\n",
      "tensor([1.0411e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8001 --- loss: 0.000010\n",
      "tensor([2.8825e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8003 --- loss: 0.000000\n",
      "tensor([7.6574e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8006 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8008 --- loss: 0.000004\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8011 --- loss: 0.000111\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8013 --- loss: 0.000000\n",
      "tensor([5.7834e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8016 --- loss: 0.000000\n",
      "tensor([1.0801e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8018 --- loss: 0.000000\n",
      "tensor([1.8360e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8021 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8023 --- loss: 0.000118\n",
      "tensor([0.0005], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8026 --- loss: 0.000482\n",
      "tensor([2.6264e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8028 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8031 --- loss: 0.000004\n",
      "tensor([5.8567e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8033 --- loss: 0.000059\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8036 --- loss: 0.000059\n",
      "tensor([4.6726e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8038 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8041 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8043 --- loss: 0.000008\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8046 --- loss: 0.000723\n",
      "tensor([1.8747e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8049 --- loss: 0.000002\n",
      "tensor([4.9485e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8051 --- loss: 0.000005\n",
      "tensor([1.5150e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8054 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8056 --- loss: 0.000005\n",
      "tensor([5.6627e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8059 --- loss: 0.000057\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8061 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8064 --- loss: 0.000008\n",
      "tensor([1.1207e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8066 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8069 --- loss: 0.000044\n",
      "tensor([2.4786e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8071 --- loss: 0.000000\n",
      "tensor([4.2943e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8074 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8076 --- loss: 0.000054\n",
      "tensor([1.5555e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8079 --- loss: 0.000016\n",
      "tensor([1.1647e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8081 --- loss: 0.000000\n",
      "tensor([1.8129e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8084 --- loss: 0.000000\n",
      "tensor([1.0090e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8086 --- loss: 0.000000\n",
      "tensor([3.0650e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8089 --- loss: 0.000000\n",
      "tensor([1.0916e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8092 --- loss: 0.000000\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8094 --- loss: 0.000686\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8097 --- loss: 0.000001\n",
      "tensor([4.0047e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8099 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8102 --- loss: 0.000113\n",
      "tensor([2.8639e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8104 --- loss: 0.000029\n",
      "tensor([3.2689e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8107 --- loss: 0.000033\n",
      "tensor([4.6765e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8109 --- loss: 0.000000\n",
      "tensor([1.6048e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8112 --- loss: 0.000000\n",
      "tensor([4.1735e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8114 --- loss: 0.000000\n",
      "tensor([0.9985], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8117 --- loss: 0.001488\n",
      "tensor([5.1412e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8119 --- loss: 0.000000\n",
      "tensor([5.7194e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8122 --- loss: 0.000000\n",
      "tensor([7.2305e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8124 --- loss: 0.000001\n",
      "tensor([7.4955e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8127 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8129 --- loss: 0.000165\n",
      "tensor([2.5428e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8132 --- loss: 0.000000\n",
      "tensor([4.1781e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8134 --- loss: 0.000000\n",
      "tensor([4.0307e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8137 --- loss: 0.000000\n",
      "tensor([6.0951e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8140 --- loss: 0.000000\n",
      "tensor([3.4456e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8142 --- loss: 0.000000\n",
      "tensor([1.2065e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8145 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8147 --- loss: 0.000051\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8150 --- loss: 0.000029\n",
      "tensor([1.3187e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8152 --- loss: 0.000000\n",
      "tensor([2.0632e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8155 --- loss: 0.000002\n",
      "tensor([0.9986], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8157 --- loss: 0.001388\n",
      "tensor([9.6783e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8160 --- loss: 0.000000\n",
      "tensor([5.2418e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8162 --- loss: 0.000001\n",
      "tensor([3.4704e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8165 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8167 --- loss: 0.000236\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8170 --- loss: 0.000006\n",
      "tensor([1.4150e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8172 --- loss: 0.000000\n",
      "tensor([4.9120e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8175 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8177 --- loss: 0.000000\n",
      "tensor([0.0020], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8180 --- loss: 0.002051\n",
      "tensor([5.0988e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8183 --- loss: 0.000000\n",
      "tensor([1.0936e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8185 --- loss: 0.000000\n",
      "tensor([6.5886e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8188 --- loss: 0.000066\n",
      "tensor([4.2537e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8190 --- loss: 0.000000\n",
      "tensor([5.8264e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8193 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8195 --- loss: 0.000002\n",
      "tensor([2.2791e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8198 --- loss: 0.000023\n",
      "tensor([1.8716e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8200 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8203 --- loss: 0.000003\n",
      "tensor([1.6228e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8205 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8208 --- loss: 0.000060\n",
      "tensor([7.3403e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8210 --- loss: 0.000073\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8213 --- loss: 0.000000\n",
      "tensor([2.0258e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8215 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8218 --- loss: 0.000188\n",
      "tensor([0.0036], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8220 --- loss: 0.003642\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8223 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8225 --- loss: 0.000001\n",
      "tensor([6.0859e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8228 --- loss: 0.000000\n",
      "tensor([1.0143e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8231 --- loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5350e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8233 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8236 --- loss: 0.000002\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8238 --- loss: 0.000167\n",
      "tensor([4.3905e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8241 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8243 --- loss: 0.000057\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8246 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8248 --- loss: 0.000001\n",
      "tensor([7.9245e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8251 --- loss: 0.000008\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8253 --- loss: 0.000102\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8256 --- loss: 0.000035\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8258 --- loss: 0.000043\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8261 --- loss: 0.000015\n",
      "tensor([1.0291e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8263 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8266 --- loss: 0.000001\n",
      "tensor([2.5651e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8268 --- loss: 0.000003\n",
      "tensor([3.2924e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8271 --- loss: 0.000000\n",
      "tensor([8.2829e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8274 --- loss: 0.000001\n",
      "tensor([3.0405e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8276 --- loss: 0.000030\n",
      "tensor([1.4989e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8279 --- loss: 0.000000\n",
      "tensor([2.2510e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8281 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8284 --- loss: 0.000002\n",
      "tensor([3.2852e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8286 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8289 --- loss: 0.000012\n",
      "tensor([2.8140e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8291 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8294 --- loss: 0.000002\n",
      "tensor([2.9113e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8296 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8299 --- loss: 0.000126\n",
      "tensor([2.8925e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8301 --- loss: 0.000000\n",
      "tensor([1.2815e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8304 --- loss: 0.000000\n",
      "tensor([1.8441e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8306 --- loss: 0.000000\n",
      "tensor([0.0010], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8309 --- loss: 0.001026\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8311 --- loss: 0.000048\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8314 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8316 --- loss: 0.000001\n",
      "tensor([6.9573e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8319 --- loss: 0.000007\n",
      "tensor([1.8603e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8322 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8324 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8327 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8329 --- loss: 0.000001\n",
      "tensor([4.0028e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8332 --- loss: 0.000004\n",
      "tensor([2.9243e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8334 --- loss: 0.000029\n",
      "tensor([0.9993], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8337 --- loss: 0.000729\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8339 --- loss: 0.000000\n",
      "tensor([1.0972e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8342 --- loss: 0.000011\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8344 --- loss: 0.000007\n",
      "tensor([1.0891e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8347 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8349 --- loss: 0.000317\n",
      "tensor([9.2582e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8352 --- loss: 0.000009\n",
      "tensor([3.0876e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8354 --- loss: 0.000000\n",
      "tensor([3.2143e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8357 --- loss: 0.000032\n",
      "tensor([4.7959e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8359 --- loss: 0.000000\n",
      "tensor([0.9968], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8362 --- loss: 0.003249\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8365 --- loss: 0.000014\n",
      "tensor([1.1776e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8367 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8370 --- loss: 0.000000\n",
      "tensor([2.9496e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8372 --- loss: 0.000029\n",
      "tensor([0.9581], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8375 --- loss: 0.042793\n",
      "tensor([8.5725e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8377 --- loss: 0.000009\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8380 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8382 --- loss: 0.000022\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8385 --- loss: 0.000305\n",
      "tensor([2.1817e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8387 --- loss: 0.000022\n",
      "tensor([4.5915e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8390 --- loss: 0.000000\n",
      "tensor([1.8182e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8392 --- loss: 0.000018\n",
      "tensor([6.4008e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8395 --- loss: 0.000006\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8397 --- loss: 0.000072\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8400 --- loss: 0.000000\n",
      "tensor([2.8896e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8402 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8405 --- loss: 0.000007\n",
      "tensor([1.3020e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8407 --- loss: 0.000013\n",
      "tensor([1.1361e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8410 --- loss: 0.000000\n",
      "tensor([7.7549e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8413 --- loss: 0.000000\n",
      "tensor([3.4961e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8415 --- loss: 0.000000\n",
      "tensor([2.3677e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8418 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8420 --- loss: 0.000004\n",
      "tensor([1.2023e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8423 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8425 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8428 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8430 --- loss: 0.000000\n",
      "tensor([4.5169e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8433 --- loss: 0.000000\n",
      "tensor([8.8462e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8435 --- loss: 0.000000\n",
      "tensor([3.5700e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8438 --- loss: 0.000000\n",
      "tensor([6.5714e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8440 --- loss: 0.000000\n",
      "tensor([9.4432e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8443 --- loss: 0.000009\n",
      "tensor([1.4829e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8445 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8448 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8450 --- loss: 0.000017\n",
      "tensor([2.2494e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8453 --- loss: 0.000000\n",
      "tensor([9.2935e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8456 --- loss: 0.000009\n",
      "tensor([1.0315e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8458 --- loss: 0.000000\n",
      "tensor([7.3779e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8461 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8463 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8466 --- loss: 0.000001\n",
      "tensor([1.1694e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8468 --- loss: 0.000000\n",
      "tensor([1.2864e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8471 --- loss: 0.000001\n",
      "tensor([8.5889e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8473 --- loss: 0.000000\n",
      "tensor([4.3417e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8476 --- loss: 0.000000\n",
      "tensor([5.8351e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8478 --- loss: 0.000000\n",
      "tensor([0.9882], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8481 --- loss: 0.011883\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8483 --- loss: 0.000000\n",
      "tensor([8.1814e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8486 --- loss: 0.000000\n",
      "tensor([3.2636e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8488 --- loss: 0.000000\n",
      "tensor([1.4911e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8491 --- loss: 0.000000\n",
      "tensor([5.7049e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8493 --- loss: 0.000000\n",
      "tensor([2.3482e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8496 --- loss: 0.000002\n",
      "tensor([1.9708e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8498 --- loss: 0.000000\n",
      "tensor([1.6171e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8501 --- loss: 0.000000\n",
      "tensor([7.0935e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8504 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8506 --- loss: 0.000001\n",
      "tensor([1.6442e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8509 --- loss: 0.000000\n",
      "tensor([1.2107e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8511 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8514 --- loss: 0.000000\n",
      "tensor([4.7342e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8516 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8519 --- loss: 0.000022\n",
      "tensor([8.8316e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8521 --- loss: 0.000000\n",
      "tensor([1.4196e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8524 --- loss: 0.000000\n",
      "tensor([6.2028e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8526 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8529 --- loss: 0.000004\n",
      "tensor([7.2776e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8531 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8534 --- loss: 0.000009\n",
      "tensor([1.5400e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8536 --- loss: 0.000000\n",
      "tensor([4.9344e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8539 --- loss: 0.000000\n",
      "tensor([1.1946e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8541 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8544 --- loss: 0.000001\n",
      "tensor([4.6780e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8547 --- loss: 0.000000\n",
      "tensor([2.7154e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8549 --- loss: 0.000003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8552 --- loss: 0.000232\n",
      "tensor([4.1138e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8554 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8557 --- loss: 0.000019\n",
      "tensor([1.0115e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8559 --- loss: 0.000000\n",
      "tensor([5.0084e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8562 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8564 --- loss: 0.000001\n",
      "tensor([8.1747e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8567 --- loss: 0.000008\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8569 --- loss: 0.000249\n",
      "tensor([5.6872e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8572 --- loss: 0.000000\n",
      "tensor([5.6525e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8574 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8577 --- loss: 0.000000\n",
      "tensor([6.5042e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8579 --- loss: 0.000000\n",
      "tensor([4.6863e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8582 --- loss: 0.000000\n",
      "tensor([3.6985e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8584 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8587 --- loss: 0.000001\n",
      "tensor([1.3574e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8589 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8592 --- loss: 0.000003\n",
      "tensor([7.4861e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8595 --- loss: 0.000001\n",
      "tensor([3.6672e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8597 --- loss: 0.000037\n",
      "tensor([1.7581e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8600 --- loss: 0.000018\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8602 --- loss: 0.000000\n",
      "tensor([6.1770e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8605 --- loss: 0.000062\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8607 --- loss: 0.000110\n",
      "tensor([1.3776e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8610 --- loss: 0.000000\n",
      "tensor([3.4213e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8612 --- loss: 0.000000\n",
      "tensor([7.1553e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8615 --- loss: 0.000000\n",
      "tensor([2.1911e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8617 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8620 --- loss: 0.000008\n",
      "tensor([6.2116e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8622 --- loss: 0.000000\n",
      "tensor([1.0182e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8625 --- loss: 0.000000\n",
      "tensor([0.9992], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8627 --- loss: 0.000848\n",
      "tensor([2.7333e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8630 --- loss: 0.000000\n",
      "tensor([4.4843e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8632 --- loss: 0.000000\n",
      "tensor([1.8509e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8635 --- loss: 0.000002\n",
      "tensor([1.3565e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8638 --- loss: 0.000001\n",
      "tensor([1.8929e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8640 --- loss: 0.000000\n",
      "tensor([1.1824e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8643 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8645 --- loss: 0.000057\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8648 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8650 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8653 --- loss: 0.000012\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8655 --- loss: 0.000007\n",
      "tensor([3.1081e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8658 --- loss: 0.000000\n",
      "tensor([1.3990e-16], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8660 --- loss: 0.000000\n",
      "tensor([1.2877e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8663 --- loss: 0.000000\n",
      "tensor([6.1203e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8665 --- loss: 0.000000\n",
      "tensor([3.5267e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8668 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8670 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8673 --- loss: 0.000029\n",
      "tensor([3.4031e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8675 --- loss: 0.000034\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8678 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8680 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8683 --- loss: 0.000020\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8686 --- loss: 0.000028\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8688 --- loss: 0.000114\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8691 --- loss: 0.000009\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8693 --- loss: 0.000002\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8696 --- loss: 0.000068\n",
      "tensor([1.1639e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8698 --- loss: 0.000000\n",
      "tensor([1.1454e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8701 --- loss: 0.000000\n",
      "tensor([6.0028e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8703 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8706 --- loss: 0.000017\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8708 --- loss: 0.000010\n",
      "tensor([6.1223e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8711 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8713 --- loss: 0.000008\n",
      "tensor([1.3936e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8716 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8718 --- loss: 0.000166\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8721 --- loss: 0.000001\n",
      "tensor([1.3195e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8723 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8726 --- loss: 0.000001\n",
      "tensor([5.8962e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8729 --- loss: 0.000000\n",
      "tensor([1.4959e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8731 --- loss: 0.000000\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8734 --- loss: 0.000437\n",
      "tensor([3.0520e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8736 --- loss: 0.000000\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8739 --- loss: 0.000558\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8741 --- loss: 0.000003\n",
      "tensor([1.5295e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8744 --- loss: 0.000000\n",
      "tensor([6.1473e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8746 --- loss: 0.000000\n",
      "tensor([1.9505e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8749 --- loss: 0.000000\n",
      "tensor([1.2063e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8751 --- loss: 0.000000\n",
      "tensor([7.2889e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8754 --- loss: 0.000000\n",
      "tensor([6.3187e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8756 --- loss: 0.000006\n",
      "tensor([0.0124], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8759 --- loss: 0.012520\n",
      "tensor([3.1416e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8761 --- loss: 0.000000\n",
      "tensor([5.7481e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8764 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8766 --- loss: 0.000001\n",
      "tensor([1.8299e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8769 --- loss: 0.000000\n",
      "tensor([2.7264e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8771 --- loss: 0.000000\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8774 --- loss: 0.000381\n",
      "tensor([4.2327e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8777 --- loss: 0.000042\n",
      "tensor([4.9128e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8779 --- loss: 0.000000\n",
      "tensor([4.3435e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8782 --- loss: 0.000043\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8784 --- loss: 0.000000\n",
      "tensor([2.9239e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8787 --- loss: 0.000000\n",
      "tensor([2.3883e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8789 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8792 --- loss: 0.000097\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8794 --- loss: 0.000002\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8797 --- loss: 0.000019\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8799 --- loss: 0.000048\n",
      "tensor([7.8669e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8802 --- loss: 0.000000\n",
      "tensor([1.9483e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8804 --- loss: 0.000000\n",
      "tensor([2.3342e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8807 --- loss: 0.000000\n",
      "tensor([1.6899e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8809 --- loss: 0.000002\n",
      "tensor([5.8008e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8812 --- loss: 0.000001\n",
      "tensor([1.2756e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8814 --- loss: 0.000000\n",
      "tensor([3.9974e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8817 --- loss: 0.000000\n",
      "tensor([1.7592e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8820 --- loss: 0.000002\n",
      "tensor([1.8599e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8822 --- loss: 0.000019\n",
      "tensor([7.0238e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8825 --- loss: 0.000000\n",
      "tensor([6.3148e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8827 --- loss: 0.000000\n",
      "tensor([5.2920e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8830 --- loss: 0.000000\n",
      "tensor([1.0166e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8832 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8835 --- loss: 0.000006\n",
      "tensor([7.1039e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8837 --- loss: 0.000001\n",
      "tensor([0.0103], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8840 --- loss: 0.010307\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8842 --- loss: 0.000037\n",
      "tensor([4.3866e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8845 --- loss: 0.000000\n",
      "tensor([0.0012], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8847 --- loss: 0.001186\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8850 --- loss: 0.000010\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8852 --- loss: 0.000003\n",
      "tensor([1.9199e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8855 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8857 --- loss: 0.000026\n",
      "tensor([3.9198e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8860 --- loss: 0.000000\n",
      "tensor([1.2848e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8862 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8865 --- loss: 0.000052\n",
      "tensor([1.8340e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8868 --- loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8870 --- loss: 0.000054\n",
      "tensor([3.2760e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8873 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8875 --- loss: 0.000013\n",
      "tensor([3.4818e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8878 --- loss: 0.000035\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8880 --- loss: 0.000034\n",
      "tensor([3.3895e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8883 --- loss: 0.000000\n",
      "tensor([5.0799e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8885 --- loss: 0.000000\n",
      "tensor([7.3881e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8888 --- loss: 0.000000\n",
      "tensor([2.0327e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8890 --- loss: 0.000000\n",
      "tensor([3.0123e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8893 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8895 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8898 --- loss: 0.000003\n",
      "tensor([1.9400e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8900 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8903 --- loss: 0.000025\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8905 --- loss: 0.000051\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8908 --- loss: 0.000002\n",
      "tensor([8.4992e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8911 --- loss: 0.000000\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8913 --- loss: 0.000407\n",
      "tensor([0.9958], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8916 --- loss: 0.004250\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8918 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8921 --- loss: 0.000003\n",
      "tensor([2.5325e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8923 --- loss: 0.000000\n",
      "tensor([3.5434e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8926 --- loss: 0.000000\n",
      "tensor([3.8926e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8928 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8931 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8933 --- loss: 0.000007\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8936 --- loss: 0.000002\n",
      "tensor([2.4323e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8938 --- loss: 0.000000\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8941 --- loss: 0.000775\n",
      "tensor([7.7178e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8943 --- loss: 0.000000\n",
      "tensor([4.4492e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8946 --- loss: 0.000000\n",
      "tensor([1.6346e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8948 --- loss: 0.000000\n",
      "tensor([5.6871e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8951 --- loss: 0.000001\n",
      "tensor([7.9813e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8953 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8956 --- loss: 0.000000\n",
      "tensor([3.5688e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8959 --- loss: 0.000004\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8961 --- loss: 0.000354\n",
      "tensor([1.1719e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8964 --- loss: 0.000000\n",
      "tensor([2.5171e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8966 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8969 --- loss: 0.000029\n",
      "tensor([1.1723e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8971 --- loss: 0.000000\n",
      "tensor([4.0489e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8974 --- loss: 0.000000\n",
      "tensor([4.4110e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8976 --- loss: 0.000000\n",
      "tensor([1.8213e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8979 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8981 --- loss: 0.000000\n",
      "tensor([7.9570e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8984 --- loss: 0.000000\n",
      "tensor([8.5228e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8986 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8989 --- loss: 0.000000\n",
      "tensor([3.1592e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8991 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8994 --- loss: 0.000049\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.8996 --- loss: 0.001628\n",
      "tensor([6.9629e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.8999 --- loss: 0.000001\n",
      "tensor([2.9616e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9002 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9004 --- loss: 0.000003\n",
      "tensor([4.2456e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9007 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9009 --- loss: 0.000004\n",
      "tensor([7.0794e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9012 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9014 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9017 --- loss: 0.000001\n",
      "tensor([3.2155e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9019 --- loss: 0.000000\n",
      "tensor([5.6524e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9022 --- loss: 0.000000\n",
      "tensor([6.0294e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9024 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9027 --- loss: 0.000000\n",
      "tensor([1.8550e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9029 --- loss: 0.000000\n",
      "tensor([3.2311e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9032 --- loss: 0.000003\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9034 --- loss: 0.000090\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9037 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9039 --- loss: 0.000008\n",
      "tensor([2.1600e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9042 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9044 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9047 --- loss: 0.000002\n",
      "tensor([2.0104e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9050 --- loss: 0.000000\n",
      "tensor([1.0447e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9052 --- loss: 0.000000\n",
      "tensor([0.9984], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9055 --- loss: 0.001638\n",
      "tensor([4.6930e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9057 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9060 --- loss: 0.000100\n",
      "tensor([2.0491e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9062 --- loss: 0.000000\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9065 --- loss: 0.000175\n",
      "tensor([5.9754e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9067 --- loss: 0.000000\n",
      "tensor([3.1293e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9070 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9072 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9075 --- loss: 0.000055\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9077 --- loss: 0.000003\n",
      "tensor([6.5631e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9080 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9082 --- loss: 0.000000\n",
      "tensor([4.2615e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9085 --- loss: 0.000000\n",
      "tensor([1.2891e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9087 --- loss: 0.000013\n",
      "tensor([2.2769e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9090 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9093 --- loss: 0.000004\n",
      "tensor([8.1412e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9095 --- loss: 0.000000\n",
      "tensor([1.1000e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9098 --- loss: 0.000000\n",
      "tensor([4.5668e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9100 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9103 --- loss: 0.000081\n",
      "tensor([2.1726e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9105 --- loss: 0.000000\n",
      "tensor([4.0100e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9108 --- loss: 0.000004\n",
      "tensor([1.2415e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9110 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9113 --- loss: 0.000016\n",
      "tensor([3.3837e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9115 --- loss: 0.000000\n",
      "tensor([0.9842], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9118 --- loss: 0.015948\n",
      "tensor([8.7293e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9120 --- loss: 0.000000\n",
      "tensor([7.4683e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9123 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9125 --- loss: 0.000066\n",
      "tensor([2.0730e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9128 --- loss: 0.000000\n",
      "tensor([1.3074e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9130 --- loss: 0.000000\n",
      "tensor([1.7366e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9133 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9135 --- loss: 0.000001\n",
      "tensor([8.0715e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9138 --- loss: 0.000000\n",
      "tensor([9.2998e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9141 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9143 --- loss: 0.000001\n",
      "tensor([5.3444e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9146 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9148 --- loss: 0.000028\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9151 --- loss: 0.000014\n",
      "tensor([0.0002], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9153 --- loss: 0.000203\n",
      "tensor([2.8863e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9156 --- loss: 0.000003\n",
      "tensor([0.0013], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9158 --- loss: 0.001338\n",
      "tensor([8.7369e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9161 --- loss: 0.000000\n",
      "tensor([7.3852e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9163 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9166 --- loss: 0.000001\n",
      "tensor([7.0130e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9168 --- loss: 0.000070\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9171 --- loss: 0.000010\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9173 --- loss: 0.000140\n",
      "tensor([3.0265e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9176 --- loss: 0.000030\n",
      "tensor([9.5914e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9178 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9181 --- loss: 0.000000\n",
      "tensor([2.0215e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9184 --- loss: 0.000000\n",
      "tensor([1.7036e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9186 --- loss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9189 --- loss: 0.000000\n",
      "tensor([1.3434e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9191 --- loss: 0.000000\n",
      "tensor([1.0023e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9194 --- loss: 0.000010\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9196 --- loss: 0.000006\n",
      "tensor([1.3089e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9199 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9201 --- loss: 0.000137\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9204 --- loss: 0.000007\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9206 --- loss: 0.000018\n",
      "tensor([9.4480e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9209 --- loss: 0.000000\n",
      "tensor([6.7654e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9211 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9214 --- loss: 0.000008\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9216 --- loss: 0.000000\n",
      "tensor([3.4697e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9219 --- loss: 0.000000\n",
      "tensor([6.7226e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9221 --- loss: 0.000067\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9224 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9226 --- loss: 0.000000\n",
      "tensor([3.7877e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9229 --- loss: 0.000000\n",
      "tensor([1.5953e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9232 --- loss: 0.000000\n",
      "tensor([4.9763e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9234 --- loss: 0.000000\n",
      "tensor([1.6065e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9237 --- loss: 0.000000\n",
      "tensor([8.4325e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9239 --- loss: 0.000000\n",
      "tensor([3.9502e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9242 --- loss: 0.000040\n",
      "tensor([2.1137e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9244 --- loss: 0.000002\n",
      "tensor([0.9996], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9247 --- loss: 0.000392\n",
      "tensor([1.2484e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9249 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9252 --- loss: 0.000000\n",
      "tensor([3.6646e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9254 --- loss: 0.000037\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9257 --- loss: 0.000134\n",
      "tensor([3.0688e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9259 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9262 --- loss: 0.000002\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9264 --- loss: 0.000091\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9267 --- loss: 0.000001\n",
      "tensor([6.5533e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9269 --- loss: 0.000000\n",
      "tensor([6.7657e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9272 --- loss: 0.000000\n",
      "tensor([8.5137e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9275 --- loss: 0.000000\n",
      "tensor([2.3764e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9277 --- loss: 0.000000\n",
      "tensor([7.3098e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9280 --- loss: 0.000000\n",
      "tensor([2.0620e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9282 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9285 --- loss: 0.000003\n",
      "tensor([7.3567e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9287 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9290 --- loss: 0.000044\n",
      "tensor([9.8637e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9292 --- loss: 0.000000\n",
      "tensor([5.1683e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9295 --- loss: 0.000000\n",
      "tensor([5.6434e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9297 --- loss: 0.000056\n",
      "tensor([4.5111e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9300 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9302 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9305 --- loss: 0.000001\n",
      "tensor([3.9568e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9307 --- loss: 0.000000\n",
      "tensor([8.4640e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9310 --- loss: 0.000000\n",
      "tensor([1.8611e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9312 --- loss: 0.000000\n",
      "tensor([6.1919e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9315 --- loss: 0.000006\n",
      "tensor([9.3872e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9317 --- loss: 0.000009\n",
      "tensor([1.1882e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9320 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9323 --- loss: 0.000011\n",
      "tensor([6.4227e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9325 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9328 --- loss: 0.000007\n",
      "tensor([1.4594e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9330 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9333 --- loss: 0.000007\n",
      "tensor([1.0125e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9335 --- loss: 0.000000\n",
      "tensor([2.3974e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9338 --- loss: 0.000024\n",
      "tensor([7.0896e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9340 --- loss: 0.000000\n",
      "tensor([4.7584e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9343 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9345 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9348 --- loss: 0.000091\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9350 --- loss: 0.000004\n",
      "tensor([3.5299e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9353 --- loss: 0.000000\n",
      "tensor([1.5802e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9355 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9358 --- loss: 0.000013\n",
      "tensor([3.5846e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9360 --- loss: 0.000000\n",
      "tensor([1.2303e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9363 --- loss: 0.000000\n",
      "tensor([1.4045e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9366 --- loss: 0.000014\n",
      "tensor([1.1404e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9368 --- loss: 0.000000\n",
      "tensor([0.0560], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9371 --- loss: 0.057615\n",
      "tensor([8.9953e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9373 --- loss: 0.000000\n",
      "tensor([4.5058e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9376 --- loss: 0.000000\n",
      "tensor([0.9978], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9378 --- loss: 0.002191\n",
      "tensor([0.9981], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9381 --- loss: 0.001934\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9383 --- loss: 0.000000\n",
      "tensor([9.6150e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9386 --- loss: 0.000000\n",
      "tensor([2.1343e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9388 --- loss: 0.000000\n",
      "tensor([4.4557e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9391 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9393 --- loss: 0.000001\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9396 --- loss: 0.000061\n",
      "tensor([1.7438e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9398 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9401 --- loss: 0.000004\n",
      "tensor([2.4014e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9403 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9406 --- loss: 0.000083\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9408 --- loss: 0.000001\n",
      "tensor([1.8607e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9411 --- loss: 0.000000\n",
      "tensor([2.7002e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9414 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9416 --- loss: 0.000125\n",
      "tensor([2.3212e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9419 --- loss: 0.000002\n",
      "tensor([3.8765e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9421 --- loss: 0.000000\n",
      "tensor([2.4404e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9424 --- loss: 0.000000\n",
      "tensor([5.7148e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9426 --- loss: 0.000000\n",
      "tensor([1.4290e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9429 --- loss: 0.000014\n",
      "tensor([9.6286e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9431 --- loss: 0.000000\n",
      "tensor([3.1795e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9434 --- loss: 0.000003\n",
      "tensor([1.5370e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9436 --- loss: 0.000015\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9439 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9441 --- loss: 0.000007\n",
      "tensor([3.5605e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9444 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9446 --- loss: 0.000004\n",
      "tensor([2.2247e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9449 --- loss: 0.000002\n",
      "tensor([1.7542e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9451 --- loss: 0.000000\n",
      "tensor([2.1208e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9454 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9457 --- loss: 0.000052\n",
      "tensor([1.2626e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9459 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9462 --- loss: 0.000131\n",
      "tensor([4.5751e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9464 --- loss: 0.000046\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9467 --- loss: 0.000249\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9469 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9472 --- loss: 0.000007\n",
      "tensor([2.1711e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9474 --- loss: 0.000022\n",
      "tensor([1.0303e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9477 --- loss: 0.000000\n",
      "tensor([7.3948e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9479 --- loss: 0.000007\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9482 --- loss: 0.000045\n",
      "tensor([1.9247e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9484 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9487 --- loss: 0.000001\n",
      "tensor([4.3950e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9489 --- loss: 0.000000\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9492 --- loss: 0.000195\n",
      "tensor([1.1305e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9494 --- loss: 0.000011\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9497 --- loss: 0.000107\n",
      "tensor([4.7917e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9499 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9502 --- loss: 0.000018\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9505 --- loss: 0.000039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9507 --- loss: 0.000000\n",
      "tensor([0.9974], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9510 --- loss: 0.002573\n",
      "tensor([2.5610e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9512 --- loss: 0.000026\n",
      "tensor([0.9818], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9515 --- loss: 0.018406\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9517 --- loss: 0.000144\n",
      "tensor([1.5509e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9520 --- loss: 0.000000\n",
      "tensor([0.9994], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9522 --- loss: 0.000645\n",
      "tensor([1.0395e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9525 --- loss: 0.000000\n",
      "tensor([1.1017e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9527 --- loss: 0.000000\n",
      "tensor([8.6751e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9530 --- loss: 0.000000\n",
      "tensor([1.0398e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9532 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9535 --- loss: 0.000053\n",
      "tensor([1.0835e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9537 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9540 --- loss: 0.000000\n",
      "tensor([5.2205e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9542 --- loss: 0.000000\n",
      "tensor([3.3622e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9545 --- loss: 0.000000\n",
      "tensor([5.8046e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9548 --- loss: 0.000001\n",
      "tensor([4.2108e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9550 --- loss: 0.000000\n",
      "tensor([3.3506e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9553 --- loss: 0.000034\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9555 --- loss: 0.000295\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9558 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9560 --- loss: 0.000000\n",
      "tensor([2.5741e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9563 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9565 --- loss: 0.000000\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9568 --- loss: 0.000456\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9570 --- loss: 0.000000\n",
      "tensor([3.9042e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9573 --- loss: 0.000000\n",
      "tensor([5.5409e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9575 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9578 --- loss: 0.000006\n",
      "tensor([0.0003], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9580 --- loss: 0.000321\n",
      "tensor([2.1593e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9583 --- loss: 0.000000\n",
      "tensor([6.9307e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9585 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9588 --- loss: 0.000008\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9590 --- loss: 0.000033\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9593 --- loss: 0.000057\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9596 --- loss: 0.000115\n",
      "tensor([2.9400e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9598 --- loss: 0.000000\n",
      "tensor([1.9050e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9601 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9603 --- loss: 0.000007\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9606 --- loss: 0.000002\n",
      "tensor([9.6400e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9608 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9611 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9613 --- loss: 0.000000\n",
      "tensor([4.8876e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9616 --- loss: 0.000000\n",
      "tensor([2.7570e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9618 --- loss: 0.000000\n",
      "tensor([1.8246e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9621 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9623 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9626 --- loss: 0.000002\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9628 --- loss: 0.000275\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9631 --- loss: 0.000002\n",
      "tensor([4.9560e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9633 --- loss: 0.000000\n",
      "tensor([6.9921e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9636 --- loss: 0.000000\n",
      "tensor([7.8431e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9639 --- loss: 0.000000\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9641 --- loss: 0.000333\n",
      "tensor([3.7140e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9644 --- loss: 0.000000\n",
      "tensor([7.0021e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9646 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9649 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9651 --- loss: 0.000004\n",
      "tensor([1.1383e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9654 --- loss: 0.000000\n",
      "tensor([2.8030e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9656 --- loss: 0.000000\n",
      "tensor([2.1469e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9659 --- loss: 0.000000\n",
      "tensor([3.0263e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9661 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9664 --- loss: 0.000004\n",
      "tensor([3.8536e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9666 --- loss: 0.000000\n",
      "tensor([1.7739e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9669 --- loss: 0.000000\n",
      "tensor([1.9356e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9671 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9674 --- loss: 0.000009\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9676 --- loss: 0.000101\n",
      "tensor([6.3262e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9679 --- loss: 0.000001\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9681 --- loss: 0.000152\n",
      "tensor([2.3377e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9684 --- loss: 0.000023\n",
      "tensor([2.7465e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9687 --- loss: 0.000000\n",
      "tensor([1.6217e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9689 --- loss: 0.000002\n",
      "tensor([0.9998], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9692 --- loss: 0.000231\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9694 --- loss: 0.000082\n",
      "tensor([4.2130e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9697 --- loss: 0.000004\n",
      "tensor([5.6513e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9699 --- loss: 0.000000\n",
      "tensor([4.2709e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9702 --- loss: 0.000004\n",
      "tensor([3.6330e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9704 --- loss: 0.000036\n",
      "tensor([1.3463e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9707 --- loss: 0.000001\n",
      "tensor([2.3652e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9709 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9712 --- loss: 0.000112\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9714 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9717 --- loss: 0.000022\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9719 --- loss: 0.000108\n",
      "tensor([5.8833e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9722 --- loss: 0.000006\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9724 --- loss: 0.000065\n",
      "tensor([4.2840e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9727 --- loss: 0.000000\n",
      "tensor([1.1345e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9730 --- loss: 0.000011\n",
      "tensor([4.0934e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9732 --- loss: 0.000000\n",
      "tensor([3.0503e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9735 --- loss: 0.000000\n",
      "tensor([7.5247e-15], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9737 --- loss: 0.000000\n",
      "tensor([0.9977], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9740 --- loss: 0.002291\n",
      "tensor([7.7119e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9742 --- loss: 0.000000\n",
      "tensor([1.4995e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9745 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9747 --- loss: 0.000066\n",
      "tensor([0.9943], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9750 --- loss: 0.005671\n",
      "tensor([2.8150e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9752 --- loss: 0.000028\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9755 --- loss: 0.000000\n",
      "tensor([1.4970e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9757 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9760 --- loss: 0.000001\n",
      "tensor([2.0170e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9762 --- loss: 0.000000\n",
      "tensor([7.0163e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9765 --- loss: 0.000000\n",
      "tensor([1.0401e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9767 --- loss: 0.000000\n",
      "tensor([1.8259e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9770 --- loss: 0.000000\n",
      "tensor([4.5419e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9772 --- loss: 0.000000\n",
      "tensor([0.0001], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9775 --- loss: 0.000141\n",
      "tensor([6.6447e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9778 --- loss: 0.000000\n",
      "tensor([1.4352e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9780 --- loss: 0.000000\n",
      "tensor([2.9880e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9783 --- loss: 0.000003\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9785 --- loss: 0.000007\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9788 --- loss: 0.000012\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9790 --- loss: 0.000452\n",
      "tensor([7.1804e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9793 --- loss: 0.000001\n",
      "tensor([2.7642e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9795 --- loss: 0.000000\n",
      "tensor([0.0004], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9798 --- loss: 0.000364\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9800 --- loss: 0.000003\n",
      "tensor([1.3373e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9803 --- loss: 0.000000\n",
      "tensor([2.2035e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9805 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9808 --- loss: 0.000000\n",
      "tensor([4.5777e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9810 --- loss: 0.000000\n",
      "tensor([4.5048e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9813 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9815 --- loss: 0.000000\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9818 --- loss: 0.000112\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9821 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9823 --- loss: 0.000007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1751e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9826 --- loss: 0.000000\n",
      "tensor([4.8533e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9828 --- loss: 0.000000\n",
      "tensor([2.8413e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9831 --- loss: 0.000000\n",
      "tensor([2.4584e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9833 --- loss: 0.000000\n",
      "tensor([1.2321e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9836 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9838 --- loss: 0.000005\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9841 --- loss: 0.000022\n",
      "tensor([6.2601e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9843 --- loss: 0.000000\n",
      "tensor([3.0062e-16], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9846 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9848 --- loss: 0.000001\n",
      "tensor([6.2069e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9851 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9853 --- loss: 0.000003\n",
      "tensor([3.0847e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9856 --- loss: 0.000000\n",
      "tensor([9.5492e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9858 --- loss: 0.000000\n",
      "tensor([1.8569e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9861 --- loss: 0.000000\n",
      "tensor([1.9355e-10], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9863 --- loss: 0.000000\n",
      "tensor([6.8145e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9866 --- loss: 0.000000\n",
      "tensor([1.9783e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9869 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9871 --- loss: 0.000000\n",
      "tensor([1.2672e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9874 --- loss: 0.000000\n",
      "tensor([4.4706e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9876 --- loss: 0.000000\n",
      "tensor([3.8178e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9879 --- loss: 0.000000\n",
      "tensor([1.2870e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9881 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9884 --- loss: 0.000005\n",
      "tensor([1.5430e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9886 --- loss: 0.000000\n",
      "tensor([1.0470e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9889 --- loss: 0.000010\n",
      "tensor([2.1666e-12], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9891 --- loss: 0.000000\n",
      "tensor([5.1214e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9894 --- loss: 0.000005\n",
      "tensor([8.4747e-14], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9896 --- loss: 0.000000\n",
      "tensor([2.1359e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9899 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9901 --- loss: 0.000001\n",
      "tensor([2.1687e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9904 --- loss: 0.000022\n",
      "tensor([0.9995], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9906 --- loss: 0.000506\n",
      "tensor([3.5776e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9909 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9912 --- loss: 0.000047\n",
      "tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9914 --- loss: 0.000078\n",
      "tensor([4.4549e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9917 --- loss: 0.000000\n",
      "tensor([6.8048e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9919 --- loss: 0.000007\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9922 --- loss: 0.000018\n",
      "tensor([3.7343e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9924 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9927 --- loss: 0.000001\n",
      "tensor([2.1802e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9929 --- loss: 0.000000\n",
      "tensor([1.8897e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9932 --- loss: 0.000002\n",
      "tensor([2.9926e-08], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9934 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9937 --- loss: 0.000006\n",
      "tensor([0.9997], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9939 --- loss: 0.000294\n",
      "tensor([1.4418e-11], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9942 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9944 --- loss: 0.000001\n",
      "tensor([6.4013e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9947 --- loss: 0.000000\n",
      "tensor([1.0195e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9949 --- loss: 0.000010\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9952 --- loss: 0.000032\n",
      "tensor([1.3119e-05], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9954 --- loss: 0.000013\n",
      "tensor([2.1085e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9957 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9960 --- loss: 0.000004\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9962 --- loss: 0.000013\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9965 --- loss: 0.000006\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9967 --- loss: 0.000000\n",
      "tensor([2.5757e-06], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9970 --- loss: 0.000003\n",
      "tensor([7.8893e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9972 --- loss: 0.000001\n",
      "tensor([5.8182e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9975 --- loss: 0.000001\n",
      "tensor([0.0008], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9977 --- loss: 0.000782\n",
      "tensor([1.5214e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9980 --- loss: 0.000000\n",
      "tensor([4.1234e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9982 --- loss: 0.000000\n",
      "tensor([6.0604e-07], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9985 --- loss: 0.000001\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9987 --- loss: 0.000000\n",
      "tensor([1.1481e-13], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9990 --- loss: 0.000000\n",
      "tensor([1.9748e-09], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.]], dtype=torch.float64)\n",
      "0.9992 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9995 --- loss: 0.000000\n",
      "tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward>)\n",
      "tensor([[1.]], dtype=torch.float64)\n",
      "0.9997 --- loss: 0.000004\n",
      "Epoch finished ! Loss: 0.001034637359351771\n",
      "Checkpoint 2 saved !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Specify number of epochs, image scale factor, batch size and learning rate\n",
    "epochs = 2 # i.e, 4\n",
    "batch_size = 1 # i.e, 16\n",
    "lr = 0.001       # i.e, 0.01\n",
    "N_train = len(train_img_prob)\n",
    "model_save_path = './model/'  # directory to same the model after each epoch. \n",
    "net = UNet(3,1).double()\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(),lr=lr,momentum=0.9,weight_decay=0.0005)\n",
    "\n",
    "\n",
    "\n",
    "# The loss function we use is binary cross entropy: nn.BCELoss()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "\n",
    "# Start training\n",
    "for epoch in range(epochs):\n",
    "    print('Starting epoch {}/{}.'.format(epoch + 1, epochs))\n",
    "    net.train()\n",
    "    # Reload images for training and perform random shuffling at the begining of each epoch\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, b in enumerate(train_loader):\n",
    "        # Get images and probility from each batch\n",
    "        imgs = b['img']\n",
    "        true_prob = b['label']\n",
    "\n",
    "        # Feed your images into the network\n",
    "        prob_pred = net(imgs)\n",
    "        print(prob_pred)\n",
    "        print(true_prob)\n",
    "\n",
    "        loss = criterion(prob_pred,true_prob)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        print('{0:.4f} --- loss: {1:.6f}'.format(i * batch_size / N_train, loss.item()))\n",
    "\n",
    "        # optimizer.zero_grad() clears x.grad for every parameter x in the optimizer. \n",
    "        optimizer.zero_grad()\n",
    "        # loss.backward() computes dloss/dx for every parameter x which has requires_grad=True. \n",
    "        # These are accumulated into x.grad for every parameter x\n",
    "        # x.grad += dloss/dx\n",
    "        loss.backward()\n",
    "        # optimizer.step updates the value of x using the gradient x.grad. \n",
    "        # x += -lr * x.grad\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch finished ! Loss: {}'.format(epoch_loss / i))\n",
    "\n",
    "    # Save the model after each epoch\n",
    "    if os.path.isdir(model_save_path):\n",
    "        torch.save(net.state_dict(),model_save_path + 'Car_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "    else:\n",
    "        os.makedirs(model_save_path, exist_ok=True)\n",
    "        torch.save(net.state_dict(),model_save_path + 'Car_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "    print('Checkpoint {} saved !'.format(epoch + 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loss converge to 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
